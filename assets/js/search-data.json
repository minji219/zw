{
  
    
        "post0": {
            "title": "Title",
            "content": "import numpy as np import pandas as pd . np.random.seed(1) #값을 통일하게 만들기 위해 seed설정 dic={&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5), &#39;X4&#39;:np.random.normal(0,1,5), &#39;X5&#39;:np.random.normal(0,1,5), &#39;X6&#39;:np.random.normal(0,1,5)} df1=pd.DataFrame(dic) df1 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 1 -0.611756 | 1.744812 | -2.060141 | -0.172428 | 1.144724 | -0.122890 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . 3 -1.072969 | 0.319039 | -0.384054 | 0.042214 | 0.502494 | -0.267888 | . 4 0.865408 | -0.249370 | 1.133769 | 0.582815 | 0.900856 | 0.530355 | . &#52395;&#48264;&#51704; &#54665;&#51012; &#49440;&#53469;&#54644;&#48372;&#51088; . df1.iloc[0] . X1 1.624345 X2 -2.301539 X3 1.462108 X4 -1.099891 X5 -1.100619 X6 -0.683728 Name: 0, dtype: float64 . df1.iloc[[0]] #이게 더 보기 좋음 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . df1.iloc[0,1] # 오 어쩌다가 걍 나옴 이렇게 하면 0번째 행 1번쨰 열 나옴 . -2.3015386968802827 . df1.iloc[0,:] #행을 뽑기 . X1 1.624345 X2 -2.301539 X3 1.462108 X4 -1.099891 X5 -1.100619 X6 -0.683728 Name: 0, dtype: float64 . df1.iloc[[0],:] #괄호 헷갈림.... . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . loc&#51004;&#47196; &#54644;&#48372;&#51109; . df1.loc[0] . X1 1.624345 X2 -2.301539 X3 1.462108 X4 -1.099891 X5 -1.100619 X6 -0.683728 Name: 0, dtype: float64 . df1.loc[[0]] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . df1.loc[0,:] . X1 1.624345 X2 -2.301539 X3 1.462108 X4 -1.099891 X5 -1.100619 X6 -0.683728 Name: 0, dtype: float64 . df1.loc[[0],:] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . &#45796;&#49884; iloc . df1.iloc[[True,True,False,False,False]] #첫번째, 두번째 행을 뽑아라...를 True 로 나타냄 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 1 -0.611756 | 1.744812 | -2.060141 | -0.172428 | 1.144724 | -0.122890 | . df1.iloc[[False,False,True,True,False],:] #이렇게 해도 가능 . X1 X2 X3 X4 X5 X6 . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . 3 -1.072969 | 0.319039 | -0.384054 | 0.042214 | 0.502494 | -0.267888 | . df1.loc[[False,False,True,False,True]] #loc으로 해도 가능 . X1 X2 X3 X4 X5 X6 . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . 4 0.865408 | -0.249370 | 1.133769 | 0.582815 | 0.900856 | 0.530355 | . df1.loc[[False,False,True,False,True],:] #당연히 이것도 가능 . X1 X2 X3 X4 X5 X6 . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . 4 0.865408 | -0.249370 | 1.133769 | 0.582815 | 0.900856 | 0.530355 | . df1 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 1 -0.611756 | 1.744812 | -2.060141 | -0.172428 | 1.144724 | -0.122890 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . 3 -1.072969 | 0.319039 | -0.384054 | 0.042214 | 0.502494 | -0.267888 | . 4 0.865408 | -0.249370 | 1.133769 | 0.582815 | 0.900856 | 0.530355 | . 1,3&#54665; &#49440;&#53469;&#54644;&#48372;&#51109; . df1.iloc[[0,2],:] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . df1.iloc[[0,2]] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . df1.loc[[0,2]] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . loc vs iloc . 인덱스가 정수가 아닌경우 . _df=pd.DataFrame({&#39;A&#39;:[1,2,3,4],&#39;B&#39;:[4,5,6,7]},index=list(&#39;abcd&#39;)) #괄호가 항상헷갈림... . _df . A B . a 1 | 4 | . b 2 | 5 | . c 3 | 6 | . d 4 | 7 | . _df.loc[&#39;a&#39;] . A 1 B 4 Name: a, dtype: int64 . _df.loc[&#39;a&#39;:&#39;c&#39;,] #문자니까 loc사용 . A B . a 1 | 4 | . b 2 | 5 | . c 3 | 6 | . _df.iloc[0:2,] . A B . a 1 | 4 | . b 2 | 5 | . &#50836;&#50557; : loc&#48372;&#45796;&#45716; iloc&#51060; &#45908; &#50424;&#47784;&#51080;&#45796;~~ . but 특정경우에 loc이 더 쓸모있을때 있음 시계열 자료일때 . _df . A B . a 1 | 4 | . b 2 | 5 | . c 3 | 6 | . d 4 | 7 | . A열 뽑을땐!! . _df.loc[&#39;A&#39;] ###이거안됨 . _df[&#39;A&#39;] . a 1 b 2 c 3 d 4 Name: A, dtype: int64 . iloc과 loc 은 [2],[2,:]처럼 1차원으로 원소 인덱싱,, 아님 [2,3],[:,3]와 같이 2차원으로 인덱싱 1차원 인덱싱하는 경우 기본적으로 행을 인덱싱,, . iloc,loc &#51008; &#54665;&#51060; &#50676;&#48372;&#45796; &#45908; &#52828;&#54616;&#45796;!! . . np.random.seed(1) #값 고정 df2=pd.DataFrame(np.random.normal(size=(10,4)),columns=list(&#39;ABCD&#39;)) . df2 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 7 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 칼럼A의 값이 0보다 큰 경우만 . df2.loc[map(lambda x: x&gt;0,df2[&#39;A&#39;]),:] #map 과 lambda사용 df2의`A`의 값 중에 0보다 큰 행을 뽑아라 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . df2.loc[lambda df2: df2[&#39;A&#39;]&gt;0,:] #map사용 없이 할 수 있음 함수를 적용한게 아니라 오브젝트 자체를 함 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . df2로 써도 되고 그냥 df 로 써도 된다... 어케 그러지..? . df2.loc[lambda df2 : df2[&#39;C&#39;]&gt;0,:] . A B C D . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 칼럼 A&gt;0, 칼럼 C&lt;0인 경우 . df2.loc[map(lambda x,y: x&gt;0 and y&lt;0,df2[&#39;A&#39;],df2[&#39;C&#39;]),:] #lambda 입력:출력 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . df2.loc[map(lambda x,y:(x&gt;0) &amp; (y&lt;0), df2[&#39;A&#39;],df2[&#39;C&#39;])] #&amp;이거 쓸때는 걍 (x&gt;0) &amp; (y&lt;0)이렇게 괄호 쳐주면ㄷ 됨 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . df2 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 7 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . df2.loc[map(lambda x,y : x&gt;-1 and y&lt;1.5,df2[&#39;A&#39;],df2[&#39;C&#39;]),:] . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 7 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | .",
            "url": "https://minji219.github.io/zw/2021/12/30/%EC%A3%BC%EC%B0%A8-%EB%B3%B5%EC%8A%B5%EA%B2%B8-%EA%B3%BC%EC%A0%9C.html",
            "relUrl": "/2021/12/30/%EC%A3%BC%EC%B0%A8-%EB%B3%B5%EC%8A%B5%EA%B2%B8-%EA%B3%BC%EC%A0%9C.html",
            "date": " • Dec 30, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "lambda&#50752; map . f = lambda x,y,z : x+y+z ##lambda입력:출력 . f(3,4,5) . 12 . 아하 . x = (lambda a=&#39;n&#39;, b=&#39;ct&#39;, c=&#39;jw&#39;: a+b) #근데 이건 괄호왜침 . x(&#39;love&#39;) #앞에 글자가 바뀌었다 . &#39;lovect&#39; . &#46988;&#45796;&#46308;&#51032; &#47532;&#49828;&#53944; &#44592;&#45733; . l=[lambda x: x**2, lambda x:x**3, lambda x: x**4, lambda x: x**5] . 입력 : 출력 형태임 . for f in l: #for 문 사용해서 하기 print(f(2)) . 4 8 16 32 . for f in l: #for 문 사용해서 하기 print(f(3)) . 9 27 81 243 . &#46988;&#45796;&#46308;&#51032; &#46357;&#49492;&#45320;&#47532; &#44592;&#45733; . hihi={&#39;f1&#39;: (lambda x: x+1), &#39;f2&#39;: (lambda x: x+219), &#39;f3&#39;: (lambda x: x+77)} . hihi[&#39;f1&#39;](1), hihi[&#39;f2&#39;](2), hihi[&#39;f3&#39;](4) . (2, 221, 81) . 오 . &#39;c&#39;&lt;&#39;d&#39; . True . 개똑똑 . &#39;d&#39;&lt;&#39;c&#39; #wow . False . &#47928;&#51088;&#50676;&#51032; &#45824;&#49548;&#48708;&#44368; . hello= lambda x,y: x if x&lt;y else y #x랑 y를 넣는데 만약 x가 y보다 작으면 x가 나오게 하고 아님 y가 나와라? . hello(&#39;d&#39;,&#39;c&#39;) . &#39;c&#39; . lambda expression&#51012; return&#44032;&#45733; . def action(x): return(lambda y: x+y) #lambda는 입력:출력 형태 . act= action(99) #99+y 임 act2 =action(98) . print(act(2)) print(act2(2)) . 101 100 . map&#49324;&#50857;&#48277; . def inc(x): return x+1 . map(inc,[1,2,3,4]) #object만들어짐 . &lt;map at 0x24a31a39460&gt; . list(map(inc,[1,2,3,4])) #list화 . [2, 3, 4, 5] . 내가만든 함수가 각ㅇ 원소에 적용이됨 . list(map(lambda x:x+1,[1,2,3,4])) . [2, 3, 4, 5] . list(map(def inc(x): return x+1,[1,2,3,4])) #이건 안됨 . File &#34;&lt;ipython-input-45-941c1cc5d48b&gt;&#34;, line 1 list(map(def inc(x): return x+1,[1,2,3,4])) #이건 안됨 ^ SyntaxError: invalid syntax . - 함수명을 쓰는 자리에 lambda로 표현한 오브젝트 자체를 전달할 수 있다. 그래서 코드가 간단해짐 . map 쓰고 왼쪽에는 함수이름, lambda표현식, 오른쪽에는 벡터의 형태 . f=lambda x : &#39;X&#39; in x #엑스가 엑스에 있는지 . f(&#39;X1&#39;),f(&#39;Y1&#39;) . (True, False) . map(f,[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;,&#39;Y4&#39;]) . &lt;map at 0x24a31aef070&gt; . list(map(f,[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;,&#39;Y4&#39;])) . [True, True, True, False] . (리스트컴프리헨션과 비교) . [f(x) for x in [&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;]] . [True, True, False, False] . list(map(pow,[2,2],[0,1])) #2^0,2^1계산 map 사용 . [1, 2] . (리스트컴프리헨션과비교) . [pow(x,y) for x,y in zip([2,2],[0,1])] #리스트컴프리헨션사용 . [1, 2] . (zip([2,2],[0,1])) #무언가의 오브젝트가 저장 . &lt;zip at 0x24a31ae9dc0&gt; . list(zip([2,2],[0,1])) . [(2, 0), (2, 1)] . [(2, 0), (2, 1)] = zip([2,2],[0,1] 같음 . . l=[lambda x:x+1, lambda x : x+2, lambda x : x+3] # 입력이 x 출력이 x+1 인 함수.. . list(map(l,[100,200,300])) #이건 안됨, map은 하나의 함수 , 다양한 입력인 경우에만 사용 가능 이건 3:3임 . TypeError Traceback (most recent call last) &lt;ipython-input-70-805186c4265a&gt; in &lt;module&gt; -&gt; 1 list(map(l,[100,200,300])) #이건 안됨, map은 하나의 함수 , 다양한 입력인 경우에만 사용 가능 이건 3:3임 TypeError: &#39;list&#39; object is not callable . 리스트 컴프리헨션은 다양한 함수 다양한 입력이 가능 ㅎㅎ . [l[i](x) for i,x in zip ([0,1,2],[100,200,300])] #i 에 0 이 들어가면 첫번쨰 람다함수튀어나옴 . [101, 202, 303] . 리스트컴프리헨션과 비교하면 map 이 반복인덱스를 쓰지 않는 장점이 있지만다양한 함수 쓰지 못함, 제약적임 .",
            "url": "https://minji219.github.io/zw/2021/12/30/%EC%97%B0%EC%8A%B5/.!!.html",
            "relUrl": "/2021/12/30/%EC%97%B0%EC%8A%B5/.!!.html",
            "date": " • Dec 30, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Title",
            "content": "import numpy as np import pandas as pd import warnings from IPython.display import HTML import folium import json import requests import matplotlib.pyplot as plt from plotnine import * . 4-2&#48264; . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) df . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 16705 240558 | 18 L. Clayton | 17 | https://cdn.sofifa.com/players/240/558/18_60.png | England | https://cdn.sofifa.com/flags/gb-eng.png | 53 | 70 | Cheltenham Town | https://cdn.sofifa.com/teams/1936/30.png | ... | 12.0 | 55.0 | 54.0 | 52.0 | 50.0 | 59.0 | GK | 52.0 | €238K | NaN | . 16706 262846 | �. Dobre | 20 | https://cdn.sofifa.com/players/262/846/22_60.png | Romania | https://cdn.sofifa.com/flags/ro.png | 53 | 63 | FC Academica Clinceni | https://cdn.sofifa.com/teams/113391/30.png | ... | 12.0 | 57.0 | 52.0 | 53.0 | 48.0 | 58.0 | GK | 53.0 | €279K | 5.0 | . 16707 241317 | 21 Xue Qinghao | 19 | https://cdn.sofifa.com/players/241/317/21_60.png | China PR | https://cdn.sofifa.com/flags/cn.png | 47 | 60 | Shanghai Shenhua FC | https://cdn.sofifa.com/teams/110955/30.png | ... | 9.0 | 49.0 | 48.0 | 45.0 | 38.0 | 52.0 | GK | 47.0 | €223K | 21.0 | . 16708 259646 | A. Shaikh | 18 | https://cdn.sofifa.com/players/259/646/22_60.png | India | https://cdn.sofifa.com/flags/in.png | 47 | 67 | ATK Mohun Bagan FC | https://cdn.sofifa.com/teams/113146/30.png | ... | 13.0 | 49.0 | 41.0 | 39.0 | 45.0 | 49.0 | GK | 47.0 | €259K | 7.0 | . 16709 178453 | 07 A. Censori | 17 | https://cdn.sofifa.com/players/178/453/07_60.png | Italy | https://cdn.sofifa.com/flags/it.png | 28 | 38 | Arezzo | https://cdn.sofifa.com/teams/110907/30.png | ... | NaN | 7.0 | 1.0 | 36.0 | 6.0 | 9.0 | ST | 36.0 | NaN | NaN | . 16710 rows × 65 columns . df6=df.groupby(by=&#39;Nationality&#39;).agg({&#39;Overall&#39;:&#39;mean&#39;}).sort_values(by=&#39;Overall&#39;,ascending=False).head(20).reset_index() df6 . Nationality Overall . 0 Tanzania | 74.000000 | . 1 Mozambique | 72.750000 | . 2 Brazil | 72.411477 | . 3 Libya | 72.250000 | . 4 Fiji | 72.000000 | . 5 Namibia | 72.000000 | . 6 Egypt | 71.678571 | . 7 Czech Republic | 71.653465 | . 8 Ukraine | 71.550725 | . 9 Algeria | 71.517241 | . 10 Central African Republic | 71.333333 | . 11 Cape Verde Islands | 71.285714 | . 12 Serbia | 70.856000 | . 13 Portugal | 70.635593 | . 14 Syria | 70.500000 | . 15 Argentina | 70.309693 | . 16 Croatia | 70.271429 | . 17 Gabon | 70.235294 | . 18 Russia | 70.231481 | . 19 Uruguay | 70.222222 | . df5=df[&#39;Nationality&#39;].value_counts().head(20).reset_index().rename(columns={&#39;index&#39;:&#39;Nationality&#39;,&#39;Nationality&#39;:&#39;count&#39;}) df5 . Nationality count . 0 England | 1845 | . 1 Spain | 1151 | . 2 Germany | 1120 | . 3 France | 987 | . 4 Argentina | 846 | . 5 Brazil | 819 | . 6 Italy | 514 | . 7 Netherlands | 443 | . 8 Portugal | 354 | . 9 United States | 341 | . 10 Mexico | 312 | . 11 Republic of Ireland | 308 | . 12 Scotland | 292 | . 13 Japan | 284 | . 14 Belgium | 267 | . 15 Denmark | 264 | . 16 Sweden | 263 | . 17 Poland | 261 | . 18 Norway | 261 | . 19 Colombia | 257 | . a=set(df6.Nationality) b=set(df5.Nationality) a.intersection(b) . {&#39;Argentina&#39;, &#39;Brazil&#39;, &#39;Portugal&#39;} . df7=df.groupby(by=&#39;Nationality&#39;).agg({&#39;Age&#39;:&#39;mean&#39;}).loc[[&#39;Argentina&#39;, &#39;Brazil&#39;, &#39;Portugal&#39;]].reset_index() df7 . Nationality Age . 0 Argentina | 27.255319 | . 1 Brazil | 26.927961 | . 2 Portugal | 25.692090 | . df7.plot.bar(x=&#39;Nationality&#39;,y=&quot;Age&quot;,figsize=(10,5)) . &lt;AxesSubplot:xlabel=&#39;Nationality&#39;&gt; . . 5&#48264; . df1=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/gdp_df1.csv&#39;) df1 . GDP Inequality Government . 0 500 | 56 | A | . 1 550 | 58 | A | . 2 530 | 59 | A | . 3 480 | 61 | A | . 4 550 | 64 | A | . 5 550 | 64 | B | . 6 750 | 66 | B | . 7 560 | 68 | B | . 8 800 | 70 | B | . 9 900 | 65 | B | . 10 900 | 65 | C | . 11 910 | 62 | C | . 12 1100 | 61 | C | . 13 1250 | 58 | C | . 14 1350 | 63 | C | . 15 1350 | 63 | D | . 16 1500 | 57 | D | . 17 1660 | 55 | D | . df2=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/gdp_df2.csv&#39;,index_col=0) df2=df2.T.reset_index() df2=df2.rename(columns={&#39;index&#39;:&#39;Government&#39;}) df2 . Government pop . 0 A | 54232.213 | . 1 B | 48823.432 | . 2 C | 46823.453 | . 3 D | 45232.119 | . df3=pd.merge(df1,df2,on=&#39;Government&#39;) df3 . GDP Inequality Government pop . 0 500 | 56 | A | 54232.213 | . 1 550 | 58 | A | 54232.213 | . 2 530 | 59 | A | 54232.213 | . 3 480 | 61 | A | 54232.213 | . 4 550 | 64 | A | 54232.213 | . 5 550 | 64 | B | 48823.432 | . 6 750 | 66 | B | 48823.432 | . 7 560 | 68 | B | 48823.432 | . 8 800 | 70 | B | 48823.432 | . 9 900 | 65 | B | 48823.432 | . 10 900 | 65 | C | 46823.453 | . 11 910 | 62 | C | 46823.453 | . 12 1100 | 61 | C | 46823.453 | . 13 1250 | 58 | C | 46823.453 | . 14 1350 | 63 | C | 46823.453 | . 15 1350 | 63 | D | 45232.119 | . 16 1500 | 57 | D | 45232.119 | . 17 1660 | 55 | D | 45232.119 | . ggplot(df3)+geom_path(aes(x=&#39;GDP&#39;,y=&#39;Inequality&#39;,colour=&#39;Government&#39;,size=&#39;pop&#39;)) . &lt;ggplot: (132878042227)&gt; . df4=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/gdp_df3.csv&#39;,index_col=0) df4=df4.reset_index().rename(columns={&#39;index&#39;:&#39;Government&#39;}) df4 . Government type . 0 A | prog | . 1 B | cons | . 2 C | prog | . 3 D | cons | . df5=pd.merge(df3,df4,on=&#39;Government&#39;) df5 . GDP Inequality Government pop type . 0 500 | 56 | A | 54232.213 | prog | . 1 550 | 58 | A | 54232.213 | prog | . 2 530 | 59 | A | 54232.213 | prog | . 3 480 | 61 | A | 54232.213 | prog | . 4 550 | 64 | A | 54232.213 | prog | . 5 550 | 64 | B | 48823.432 | cons | . 6 750 | 66 | B | 48823.432 | cons | . 7 560 | 68 | B | 48823.432 | cons | . 8 800 | 70 | B | 48823.432 | cons | . 9 900 | 65 | B | 48823.432 | cons | . 10 900 | 65 | C | 46823.453 | prog | . 11 910 | 62 | C | 46823.453 | prog | . 12 1100 | 61 | C | 46823.453 | prog | . 13 1250 | 58 | C | 46823.453 | prog | . 14 1350 | 63 | C | 46823.453 | prog | . 15 1350 | 63 | D | 45232.119 | cons | . 16 1500 | 57 | D | 45232.119 | cons | . 17 1660 | 55 | D | 45232.119 | cons | . ggplot(df5)+geom_path(aes(x=&#39;GDP&#39;,y=&#39;Inequality&#39;,colour=&#39;Government&#39;,size=&#39;pop&#39;,linetype=&#39;type&#39;)) . &lt;ggplot: (132878090268)&gt; . . 6-4&#48264; . df10=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/phone.csv&#39;) df10 . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 461 | 324 | 136 | 109 | 76 | 81 | 43 | 37 | 135 | 28 | 39 | 14 | 22 | 17 | 20 | 17 | . 1 2019-11 | 461 | 358 | 167 | 141 | 86 | 61 | 29 | 36 | 141 | 27 | 29 | 20 | 23 | 10 | 19 | 27 | . 2 2019-12 | 426 | 383 | 143 | 105 | 53 | 45 | 51 | 48 | 129 | 30 | 20 | 26 | 28 | 18 | 18 | 19 | . 3 2020-01 | 677 | 494 | 212 | 187 | 110 | 79 | 65 | 49 | 158 | 23 | 13 | 19 | 19 | 22 | 27 | 22 | . 4 2020-02 | 593 | 520 | 217 | 195 | 112 | 67 | 62 | 71 | 157 | 25 | 18 | 16 | 24 | 18 | 23 | 20 | . 5 2020-03 | 637 | 537 | 246 | 187 | 92 | 66 | 59 | 67 | 145 | 21 | 16 | 24 | 18 | 31 | 22 | 14 | . 6 2020-04 | 647 | 583 | 222 | 154 | 98 | 59 | 48 | 64 | 113 | 20 | 23 | 25 | 19 | 19 | 23 | 21 | . 7 2020-05 | 629 | 518 | 192 | 176 | 91 | 87 | 50 | 66 | 150 | 43 | 27 | 15 | 18 | 19 | 19 | 13 | . 8 2020-06 | 663 | 552 | 209 | 185 | 93 | 69 | 54 | 60 | 140 | 39 | 16 | 16 | 17 | 29 | 25 | 16 | . 9 2020-07 | 599 | 471 | 214 | 193 | 89 | 78 | 65 | 59 | 130 | 40 | 27 | 25 | 21 | 18 | 18 | 12 | . 10 2020-08 | 615 | 567 | 204 | 182 | 105 | 82 | 62 | 42 | 129 | 47 | 16 | 23 | 21 | 27 | 23 | 20 | . 11 2020-09 | 621 | 481 | 230 | 220 | 102 | 88 | 56 | 49 | 143 | 54 | 14 | 15 | 17 | 15 | 19 | 15 | . 12 2020-10 | 637 | 555 | 232 | 203 | 90 | 52 | 63 | 49 | 140 | 33 | 17 | 20 | 22 | 9 | 22 | 21 | . df11=df10.assign(Date=list(map(lambda x: x[:4], df10[&#39;Date&#39;]))) df11 . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019 | 461 | 324 | 136 | 109 | 76 | 81 | 43 | 37 | 135 | 28 | 39 | 14 | 22 | 17 | 20 | 17 | . 1 2019 | 461 | 358 | 167 | 141 | 86 | 61 | 29 | 36 | 141 | 27 | 29 | 20 | 23 | 10 | 19 | 27 | . 2 2019 | 426 | 383 | 143 | 105 | 53 | 45 | 51 | 48 | 129 | 30 | 20 | 26 | 28 | 18 | 18 | 19 | . 3 2020 | 677 | 494 | 212 | 187 | 110 | 79 | 65 | 49 | 158 | 23 | 13 | 19 | 19 | 22 | 27 | 22 | . 4 2020 | 593 | 520 | 217 | 195 | 112 | 67 | 62 | 71 | 157 | 25 | 18 | 16 | 24 | 18 | 23 | 20 | . 5 2020 | 637 | 537 | 246 | 187 | 92 | 66 | 59 | 67 | 145 | 21 | 16 | 24 | 18 | 31 | 22 | 14 | . 6 2020 | 647 | 583 | 222 | 154 | 98 | 59 | 48 | 64 | 113 | 20 | 23 | 25 | 19 | 19 | 23 | 21 | . 7 2020 | 629 | 518 | 192 | 176 | 91 | 87 | 50 | 66 | 150 | 43 | 27 | 15 | 18 | 19 | 19 | 13 | . 8 2020 | 663 | 552 | 209 | 185 | 93 | 69 | 54 | 60 | 140 | 39 | 16 | 16 | 17 | 29 | 25 | 16 | . 9 2020 | 599 | 471 | 214 | 193 | 89 | 78 | 65 | 59 | 130 | 40 | 27 | 25 | 21 | 18 | 18 | 12 | . 10 2020 | 615 | 567 | 204 | 182 | 105 | 82 | 62 | 42 | 129 | 47 | 16 | 23 | 21 | 27 | 23 | 20 | . 11 2020 | 621 | 481 | 230 | 220 | 102 | 88 | 56 | 49 | 143 | 54 | 14 | 15 | 17 | 15 | 19 | 15 | . 12 2020 | 637 | 555 | 232 | 203 | 90 | 52 | 63 | 49 | 140 | 33 | 17 | 20 | 22 | 9 | 22 | 21 | . df11.groupby(by=&#39;Date&#39;).agg(sum).T.plot.pie(y=&#39;2019&#39;,legend=False) . &lt;AxesSubplot:ylabel=&#39;2019&#39;&gt; . . df11.set_index(&#39;Date&#39;).sum(axis=1).groupby(by=&#39;Date&#39;).agg(np.mean) . Date 2019 1578.666667 2020 2145.800000 dtype: float64 . df11.set_index(&#39;Date&#39;).sum(axis=1).groupby(&#39;Date&#39;).agg(np.mean).plot.bar(x=&#39;Date&#39;) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; .",
            "url": "https://minji219.github.io/zw/2021/12/30/%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC2%EC%B0%A8.html",
            "relUrl": "/2021/12/30/%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC2%EC%B0%A8.html",
            "date": " • Dec 30, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Title",
            "content": "import pandas as pd . df2016=pd.read_csv(&quot;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/stocks_2016.csv&quot;) df2017=pd.read_csv(&quot;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/stocks_2017.csv&quot;) df2018=pd.read_csv(&quot;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/stocks_2018.csv&quot;) . concat은 음 약간 R에서 rbind cbind같은 느낌.. . df2016 . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . df2017 . Symbol Shares Low High . 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . df2018 . Symbol Shares Low High . 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . pd.concat([df2016,df2017,df2018]) #concat으로 합치기 인덱스가 좀 이상하다. . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . pd.concat([df2016,df2017,df2018]).reset_index() #인덱스ㅜ 다시 설정 . index Symbol Shares Low High . 0 0 | AAPL | 80 | 95 | 110 | . 1 1 | TSLA | 50 | 80 | 130 | . 2 2 | WMT | 40 | 55 | 70 | . 3 0 | AAPL | 50 | 120 | 140 | . 4 1 | GE | 100 | 30 | 40 | . 5 2 | IBM | 87 | 75 | 95 | . 6 3 | SLB | 20 | 55 | 85 | . 7 4 | TXN | 500 | 15 | 23 | . 8 5 | TSLA | 100 | 100 | 300 | . 9 0 | AAPL | 40 | 135 | 170 | . 10 1 | AMZN | 8 | 900 | 1125 | . 11 2 | TSLA | 50 | 220 | 400 | . pd.concat([df2016,df2017,df2018]).reset_index(drop=True) #reset_index안에 drop=True설정하여 원래 인덱스 없앰 . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 3 AAPL | 50 | 120 | 140 | . 4 GE | 100 | 30 | 40 | . 5 IBM | 87 | 75 | 95 | . 6 SLB | 20 | 55 | 85 | . 7 TXN | 500 | 15 | 23 | . 8 TSLA | 100 | 100 | 300 | . 9 AAPL | 40 | 135 | 170 | . 10 AMZN | 8 | 900 | 1125 | . 11 TSLA | 50 | 220 | 400 | . R에서 rbind와 유사 . -rbind와의 차이점 : 합치려는 데이터 프레임의 columns가 꼭 동일할필요는 없다. . df2017 . Symbol Shares Low High . 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . df2017.iloc[:,1:] #세로 . Shares Low High . 0 50 | 120 | 140 | . 1 100 | 30 | 40 | . 2 87 | 75 | 95 | . 3 20 | 55 | 85 | . 4 500 | 15 | 23 | . 5 100 | 100 | 300 | . df2017.iloc[1:,:] #가로 . Symbol Shares Low High . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . pd.concat([df2016,df2017.iloc[:,1:]]) #columns가 달라도 상관 없음 걍 nan으로 들어감 . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 0 NaN | 50 | 120 | 140 | . 1 NaN | 100 | 30 | 40 | . 2 NaN | 87 | 75 | 95 | . 3 NaN | 20 | 55 | 85 | . 4 NaN | 500 | 15 | 23 | . 5 NaN | 100 | 100 | 300 | . pd.concat([...],axis=&#39;columns&#39;) . R에서 cbind랑 비슷한 느낌 근데 row의 숫자가 서로 달라도 괜찮은... . df2016 . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . df2017 . Symbol Shares Low High . 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . df2018 . Symbol Shares Low High . 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . pd.concat([df2016,df2017,df2018],axis=&#39;columns&#39;) . Symbol Shares Low High Symbol Shares Low High Symbol Shares Low High . 0 AAPL | 80.0 | 95.0 | 110.0 | AAPL | 50 | 120 | 140 | AAPL | 40.0 | 135.0 | 170.0 | . 1 TSLA | 50.0 | 80.0 | 130.0 | GE | 100 | 30 | 40 | AMZN | 8.0 | 900.0 | 1125.0 | . 2 WMT | 40.0 | 55.0 | 70.0 | IBM | 87 | 75 | 95 | TSLA | 50.0 | 220.0 | 400.0 | . 3 NaN | NaN | NaN | NaN | SLB | 20 | 55 | 85 | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | NaN | TXN | 500 | 15 | 23 | NaN | NaN | NaN | NaN | . 5 NaN | NaN | NaN | NaN | TSLA | 100 | 100 | 300 | NaN | NaN | NaN | NaN | . pd.concat([df2016,df2017,df2018],axis=1) #&#39;columns&#39;를 1로 해도 괜찮 . Symbol Shares Low High Symbol Shares Low High Symbol Shares Low High . 0 AAPL | 80.0 | 95.0 | 110.0 | AAPL | 50 | 120 | 140 | AAPL | 40.0 | 135.0 | 170.0 | . 1 TSLA | 50.0 | 80.0 | 130.0 | GE | 100 | 30 | 40 | AMZN | 8.0 | 900.0 | 1125.0 | . 2 WMT | 40.0 | 55.0 | 70.0 | IBM | 87 | 75 | 95 | TSLA | 50.0 | 220.0 | 400.0 | . 3 NaN | NaN | NaN | NaN | SLB | 20 | 55 | 85 | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | NaN | TXN | 500 | 15 | 23 | NaN | NaN | NaN | NaN | . 5 NaN | NaN | NaN | NaN | TSLA | 100 | 100 | 300 | NaN | NaN | NaN | NaN | . pd.concat([...],keys=[...]) . pd.concat([df2016,df2017,df2018],keys=[2016,2017,2018]) # 인덱스를 나눠줌..? 제목을 붙혀줌...이런맥락 . Symbol Shares Low High . 2016 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2017 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 2018 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . -위의 코드는 아래와 같다. . pd.concat({2016:df2016,2017:df2017,2018:df2018}) . Symbol Shares Low High . 2016 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2017 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 2018 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . pd.concat({df2016:2016,df2017:2017,df2018:2018}) #이건안됨 . TypeError Traceback (most recent call last) &lt;ipython-input-22-69825d7e8ddc&gt; in &lt;module&gt; -&gt; 1 pd.concat({df2016:2016,df2017:2017,df2018:2018}) #이건안됨 ~ anaconda3 lib site-packages pandas core generic.py in __hash__(self) 1783 1784 def __hash__(self) -&gt; int: -&gt; 1785 raise TypeError( 1786 f&#34;{repr(type(self).__name__)} objects are mutable, &#34; 1787 f&#34;thus they cannot be hashed&#34; TypeError: &#39;DataFrame&#39; objects are mutable, thus they cannot be hashed . pd.concat(dict(zip([2016,2017,2018],[df2016,df2017,df2018]))) #zip으로 묶기 . Symbol Shares Low High . 2016 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2017 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 2018 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . -의도하지않았는데 그냥 되는것들.. . pd.concat([df2016,df2017,df2018],keys=[2016,2017]) . Symbol Shares Low High . 2016 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2017 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 그럼걍 2016,2017 꺼만 나옴 . pd.concat([df2016,df2017,df2018],keys=[2017,2018]) #2016꺼가 빠짐 . Symbol Shares Low High . 2017 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2018 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . pd.concat([...],keys=[...],axis=&#39;columns&#39;) . pd.concat([df2016,df2017,df2018],keys=[2016,2017,2018],axis=1) . 2016 2017 2018 . Symbol Shares Low High Symbol Shares Low High Symbol Shares Low High . 0 AAPL | 80.0 | 95.0 | 110.0 | AAPL | 50 | 120 | 140 | AAPL | 40.0 | 135.0 | 170.0 | . 1 TSLA | 50.0 | 80.0 | 130.0 | GE | 100 | 30 | 40 | AMZN | 8.0 | 900.0 | 1125.0 | . 2 WMT | 40.0 | 55.0 | 70.0 | IBM | 87 | 75 | 95 | TSLA | 50.0 | 220.0 | 400.0 | . 3 NaN | NaN | NaN | NaN | SLB | 20 | 55 | 85 | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | NaN | TXN | 500 | 15 | 23 | NaN | NaN | NaN | NaN | . 5 NaN | NaN | NaN | NaN | TSLA | 100 | 100 | 300 | NaN | NaN | NaN | NaN | . pd.concat({2016:df2016,2017:df2017,2018:df2018},axis=1) . 2016 2017 2018 . Symbol Shares Low High Symbol Shares Low High Symbol Shares Low High . 0 AAPL | 80.0 | 95.0 | 110.0 | AAPL | 50 | 120 | 140 | AAPL | 40.0 | 135.0 | 170.0 | . 1 TSLA | 50.0 | 80.0 | 130.0 | GE | 100 | 30 | 40 | AMZN | 8.0 | 900.0 | 1125.0 | . 2 WMT | 40.0 | 55.0 | 70.0 | IBM | 87 | 75 | 95 | TSLA | 50.0 | 220.0 | 400.0 | . 3 NaN | NaN | NaN | NaN | SLB | 20 | 55 | 85 | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | NaN | TXN | 500 | 15 | 23 | NaN | NaN | NaN | NaN | . 5 NaN | NaN | NaN | NaN | TSLA | 100 | 100 | 300 | NaN | NaN | NaN | NaN | . pd.concat(dict(zip([2016,2017,2018],[df2016,df2017,df2018])),axis=1) . 2016 2017 2018 . Symbol Shares Low High Symbol Shares Low High Symbol Shares Low High . 0 AAPL | 80.0 | 95.0 | 110.0 | AAPL | 50 | 120 | 140 | AAPL | 40.0 | 135.0 | 170.0 | . 1 TSLA | 50.0 | 80.0 | 130.0 | GE | 100 | 30 | 40 | AMZN | 8.0 | 900.0 | 1125.0 | . 2 WMT | 40.0 | 55.0 | 70.0 | IBM | 87 | 75 | 95 | TSLA | 50.0 | 220.0 | 400.0 | . 3 NaN | NaN | NaN | NaN | SLB | 20 | 55 | 85 | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | NaN | TXN | 500 | 15 | 23 | NaN | NaN | NaN | NaN | . 5 NaN | NaN | NaN | NaN | TSLA | 100 | 100 | 300 | NaN | NaN | NaN | NaN | . . 타이디하게 바꾸어보기 . df2016 . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . df2016.melt(id_vars=&#39;Symbol&#39;) . Symbol variable value . 0 AAPL | Shares | 80 | . 1 TSLA | Shares | 50 | . 2 WMT | Shares | 40 | . 3 AAPL | Low | 95 | . 4 TSLA | Low | 80 | . 5 WMT | Low | 55 | . 6 AAPL | High | 110 | . 7 TSLA | High | 130 | . 8 WMT | High | 70 | . df2017 . Symbol Shares Low High . 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . df2017.melt(id_vars=&#39;Symbol&#39;) . Symbol variable value . 0 AAPL | Shares | 50 | . 1 GE | Shares | 100 | . 2 IBM | Shares | 87 | . 3 SLB | Shares | 20 | . 4 TXN | Shares | 500 | . 5 TSLA | Shares | 100 | . 6 AAPL | Low | 120 | . 7 GE | Low | 30 | . 8 IBM | Low | 75 | . 9 SLB | Low | 55 | . 10 TXN | Low | 15 | . 11 TSLA | Low | 100 | . 12 AAPL | High | 140 | . 13 GE | High | 40 | . 14 IBM | High | 95 | . 15 SLB | High | 85 | . 16 TXN | High | 23 | . 17 TSLA | High | 300 | . df2018 . Symbol Shares Low High . 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . df2018.melt(id_vars=&#39;Symbol&#39;) . Symbol variable value . 0 AAPL | Shares | 40 | . 1 AMZN | Shares | 8 | . 2 TSLA | Shares | 50 | . 3 AAPL | Low | 135 | . 4 AMZN | Low | 900 | . 5 TSLA | Low | 220 | . 6 AAPL | High | 170 | . 7 AMZN | High | 1125 | . 8 TSLA | High | 400 | . pd.concat([df2016,df2017,df2018]) . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . a=pd.concat([df2016,df2017,df2018]) . a.melt(id_vars=&#39;Symbol&#39;) . Symbol variable value . 0 AAPL | Shares | 80 | . 1 TSLA | Shares | 50 | . 2 WMT | Shares | 40 | . 3 AAPL | Shares | 50 | . 4 GE | Shares | 100 | . 5 IBM | Shares | 87 | . 6 SLB | Shares | 20 | . 7 TXN | Shares | 500 | . 8 TSLA | Shares | 100 | . 9 AAPL | Shares | 40 | . 10 AMZN | Shares | 8 | . 11 TSLA | Shares | 50 | . 12 AAPL | Low | 95 | . 13 TSLA | Low | 80 | . 14 WMT | Low | 55 | . 15 AAPL | Low | 120 | . 16 GE | Low | 30 | . 17 IBM | Low | 75 | . 18 SLB | Low | 55 | . 19 TXN | Low | 15 | . 20 TSLA | Low | 100 | . 21 AAPL | Low | 135 | . 22 AMZN | Low | 900 | . 23 TSLA | Low | 220 | . 24 AAPL | High | 110 | . 25 TSLA | High | 130 | . 26 WMT | High | 70 | . 27 AAPL | High | 140 | . 28 GE | High | 40 | . 29 IBM | High | 95 | . 30 SLB | High | 85 | . 31 TXN | High | 23 | . 32 TSLA | High | 300 | . 33 AAPL | High | 170 | . 34 AMZN | High | 1125 | . 35 TSLA | High | 400 | .",
            "url": "https://minji219.github.io/zw/2021/12/30/concat%EC%97%B0%EC%8A%B5.html",
            "relUrl": "/2021/12/30/concat%EC%97%B0%EC%8A%B5.html",
            "date": " • Dec 30, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "(8주차) 10월27일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/5) group by (1) . - (2/5) group by (2) . - (3/5) pd.cut (1) . - (4/5) pd.cut (2) . - (5/5) 과제설명 . data . import pandas as pd import numpy as np . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv&#39;) . df . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 0 1 | 1 | 4 | WN | LAX | SLC | 1625 | 58.0 | 94.0 | 590 | 1905 | 65.0 | 0 | 0 | . 1 1 | 1 | 4 | UA | DEN | IAD | 823 | 7.0 | 154.0 | 1452 | 1333 | -13.0 | 0 | 0 | . 2 1 | 1 | 4 | MQ | DFW | VPS | 1305 | 36.0 | 85.0 | 641 | 1453 | 35.0 | 0 | 0 | . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 4 1 | 1 | 4 | WN | LAX | MCI | 1720 | 48.0 | 166.0 | 1363 | 2225 | 39.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 58488 12 | 31 | 4 | F9 | LAS | SFO | 1910 | 13.0 | 71.0 | 414 | 2050 | 4.0 | 0 | 0 | . 58489 12 | 31 | 4 | OO | SFO | SBA | 1846 | -6.0 | 46.0 | 262 | 1956 | -5.0 | 0 | 0 | . 58490 12 | 31 | 4 | WN | MSP | ATL | 525 | 39.0 | 124.0 | 907 | 855 | 34.0 | 0 | 0 | . 58491 12 | 31 | 4 | OO | SFO | BOI | 859 | 5.0 | 73.0 | 522 | 1146 | -1.0 | 0 | 0 | . 58492 rows × 14 columns . df.columns . Index([&#39;MONTH&#39;, &#39;DAY&#39;, &#39;WEEKDAY&#39;, &#39;AIRLINE&#39;, &#39;ORG_AIR&#39;, &#39;DEST_AIR&#39;, &#39;SCHED_DEP&#39;, &#39;DEP_DELAY&#39;, &#39;AIR_TIME&#39;, &#39;DIST&#39;, &#39;SCHED_ARR&#39;, &#39;ARR_DELAY&#39;, &#39;DIVERTED&#39;, &#39;CANCELLED&#39;], dtype=&#39;object&#39;) . https://github.com/PacktPublishing/Pandas-Cookbook/blob/master/data/descriptions/flights_description.csv | . groupby . - 데이터프레임을 여러개의 서브데이터프레임으로 나누는 기능 . - 단독으로 쓸 이유는 별로 없다. $ to$ 그룹을 나누고 어떠한 &quot;연산&quot;을 하기 위함 . df.groupby(by=&#39;AIRLINE&#39;) . &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f58ee1d7b20&gt; . 데이터프레임을 각 항공사 별로 나눔 | . - 확인 . grouped_df = df.groupby(by=&#39;AIRLINE&#39;) . grouped_df.groups . {&#39;AA&#39;: [3, 6, 8, 15, 26, 32, 33, 36, 37, 41, 46, 47, 48, 55, 62, 66, 73, 75, 76, 87, 89, 97, 98, 107, 120, 122, 128, 131, 133, 146, 160, 171, 174, 178, 179, 188, 200, 201, 206, 221, 267, 270, 279, 305, 309, 311, 321, 330, 332, 342, 343, 347, 348, 380, 381, 382, 390, 393, 398, 402, 404, 405, 419, 427, 430, 431, 441, 449, 451, 455, 457, 466, 476, 491, 493, 497, 509, 514, 521, 527, 528, 537, 550, 551, 556, 560, 568, 572, 587, 589, 592, 612, 613, 618, 624, 626, 628, 634, 640, 652, ...], &#39;AS&#39;: [38, 198, 241, 277, 397, 450, 453, 500, 518, 591, 718, 737, 741, 808, 820, 867, 872, 1005, 1106, 1146, 1292, 1437, 1530, 1559, 1609, 1636, 1747, 1786, 1810, 1826, 1892, 1921, 2010, 2151, 2269, 2446, 2526, 2576, 2586, 2941, 3112, 3125, 3171, 3176, 3413, 3483, 3494, 3596, 3678, 3734, 3891, 3910, 3937, 3989, 4099, 4128, 4326, 4397, 4432, 4587, 4743, 4799, 4841, 4850, 4912, 4987, 5099, 5154, 5176, 5254, 5261, 5297, 5356, 5372, 5496, 5667, 5685, 5688, 5877, 5976, 6016, 6079, 6122, 6245, 6255, 6393, 6529, 6816, 6824, 6861, 6945, 6988, 7065, 7150, 7153, 7196, 7225, 7235, 7389, 7478, ...], &#39;B6&#39;: [123, 127, 239, 333, 548, 549, 696, 757, 945, 1175, 1361, 1453, 1547, 1561, 1564, 1650, 1670, 1691, 1800, 1939, 1998, 2251, 2253, 2256, 2330, 2385, 2434, 2607, 2650, 2692, 2721, 2781, 2800, 2884, 2936, 3060, 3306, 3648, 3793, 3983, 4347, 4552, 4578, 4639, 4779, 4820, 4885, 5036, 5125, 5131, 5205, 5211, 5228, 5260, 5351, 5483, 5577, 5585, 5777, 5956, 6126, 6151, 6418, 6901, 6952, 6977, 7792, 7798, 7853, 7877, 7904, 8030, 8082, 8091, 8118, 8145, 8177, 8364, 8507, 8541, 8543, 8558, 8732, 8828, 8912, 9093, 9173, 9275, 9371, 9389, 9447, 9482, 9574, 9686, 9896, 10066, 10254, 10416, 10600, 10727, ...], &#39;DL&#39;: [53, 57, 77, 79, 85, 90, 91, 101, 116, 117, 121, 129, 130, 137, 142, 152, 154, 155, 158, 159, 162, 165, 169, 172, 181, 182, 184, 185, 189, 190, 204, 207, 211, 215, 216, 222, 235, 238, 244, 245, 248, 249, 250, 253, 254, 258, 286, 289, 304, 307, 308, 310, 313, 323, 326, 328, 329, 336, 353, 354, 364, 373, 385, 395, 407, 411, 412, 413, 420, 433, 435, 439, 445, 456, 468, 481, 485, 490, 492, 508, 517, 526, 529, 531, 535, 543, 546, 559, 570, 579, 584, 588, 593, 602, 606, 607, 616, 617, 631, 642, ...], &#39;EV&#39;: [11, 13, 29, 40, 69, 100, 106, 118, 136, 143, 147, 164, 167, 170, 194, 196, 199, 205, 208, 219, 220, 225, 231, 233, 236, 251, 252, 261, 264, 265, 268, 282, 291, 293, 298, 312, 319, 337, 352, 362, 363, 369, 371, 383, 403, 414, 415, 424, 429, 437, 442, 443, 459, 460, 465, 470, 495, 499, 503, 505, 506, 522, 525, 530, 541, 567, 574, 580, 583, 632, 645, 654, 659, 677, 683, 689, 693, 695, 697, 714, 721, 723, 725, 730, 740, 742, 761, 764, 765, 768, 772, 776, 777, 778, 785, 787, 790, 791, 794, 799, ...], &#39;F9&#39;: [7, 93, 209, 232, 247, 290, 301, 386, 444, 483, 553, 563, 596, 598, 599, 605, 665, 685, 738, 844, 870, 948, 985, 1103, 1167, 1181, 1264, 1374, 1382, 1407, 1421, 1435, 1489, 1590, 1611, 1697, 1746, 1760, 1775, 1776, 1807, 1830, 1925, 1962, 2014, 2036, 2069, 2078, 2111, 2125, 2208, 2335, 2405, 2515, 2557, 2579, 2600, 2683, 2693, 2708, 2731, 2733, 2805, 2853, 2861, 3024, 3241, 3288, 3374, 3382, 3395, 3418, 3555, 3570, 3575, 3628, 3638, 3716, 3735, 3777, 3843, 3923, 3962, 3977, 4016, 4031, 4046, 4069, 4111, 4151, 4172, 4287, 4356, 4371, 4420, 4469, 4542, 4641, 4671, 4720, ...], &#39;HA&#39;: [582, 712, 878, 1053, 1269, 1345, 1544, 1864, 2316, 2644, 2681, 3002, 3165, 3227, 4359, 4414, 4926, 5187, 5281, 5320, 5363, 7267, 7372, 7744, 7808, 9360, 9761, 10163, 11119, 11626, 11743, 11809, 12275, 12752, 12780, 13466, 13755, 13956, 14566, 15064, 15316, 15959, 16501, 17632, 18467, 18720, 20461, 21558, 21761, 22454, 22584, 22592, 22618, 22858, 22892, 23177, 23374, 23773, 25763, 26127, 27745, 28864, 29608, 29762, 29875, 30610, 31164, 31505, 31530, 31675, 32030, 32037, 32987, 33311, 33747, 34884, 35959, 36068, 36319, 36425, 37119, 37128, 37664, 37983, 38440, 39475, 39482, 39625, 41664, 42165, 42485, 42846, 44068, 45330, 46713, 47772, 48279, 48722, 49667, 49782, ...], &#39;MQ&#39;: [2, 10, 18, 24, 50, 60, 71, 78, 81, 103, 105, 115, 125, 149, 180, 187, 210, 214, 228, 285, 296, 314, 320, 334, 335, 339, 341, 357, 458, 472, 484, 486, 488, 502, 516, 524, 534, 547, 581, 601, 622, 638, 639, 646, 661, 707, 711, 722, 727, 751, 769, 774, 802, 805, 830, 851, 854, 856, 865, 876, 915, 939, 955, 968, 977, 980, 1002, 1006, 1036, 1085, 1087, 1104, 1113, 1150, 1158, 1163, 1168, 1169, 1204, 1229, 1231, 1234, 1238, 1246, 1287, 1296, 1303, 1306, 1328, 1329, 1336, 1393, 1398, 1410, 1423, 1428, 1436, 1448, 1449, 1454, ...], &#39;NK&#39;: [17, 74, 95, 109, 166, 345, 358, 401, 434, 436, 446, 452, 482, 507, 510, 519, 533, 544, 610, 615, 620, 729, 735, 845, 858, 887, 898, 916, 970, 1017, 1095, 1097, 1153, 1188, 1208, 1257, 1342, 1392, 1536, 1579, 1580, 1657, 1732, 1761, 1863, 1943, 1948, 1990, 2026, 2068, 2071, 2118, 2124, 2149, 2177, 2196, 2214, 2244, 2299, 2334, 2378, 2424, 2425, 2447, 2523, 2537, 2592, 2613, 2639, 2643, 2740, 2749, 2752, 2764, 2765, 2770, 2786, 2875, 2886, 3018, 3061, 3065, 3072, 3151, 3153, 3174, 3248, 3315, 3381, 3435, 3566, 3598, 3674, 3696, 3701, 3708, 3840, 3877, 3894, 3934, ...], &#39;OO&#39;: [12, 16, 22, 25, 27, 34, 39, 42, 51, 52, 54, 58, 61, 63, 65, 82, 86, 99, 102, 113, 124, 126, 135, 138, 139, 151, 157, 161, 168, 175, 213, 223, 237, 240, 242, 255, 257, 278, 281, 284, 288, 297, 315, 317, 318, 322, 324, 327, 331, 359, 361, 366, 367, 370, 376, 378, 379, 387, 392, 418, 421, 447, 448, 540, 552, 554, 565, 569, 576, 590, 600, 603, 604, 609, 625, 629, 637, 649, 653, 658, 660, 663, 666, 671, 672, 673, 676, 679, 681, 682, 684, 691, 692, 708, 734, 754, 755, 762, 789, 793, ...], &#39;UA&#39;: [1, 5, 9, 14, 21, 44, 45, 67, 70, 72, 94, 108, 110, 134, 140, 141, 144, 145, 163, 177, 183, 192, 197, 246, 260, 262, 263, 266, 269, 273, 275, 283, 295, 325, 338, 340, 349, 368, 374, 375, 377, 389, 394, 396, 408, 423, 425, 438, 440, 462, 463, 469, 471, 474, 479, 501, 511, 512, 513, 520, 523, 536, 539, 542, 555, 557, 566, 573, 577, 586, 594, 595, 608, 621, 623, 630, 635, 636, 647, 650, 651, 667, 686, 687, 698, 699, 700, 701, 713, 717, 719, 745, 756, 773, 784, 801, 829, 836, 842, 843, ...], &#39;US&#39;: [31, 35, 49, 96, 104, 111, 112, 119, 148, 150, 153, 191, 202, 203, 224, 229, 355, 360, 372, 384, 391, 467, 473, 477, 478, 487, 494, 538, 545, 558, 561, 564, 575, 578, 619, 690, 715, 726, 728, 760, 795, 806, 881, 896, 901, 910, 954, 1028, 1033, 1068, 1134, 1135, 1143, 1155, 1164, 1201, 1210, 1245, 1274, 1288, 1290, 1291, 1335, 1355, 1377, 1399, 1406, 1446, 1459, 1462, 1470, 1471, 1476, 1481, 1493, 1499, 1503, 1552, 1554, 1565, 1589, 1593, 1603, 1661, 1680, 1716, 1731, 1733, 1735, 1743, 1749, 1754, 1755, 1758, 1767, 1773, 1790, 1821, 1904, 1905, ...], &#39;VX&#39;: [56, 227, 243, 417, 432, 464, 614, 641, 703, 759, 812, 825, 943, 1058, 1092, 1093, 1192, 1302, 1312, 1343, 1369, 1452, 1586, 1599, 1644, 1696, 1705, 1805, 1930, 1957, 2048, 2219, 2220, 2270, 2302, 2324, 2484, 2572, 2620, 2646, 2735, 2753, 2808, 2880, 2898, 2919, 3110, 3111, 3120, 3210, 3246, 3261, 3302, 3427, 3501, 3510, 3664, 3680, 3694, 3731, 3860, 3938, 3968, 4005, 4029, 4035, 4056, 4088, 4270, 4351, 4531, 4536, 4540, 4692, 4712, 4728, 4746, 4825, 4856, 4860, 4869, 4876, 4890, 4901, 4928, 4994, 5075, 5078, 5115, 5143, 5167, 5206, 5245, 5265, 5379, 5383, 5413, 5502, 5512, 5522, ...], &#39;WN&#39;: [0, 4, 19, 20, 23, 28, 30, 43, 59, 64, 68, 80, 83, 84, 88, 92, 114, 132, 156, 173, 176, 186, 193, 195, 212, 217, 218, 226, 230, 234, 256, 259, 271, 272, 274, 276, 280, 287, 292, 294, 299, 300, 302, 303, 306, 316, 344, 346, 350, 351, 356, 365, 388, 399, 400, 406, 409, 410, 416, 422, 426, 428, 454, 461, 475, 480, 489, 496, 498, 504, 515, 532, 562, 571, 585, 597, 611, 627, 633, 648, 657, 669, 670, 674, 678, 710, 720, 724, 731, 744, 747, 752, 753, 788, 797, 804, 807, 813, 815, 817, ...]} . 너무 보기 힘듬 | . - 보기좋은 형태로 확인 . list(grouped_df.groups) . [&#39;AA&#39;, &#39;AS&#39;, &#39;B6&#39;, &#39;DL&#39;, &#39;EV&#39;, &#39;F9&#39;, &#39;HA&#39;, &#39;MQ&#39;, &#39;NK&#39;, &#39;OO&#39;, &#39;UA&#39;, &#39;US&#39;, &#39;VX&#39;, &#39;WN&#39;] . grouped_df.get_group(&#39;AA&#39;) . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 6 1 | 1 | 4 | AA | DFW | MSY | 1250 | 84.0 | 64.0 | 447 | 1410 | 83.0 | 0 | 0 | . 8 1 | 1 | 4 | AA | ORD | STL | 1845 | -5.0 | 44.0 | 258 | 1950 | -5.0 | 0 | 0 | . 15 1 | 1 | 4 | AA | DEN | DFW | 1445 | -6.0 | 93.0 | 641 | 1745 | 4.0 | 0 | 0 | . 26 1 | 1 | 4 | AA | LAX | AUS | 1430 | 33.0 | 157.0 | 1242 | 1925 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58470 12 | 31 | 4 | AA | DFW | FAT | 1020 | -3.0 | 196.0 | 1313 | 1156 | -2.0 | 0 | 0 | . 58475 12 | 31 | 4 | AA | IAH | CLT | 710 | 1.0 | 113.0 | 912 | 1037 | -12.0 | 0 | 0 | . 58476 12 | 31 | 4 | AA | DFW | TPA | 1020 | -3.0 | 121.0 | 929 | 1340 | -6.0 | 0 | 0 | . 58479 12 | 31 | 4 | AA | DFW | ELP | 1200 | 3.0 | 94.0 | 551 | 1250 | 13.0 | 0 | 0 | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 8900 rows × 14 columns . for g in grouped_df.groups: print(g) display(grouped_df.get_group(g)) . AA . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 6 1 | 1 | 4 | AA | DFW | MSY | 1250 | 84.0 | 64.0 | 447 | 1410 | 83.0 | 0 | 0 | . 8 1 | 1 | 4 | AA | ORD | STL | 1845 | -5.0 | 44.0 | 258 | 1950 | -5.0 | 0 | 0 | . 15 1 | 1 | 4 | AA | DEN | DFW | 1445 | -6.0 | 93.0 | 641 | 1745 | 4.0 | 0 | 0 | . 26 1 | 1 | 4 | AA | LAX | AUS | 1430 | 33.0 | 157.0 | 1242 | 1925 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58470 12 | 31 | 4 | AA | DFW | FAT | 1020 | -3.0 | 196.0 | 1313 | 1156 | -2.0 | 0 | 0 | . 58475 12 | 31 | 4 | AA | IAH | CLT | 710 | 1.0 | 113.0 | 912 | 1037 | -12.0 | 0 | 0 | . 58476 12 | 31 | 4 | AA | DFW | TPA | 1020 | -3.0 | 121.0 | 929 | 1340 | -6.0 | 0 | 0 | . 58479 12 | 31 | 4 | AA | DFW | ELP | 1200 | 3.0 | 94.0 | 551 | 1250 | 13.0 | 0 | 0 | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 8900 rows × 14 columns . AS . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 38 1 | 1 | 4 | AS | PHX | SEA | 1505 | -2.0 | 155.0 | 1107 | 1702 | -3.0 | 0 | 0 | . 198 1 | 2 | 5 | AS | LAX | SEA | 2110 | 5.0 | 145.0 | 954 | 2352 | 8.0 | 0 | 0 | . 241 1 | 2 | 5 | AS | LAS | PDX | 650 | -5.0 | 117.0 | 763 | 906 | -3.0 | 0 | 0 | . 277 1 | 2 | 5 | AS | ORD | ANC | 935 | -1.0 | 402.0 | 2846 | 1339 | -6.0 | 0 | 0 | . 397 1 | 3 | 6 | AS | LAS | SEA | 1300 | 48.0 | 137.0 | 867 | 1535 | 47.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58305 12 | 30 | 3 | AS | LAX | SEA | 1325 | -2.0 | 134.0 | 954 | 1608 | -7.0 | 0 | 0 | . 58355 12 | 31 | 4 | AS | PHX | SEA | 1200 | -5.0 | 145.0 | 1107 | 1407 | -24.0 | 0 | 0 | . 58404 12 | 31 | 4 | AS | SFO | SLC | 2110 | -2.0 | 80.0 | 599 | 2358 | -4.0 | 0 | 0 | . 58407 12 | 31 | 4 | AS | SFO | PDX | 645 | -2.0 | 81.0 | 550 | 832 | -3.0 | 0 | 0 | . 58428 12 | 31 | 4 | AS | LAX | SEA | 1420 | -8.0 | 127.0 | 954 | 1709 | -25.0 | 0 | 0 | . 768 rows × 14 columns . B6 . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 123 1 | 1 | 4 | B6 | LAS | BOS | 1230 | 0.0 | 246.0 | 2381 | 2026 | -27.0 | 0 | 0 | . 127 1 | 1 | 4 | B6 | LAS | BOS | 2359 | 68.0 | 247.0 | 2381 | 749 | 46.0 | 0 | 0 | . 239 1 | 2 | 5 | B6 | ORD | BOS | 540 | -8.0 | 96.0 | 867 | 856 | -22.0 | 0 | 0 | . 333 1 | 3 | 6 | B6 | LAX | FLL | 2237 | 32.0 | 270.0 | 2342 | 619 | 42.0 | 0 | 0 | . 548 1 | 4 | 7 | B6 | SFO | FLL | 2307 | -4.0 | 298.0 | 2583 | 724 | -1.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58262 12 | 30 | 3 | B6 | SFO | LGB | 1921 | -6.0 | 57.0 | 354 | 2038 | -14.0 | 0 | 0 | . 58301 12 | 30 | 3 | B6 | LAX | JFK | 630 | 4.0 | 285.0 | 2475 | 1445 | -6.0 | 0 | 0 | . 58425 12 | 31 | 4 | B6 | ORD | SJU | 700 | 239.0 | 250.0 | 2072 | 1335 | 239.0 | 0 | 0 | . 58477 12 | 31 | 4 | B6 | DFW | BOS | 1145 | 12.0 | 161.0 | 1562 | 1608 | -14.0 | 0 | 0 | . 58483 12 | 31 | 4 | B6 | PHX | BOS | 2236 | -12.0 | 231.0 | 2300 | 515 | -45.0 | 0 | 0 | . 543 rows × 14 columns . DL . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 53 1 | 1 | 4 | DL | LAS | MSP | 713 | -5.0 | 156.0 | 1299 | 1220 | -18.0 | 0 | 0 | . 57 1 | 1 | 4 | DL | MSP | RSW | 700 | -1.0 | 169.0 | 1416 | 1130 | -20.0 | 0 | 0 | . 77 1 | 1 | 4 | DL | LAX | ATL | 1130 | 24.0 | 217.0 | 1947 | 1840 | 16.0 | 0 | 0 | . 79 1 | 1 | 4 | DL | LAX | CMH | 2146 | -3.0 | 223.0 | 1995 | 459 | -13.0 | 0 | 0 | . 85 1 | 1 | 4 | DL | ATL | OKC | 2059 | -4.0 | 116.0 | 761 | 2227 | -12.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58440 12 | 31 | 4 | DL | ATL | CVG | 1611 | -4.0 | 61.0 | 373 | 1736 | -6.0 | 0 | 0 | . 58448 12 | 31 | 4 | DL | ATL | SRQ | 1610 | 0.0 | 61.0 | 444 | 1740 | -13.0 | 0 | 0 | . 58464 12 | 31 | 4 | DL | LAX | SFO | 700 | 108.0 | 54.0 | 337 | 825 | 105.0 | 0 | 0 | . 58467 12 | 31 | 4 | DL | ATL | IND | 1235 | -3.0 | 63.0 | 432 | 1407 | -13.0 | 0 | 0 | . 58485 12 | 31 | 4 | DL | ATL | CMH | 2206 | 2.0 | 64.0 | 447 | 2338 | -8.0 | 0 | 0 | . 10601 rows × 14 columns . EV . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 11 1 | 1 | 4 | EV | ORD | JAN | 1155 | 6.0 | 113.0 | 677 | 1403 | 5.0 | 0 | 0 | . 13 1 | 1 | 4 | EV | ORD | CMH | 1010 | -2.0 | 46.0 | 296 | 1228 | -9.0 | 0 | 0 | . 29 1 | 1 | 4 | EV | ORD | IND | 1025 | -6.0 | 29.0 | 177 | 1228 | -19.0 | 0 | 0 | . 40 1 | 1 | 4 | EV | IAH | CLE | 1038 | -3.0 | 126.0 | 1091 | 1425 | -18.0 | 0 | 0 | . 69 1 | 1 | 4 | EV | ATL | RAP | 1930 | -5.0 | 181.0 | 1230 | 2104 | -15.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58445 12 | 31 | 4 | EV | DFW | TXK | 850 | -5.0 | 30.0 | 181 | 948 | -17.0 | 0 | 0 | . 58452 12 | 31 | 4 | EV | DFW | SHV | 1650 | -4.0 | 32.0 | 190 | 1746 | -12.0 | 0 | 0 | . 58459 12 | 31 | 4 | EV | MSP | ORD | 1435 | 18.0 | 61.0 | 334 | 1609 | 3.0 | 0 | 0 | . 58463 12 | 31 | 4 | EV | ORD | MSN | 1220 | 18.0 | 32.0 | 108 | 1319 | 27.0 | 0 | 0 | . 58486 12 | 31 | 4 | EV | DFW | LFT | 850 | 21.0 | 52.0 | 351 | 1012 | 14.0 | 0 | 0 | . 5858 rows × 14 columns . F9 . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 7 1 | 1 | 4 | F9 | SFO | PHX | 1020 | -7.0 | 91.0 | 651 | 1315 | -6.0 | 0 | 0 | . 93 1 | 1 | 4 | F9 | ATL | DEN | 859 | 16.0 | 181.0 | 1199 | 1026 | 10.0 | 0 | 0 | . 209 1 | 2 | 5 | F9 | MSP | DEN | 1025 | -6.0 | 97.0 | 680 | 1134 | -13.0 | 0 | 0 | . 232 1 | 2 | 5 | F9 | DEN | PHX | 2040 | -7.0 | 83.0 | 602 | 2228 | -18.0 | 0 | 0 | . 247 1 | 2 | 5 | F9 | ORD | ATL | 730 | 10.0 | 86.0 | 606 | 1020 | 23.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58288 12 | 30 | 3 | F9 | DEN | ORD | 625 | -4.0 | 136.0 | 888 | 1000 | 14.0 | 0 | 0 | . 58331 12 | 30 | 3 | F9 | ORD | PHX | 825 | 18.0 | 207.0 | 1440 | 1127 | 14.0 | 0 | 0 | . 58447 12 | 31 | 4 | F9 | DEN | LAS | 1245 | 13.0 | 94.0 | 628 | 1340 | 13.0 | 0 | 0 | . 58449 12 | 31 | 4 | F9 | DEN | MCO | 645 | 11.0 | 169.0 | 1546 | 1224 | -11.0 | 0 | 0 | . 58488 12 | 31 | 4 | F9 | LAS | SFO | 1910 | 13.0 | 71.0 | 414 | 2050 | 4.0 | 0 | 0 | . 1317 rows × 14 columns . HA . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 582 1 | 4 | 7 | HA | LAX | OGG | 1115 | -11.0 | 310.0 | 2486 | 1500 | -27.0 | 0 | 0 | . 712 1 | 5 | 1 | HA | LAS | HNL | 900 | -5.0 | 357.0 | 2762 | 1315 | 5.0 | 0 | 0 | . 878 1 | 6 | 2 | HA | PHX | HNL | 800 | 1.0 | 374.0 | 2917 | 1140 | 3.0 | 0 | 0 | . 1053 1 | 7 | 3 | HA | LAX | HNL | 1705 | 0.0 | 332.0 | 2556 | 2055 | -2.0 | 0 | 0 | . 1269 1 | 8 | 4 | HA | LAX | HNL | 1000 | -1.0 | 335.0 | 2556 | 1350 | 0.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 55883 12 | 16 | 3 | HA | LAX | HNL | 835 | 1.0 | 314.0 | 2556 | 1235 | -18.0 | 0 | 0 | . 56174 12 | 18 | 5 | HA | LAX | HNL | 835 | -5.0 | 342.0 | 2556 | 1235 | -4.0 | 0 | 0 | . 56350 12 | 19 | 6 | HA | PHX | HNL | 800 | -5.0 | 363.0 | 2917 | 1155 | -34.0 | 0 | 0 | . 56816 12 | 21 | 1 | HA | LAX | LIH | 740 | 20.0 | 303.0 | 2615 | 1145 | -11.0 | 0 | 0 | . 58391 12 | 31 | 4 | HA | LAX | HNL | 1000 | 0.0 | 324.0 | 2556 | 1350 | -9.0 | 0 | 0 | . 112 rows × 14 columns . MQ . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 2 1 | 1 | 4 | MQ | DFW | VPS | 1305 | 36.0 | 85.0 | 641 | 1453 | 35.0 | 0 | 0 | . 10 1 | 1 | 4 | MQ | DFW | DRO | 1335 | 28.0 | 104.0 | 674 | 1438 | 28.0 | 0 | 0 | . 18 1 | 1 | 4 | MQ | ORD | DAY | 2220 | 19.0 | 37.0 | 240 | 23 | 20.0 | 0 | 0 | . 24 1 | 1 | 4 | MQ | DFW | BTR | 730 | NaN | NaN | 383 | 853 | NaN | 0 | 1 | . 50 1 | 1 | 4 | MQ | ORD | CID | 1135 | -7.0 | 37.0 | 196 | 1238 | -15.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58415 12 | 31 | 4 | MQ | ORD | FWA | 845 | -2.0 | 37.0 | 157 | 1045 | -4.0 | 0 | 0 | . 58426 12 | 31 | 4 | MQ | DFW | FAR | 1154 | 4.0 | 124.0 | 968 | 1437 | -13.0 | 0 | 0 | . 58468 12 | 31 | 4 | MQ | DFW | OKC | 1720 | -3.0 | 31.0 | 175 | 1819 | -10.0 | 0 | 0 | . 58474 12 | 31 | 4 | MQ | ORD | FNT | 829 | 4.0 | 40.0 | 223 | 1034 | -4.0 | 0 | 0 | . 58484 12 | 31 | 4 | MQ | ORD | DSM | 1333 | 1.0 | 57.0 | 299 | 1455 | -7.0 | 0 | 0 | . 3471 rows × 14 columns . NK . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 17 1 | 1 | 4 | NK | DEN | DTW | 1952 | 37.0 | 124.0 | 1123 | 31 | 54.0 | 0 | 0 | . 74 1 | 1 | 4 | NK | PHX | DFW | 159 | -1.0 | 103.0 | 868 | 502 | 1.0 | 0 | 0 | . 95 1 | 1 | 4 | NK | LAS | OAK | 1115 | 22.0 | 62.0 | 407 | 1246 | 10.0 | 0 | 0 | . 109 1 | 1 | 4 | NK | MSP | ORD | 616 | 2.0 | 49.0 | 334 | 745 | -19.0 | 0 | 0 | . 166 1 | 2 | 5 | NK | LAS | PDX | 1535 | -8.0 | 123.0 | 763 | 1754 | -4.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58160 12 | 29 | 2 | NK | MSP | MCO | 740 | 0.0 | 171.0 | 1310 | 1158 | 33.0 | 0 | 0 | . 58197 12 | 30 | 3 | NK | IAH | ORD | 755 | -8.0 | 136.0 | 925 | 1030 | -2.0 | 0 | 0 | . 58437 12 | 31 | 4 | NK | ORD | DFW | 1952 | 15.0 | 135.0 | 802 | 2225 | 23.0 | 0 | 0 | . 58461 12 | 31 | 4 | NK | ORD | LGA | 1801 | -5.0 | 84.0 | 733 | 2109 | -26.0 | 0 | 0 | . 58469 12 | 31 | 4 | NK | LAS | MSY | 1950 | 124.0 | 163.0 | 1500 | 112 | 101.0 | 0 | 0 | . 1516 rows × 14 columns . OO . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 12 1 | 1 | 4 | OO | ORD | MSP | 1510 | 2.0 | 65.0 | 334 | 1646 | 4.0 | 0 | 0 | . 16 1 | 1 | 4 | OO | DEN | SGU | 1105 | 21.0 | 66.0 | 517 | 1249 | 20.0 | 0 | 0 | . 22 1 | 1 | 4 | OO | LAS | LAX | 1544 | -4.0 | 39.0 | 236 | 1655 | -12.0 | 0 | 0 | . 25 1 | 1 | 4 | OO | ORD | SPI | 2110 | -4.0 | 31.0 | 174 | 2205 | 5.0 | 0 | 0 | . 27 1 | 1 | 4 | OO | IAH | JAC | 1104 | -1.0 | 161.0 | 1265 | 1316 | -1.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58451 12 | 31 | 4 | OO | ATL | FWA | 1905 | -3.0 | 72.0 | 508 | 2051 | -14.0 | 0 | 0 | . 58480 12 | 31 | 4 | OO | MSP | BIS | 1310 | -2.0 | 65.0 | 386 | 1449 | -9.0 | 0 | 0 | . 58482 12 | 31 | 4 | OO | DEN | CPR | 1850 | -2.0 | 38.0 | 230 | 1956 | 1.0 | 0 | 0 | . 58489 12 | 31 | 4 | OO | SFO | SBA | 1846 | -6.0 | 46.0 | 262 | 1956 | -5.0 | 0 | 0 | . 58491 12 | 31 | 4 | OO | SFO | BOI | 859 | 5.0 | 73.0 | 522 | 1146 | -1.0 | 0 | 0 | . 6588 rows × 14 columns . UA . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 1 1 | 1 | 4 | UA | DEN | IAD | 823 | 7.0 | 154.0 | 1452 | 1333 | -13.0 | 0 | 0 | . 5 1 | 1 | 4 | UA | IAH | SAN | 1450 | 1.0 | 178.0 | 1303 | 1620 | -14.0 | 0 | 0 | . 9 1 | 1 | 4 | UA | IAH | SJC | 925 | 3.0 | 215.0 | 1608 | 1136 | -14.0 | 0 | 0 | . 14 1 | 1 | 4 | UA | IAH | IND | 1426 | -1.0 | 102.0 | 844 | 1742 | -20.0 | 0 | 0 | . 21 1 | 1 | 4 | UA | ORD | CLE | 2102 | 48.0 | 47.0 | 315 | 2320 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58422 12 | 31 | 4 | UA | DEN | SAN | 1535 | 0.0 | 124.0 | 853 | 1704 | -13.0 | 0 | 0 | . 58432 12 | 31 | 4 | UA | ORD | SAN | 1915 | 7.0 | 238.0 | 1723 | 2143 | -3.0 | 0 | 0 | . 58457 12 | 31 | 4 | UA | ORD | LAX | 659 | -1.0 | 241.0 | 1744 | 946 | 0.0 | 0 | 0 | . 58460 12 | 31 | 4 | UA | SFO | PHL | 2235 | -6.0 | 265.0 | 2521 | 700 | -42.0 | 0 | 0 | . 58481 12 | 31 | 4 | UA | IAH | LAX | 1433 | 1.0 | 197.0 | 1379 | 1625 | -13.0 | 0 | 0 | . 7792 rows × 14 columns . US . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 31 1 | 1 | 4 | US | PHX | DEN | 1810 | 29.0 | 94.0 | 602 | 1954 | 49.0 | 0 | 0 | . 35 1 | 1 | 4 | US | ORD | PHL | 1600 | -2.0 | 80.0 | 678 | 1857 | -9.0 | 0 | 0 | . 49 1 | 1 | 4 | US | IAH | PHX | 1445 | -1.0 | 147.0 | 1009 | 1638 | -7.0 | 0 | 0 | . 96 1 | 1 | 4 | US | ATL | PHL | 1445 | -4.0 | 90.0 | 666 | 1644 | -11.0 | 0 | 0 | . 104 1 | 1 | 4 | US | MSP | PHX | 730 | -3.0 | 174.0 | 1276 | 1010 | -20.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 31514 6 | 30 | 2 | US | DEN | PHL | 705 | -4.0 | 188.0 | 1558 | 1240 | 1.0 | 0 | 0 | . 31523 6 | 30 | 2 | US | PHX | DEN | 1451 | 6.0 | 85.0 | 602 | 1738 | 7.0 | 0 | 0 | . 31535 6 | 30 | 2 | US | PHX | AUS | 840 | -3.0 | 116.0 | 872 | 1304 | -11.0 | 0 | 0 | . 31561 6 | 30 | 2 | US | ORD | PHX | 710 | -5.0 | 170.0 | 1440 | 901 | -50.0 | 0 | 0 | . 31582 6 | 30 | 2 | US | PHX | OGG | 800 | -4.0 | 356.0 | 2845 | 1127 | -13.0 | 0 | 0 | . 1615 rows × 14 columns . VX . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 56 1 | 1 | 4 | VX | LAS | SFO | 900 | 23.0 | 65.0 | 414 | 1035 | 11.0 | 0 | 0 | . 227 1 | 2 | 5 | VX | SFO | LAS | 1220 | -5.0 | 68.0 | 414 | 1350 | -5.0 | 0 | 0 | . 243 1 | 2 | 5 | VX | SFO | SEA | 700 | -4.0 | 104.0 | 679 | 905 | -1.0 | 0 | 0 | . 417 1 | 3 | 6 | VX | SFO | LAS | 900 | -2.0 | 62.0 | 414 | 1030 | -11.0 | 0 | 0 | . 432 1 | 3 | 6 | VX | SFO | SEA | 2035 | -2.0 | 106.0 | 679 | 2240 | -2.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58332 12 | 30 | 3 | VX | SFO | LAS | 1950 | -3.0 | 58.0 | 414 | 2120 | -4.0 | 0 | 0 | . 58383 12 | 31 | 4 | VX | SFO | PSP | 1630 | -7.0 | 65.0 | 421 | 1755 | -12.0 | 0 | 0 | . 58400 12 | 31 | 4 | VX | SFO | LAX | 1125 | -4.0 | 54.0 | 337 | 1245 | -10.0 | 0 | 0 | . 58471 12 | 31 | 4 | VX | SFO | LAX | 700 | 6.0 | 51.0 | 337 | 820 | 3.0 | 0 | 0 | . 58478 12 | 31 | 4 | VX | SFO | LAX | 1530 | 29.0 | 52.0 | 337 | 1650 | 22.0 | 0 | 0 | . 993 rows × 14 columns . WN . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 0 1 | 1 | 4 | WN | LAX | SLC | 1625 | 58.0 | 94.0 | 590 | 1905 | 65.0 | 0 | 0 | . 4 1 | 1 | 4 | WN | LAX | MCI | 1720 | 48.0 | 166.0 | 1363 | 2225 | 39.0 | 0 | 0 | . 19 1 | 1 | 4 | WN | PHX | LAX | 1640 | 51.0 | 58.0 | 370 | 1700 | 59.0 | 0 | 0 | . 20 1 | 1 | 4 | WN | ATL | BWI | 1115 | 1.0 | 76.0 | 577 | 1305 | -15.0 | 0 | 0 | . 23 1 | 1 | 4 | WN | ATL | HOU | 1555 | 30.0 | 113.0 | 696 | 1720 | 18.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58455 12 | 31 | 4 | WN | LAX | SMF | 1420 | -2.0 | 64.0 | 373 | 1540 | -7.0 | 0 | 0 | . 58458 12 | 31 | 4 | WN | LAS | SFO | 1825 | 25.0 | 67.0 | 414 | 1955 | 17.0 | 0 | 0 | . 58472 12 | 31 | 4 | WN | PHX | HOU | 845 | 5.0 | 119.0 | 1020 | 1210 | 7.0 | 0 | 0 | . 58473 12 | 31 | 4 | WN | DEN | PDX | 1205 | 4.0 | 130.0 | 991 | 1400 | -13.0 | 0 | 0 | . 58490 12 | 31 | 4 | WN | MSP | ATL | 525 | 39.0 | 124.0 | 907 | 855 | 34.0 | 0 | 0 | . 8418 rows × 14 columns . AIRLINE&#51012; &#44592;&#51456;&#51004;&#47196; &#45936;&#51060;&#53552;&#54532;&#47112;&#51076;&#51012; &#45208;&#45572;&#44256; $ to$ ARR_DELAY&#50640; mean&#54632;&#49688;&#47484; &#51201;&#50857;: (AIRLINE $ to$ {ARR_DELAY: mean}) . - 방법1 . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:&#39;mean&#39;}) . ARR_DELAY . AIRLINE . AA 5.542661 | . AS -0.833333 | . B6 8.692593 | . DL 0.339691 | . EV 7.034580 | . F9 13.630651 | . HA 4.972973 | . MQ 6.860591 | . NK 18.436070 | . OO 7.593463 | . UA 7.765755 | . US 1.681105 | . VX 5.348884 | . WN 6.397353 | . - 방법2 ($ star star star$) . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:np.mean}) . ARR_DELAY . AIRLINE . AA 5.542661 | . AS -0.833333 | . B6 8.692593 | . DL 0.339691 | . EV 7.034580 | . F9 13.630651 | . HA 4.972973 | . MQ 6.860591 | . NK 18.436070 | . OO 7.593463 | . UA 7.765755 | . US 1.681105 | . VX 5.348884 | . WN 6.397353 | . - 방법3 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(&#39;mean&#39;) . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . - 방법4 ($ star$) . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(np.mean) . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . - 방법5 . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].mean() . AIRLINE AA 5.542661 AS -0.833333 B6 8.692593 DL 0.339691 EV 7.034580 F9 13.630651 HA 4.972973 MQ 6.860591 NK 18.436070 OO 7.593463 UA 7.765755 US 1.681105 VX 5.348884 WN 6.397353 Name: ARR_DELAY, dtype: float64 . - 방법2와 방법4는 사용자정의 함수를 쓸 수 있다는 장점이 있음 . def f(x): return -np.mean(x) . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:f}) . ARR_DELAY . AIRLINE . AA -5.542661 | . AS 0.833333 | . B6 -8.692593 | . DL -0.339691 | . EV -7.034580 | . F9 -13.630651 | . HA -4.972973 | . MQ -6.860591 | . NK -18.436070 | . OO -7.593463 | . UA -7.765755 | . US -1.681105 | . VX -5.348884 | . WN -6.397353 | . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:lambda x: -np.mean(x)}) . ARR_DELAY . AIRLINE . AA -5.542661 | . AS 0.833333 | . B6 -8.692593 | . DL -0.339691 | . EV -7.034580 | . F9 -13.630651 | . HA -4.972973 | . MQ -6.860591 | . NK -18.436070 | . OO -7.593463 | . UA -7.765755 | . US -1.681105 | . VX -5.348884 | . WN -6.397353 | . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(lambda x: -np.mean(x)) . AIRLINE AA -5.542661 AS 0.833333 B6 -8.692593 DL -0.339691 EV -7.034580 F9 -13.630651 HA -4.972973 MQ -6.860591 NK -18.436070 OO -7.593463 UA -7.765755 US -1.681105 VX -5.348884 WN -6.397353 Name: ARR_DELAY, dtype: float64 . - 입력이 여러개인 사용자 정의 함수도 사용가능함 . def f(x,y): return np.mean(x)**y . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(f,2) . AIRLINE AA 30.721086 AS 0.694444 B6 75.561166 DL 0.115390 EV 49.485310 F9 185.794656 HA 24.730460 MQ 47.067715 NK 339.888677 OO 57.660681 UA 60.306954 US 2.826113 VX 28.610564 WN 40.926120 Name: ARR_DELAY, dtype: float64 . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;: lambda x: f(x,2)}) . ARR_DELAY . AIRLINE . AA 30.721086 | . AS 0.694444 | . B6 75.561166 | . DL 0.115390 | . EV 49.485310 | . F9 185.794656 | . HA 24.730460 | . MQ 47.067715 | . NK 339.888677 | . OO 57.660681 | . UA 60.306954 | . US 2.826113 | . VX 28.610564 | . WN 40.926120 | . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum} . - 방법1~5 . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:&#39;sum&#39;}) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:np.sum}) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].agg(&#39;sum&#39;) . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].agg(np.sum) . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].sum() . AIRLINE WEEKDAY AA 1 41 2 9 3 16 4 20 5 18 .. WN 3 18 4 10 5 7 6 10 7 7 Name: CANCELLED, Length: 98, dtype: int64 . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum, mean} , {DIVERTED: sum, mean} . - 방법 1~4 (5번은 쓸 수 없다) . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[&#39;sum&#39;,&#39;mean&#39;],&#39;DIVERTED&#39;:[&#39;sum&#39;,&#39;mean&#39;]}) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[np.sum,np.mean],&#39;DIVERTED&#39;:[np.sum,np.mean]}) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[[&#39;CANCELLED&#39;,&#39;DIVERTED&#39;]].agg([&#39;sum&#39;,&#39;mean&#39;]) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[[&#39;CANCELLED&#39;,&#39;DIVERTED&#39;]].agg([np.sum,np.mean]) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum, mean, size} , {AIR_TIME: mean,var} . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[&#39;sum&#39;,&#39;mean&#39;,&#39;size&#39;],&#39;AIR_TIME&#39;:[&#39;mean&#39;,&#39;var&#39;]}) . CANCELLED AIR_TIME . sum mean size mean var . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]) .agg({&#39;CANCELLED&#39;:[np.sum,np.mean,len],&#39;AIR_TIME&#39;:[np.mean,lambda x: np.std(x,ddof=1)**2]}) . CANCELLED AIR_TIME . sum mean len mean &lt;lambda_0&gt; . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . grouping by continuous variable . df . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 0 1 | 1 | 4 | WN | LAX | SLC | 1625 | 58.0 | 94.0 | 590 | 1905 | 65.0 | 0 | 0 | . 1 1 | 1 | 4 | UA | DEN | IAD | 823 | 7.0 | 154.0 | 1452 | 1333 | -13.0 | 0 | 0 | . 2 1 | 1 | 4 | MQ | DFW | VPS | 1305 | 36.0 | 85.0 | 641 | 1453 | 35.0 | 0 | 0 | . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 4 1 | 1 | 4 | WN | LAX | MCI | 1720 | 48.0 | 166.0 | 1363 | 2225 | 39.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 58488 12 | 31 | 4 | F9 | LAS | SFO | 1910 | 13.0 | 71.0 | 414 | 2050 | 4.0 | 0 | 0 | . 58489 12 | 31 | 4 | OO | SFO | SBA | 1846 | -6.0 | 46.0 | 262 | 1956 | -5.0 | 0 | 0 | . 58490 12 | 31 | 4 | WN | MSP | ATL | 525 | 39.0 | 124.0 | 907 | 855 | 34.0 | 0 | 0 | . 58491 12 | 31 | 4 | OO | SFO | BOI | 859 | 5.0 | 73.0 | 522 | 1146 | -1.0 | 0 | 0 | . 58492 rows × 14 columns . - 목표: DIST를 적당한 구간으로 나누어 카테고리화 하고 그것을 바탕으로 groupby를 수행하자. . df.DIST.hist() . &lt;AxesSubplot:&gt; . df.DIST.describe() . count 58492.000000 mean 872.900072 std 624.996805 min 67.000000 25% 391.000000 50% 690.000000 75% 1199.000000 max 4502.000000 Name: DIST, dtype: float64 . - 구간을 아래와 같이 설정한다. . bins=[-np.inf, 400, 700, 1200, np.inf] . - pd.cut()을 이용하여 각 구간의 obs를 카테고리화 하자. . cuts=pd.cut(df.DIST,bins=bins) cuts . 0 (400.0, 700.0] 1 (1200.0, inf] 2 (400.0, 700.0] 3 (700.0, 1200.0] 4 (1200.0, inf] ... 58487 (1200.0, inf] 58488 (400.0, 700.0] 58489 (-inf, 400.0] 58490 (700.0, 1200.0] 58491 (400.0, 700.0] Name: DIST, Length: 58492, dtype: category Categories (4, interval[float64, right]): [(-inf, 400.0] &lt; (400.0, 700.0] &lt; (700.0, 1200.0] &lt; (1200.0, inf]] . - cuts, AIRLINE $ to$ {DIVERTED: sum} . df.groupby([cuts,&#39;AIRLINE&#39;]).agg({&#39;DIVERTED&#39;:sum}) . DIVERTED . DIST AIRLINE . (-inf, 400.0] AA 0 | . AS 0 | . B6 0 | . DL 1 | . EV 3 | . F9 0 | . HA 0 | . MQ 0 | . NK 0 | . OO 5 | . UA 2 | . US 0 | . VX 0 | . WN 1 | . (400.0, 700.0] AA 3 | . AS 0 | . B6 0 | . DL 12 | . EV 8 | . F9 1 | . HA 0 | . MQ 4 | . NK 1 | . OO 7 | . UA 1 | . US 0 | . VX 0 | . WN 2 | . (700.0, 1200.0] AA 10 | . AS 0 | . B6 1 | . DL 6 | . EV 4 | . F9 0 | . HA 0 | . MQ 1 | . NK 1 | . OO 5 | . UA 4 | . US 0 | . VX 0 | . WN 4 | . (1200.0, inf] AA 13 | . AS 0 | . B6 1 | . DL 5 | . EV 0 | . F9 1 | . HA 1 | . MQ 0 | . NK 3 | . OO 4 | . UA 12 | . US 1 | . VX 1 | . WN 8 | . - 아래와 비교해보자. . df.groupby([&#39;AIRLINE&#39;]).agg({&#39;AIRLINE&#39;:len}) . AIRLINE . AIRLINE . AA 8900 | . AS 768 | . B6 543 | . DL 10601 | . EV 5858 | . F9 1317 | . HA 112 | . MQ 3471 | . NK 1516 | . OO 6588 | . UA 7792 | . US 1615 | . VX 993 | . WN 8418 | . - cuts을 이용하여 추가그룹핑을 하면 조금 다른 특징들을 데이터에서 발견할 수 있다. . AA항공사와 DL항공사는 모두 비슷한 우회횟수를 가지고 있음. | AA항공사는 700회이상의 구간에서 우회를 많이하고 DL항공사는 400~700사이에서 우회를 많이 한다. (패턴이 다름) | . - 구간이름에 label을 붙이는 방법 . bins . [-inf, 400, 700, 1200, inf] . cuts2=pd.cut(df.DIST,bins=bins,labels=[&#39;Q1&#39;,&#39;Q2&#39;,&#39;Q3&#39;,&#39;Q4&#39;]) cuts2 . 0 Q2 1 Q4 2 Q2 3 Q3 4 Q4 .. 58487 Q4 58488 Q2 58489 Q1 58490 Q3 58491 Q2 Name: DIST, Length: 58492, dtype: category Categories (4, object): [&#39;Q1&#39; &lt; &#39;Q2&#39; &lt; &#39;Q3&#39; &lt; &#39;Q4&#39;] . df.groupby(by=[cuts2,&#39;AIRLINE&#39;]).agg({&#39;DIVERTED&#39;:sum}) . DIVERTED . DIST AIRLINE . Q1 AA 0 | . AS 0 | . B6 0 | . DL 1 | . EV 3 | . F9 0 | . HA 0 | . MQ 0 | . NK 0 | . OO 5 | . UA 2 | . US 0 | . VX 0 | . WN 1 | . Q2 AA 3 | . AS 0 | . B6 0 | . DL 12 | . EV 8 | . F9 1 | . HA 0 | . MQ 4 | . NK 1 | . OO 7 | . UA 1 | . US 0 | . VX 0 | . WN 2 | . Q3 AA 10 | . AS 0 | . B6 1 | . DL 6 | . EV 4 | . F9 0 | . HA 0 | . MQ 1 | . NK 1 | . OO 5 | . UA 4 | . US 0 | . VX 0 | . WN 4 | . Q4 AA 13 | . AS 0 | . B6 1 | . DL 5 | . EV 0 | . F9 1 | . HA 1 | . MQ 0 | . NK 3 | . OO 4 | . UA 12 | . US 1 | . VX 1 | . WN 8 | . df.groupby(cuts2).agg({&#39;DIVERTED&#39;:len}) . DIVERTED . DIST . Q1 15027 | . Q2 14697 | . Q3 14417 | . Q4 14351 | . &#49689;&#51228; . 구간을 . bins=[-np.inf, 400, 700, 1200, np.inf] . 이 아니라 . bins=[-np.inf, 400, 600, 800, 1000, 1200, np.inf] . 와 같이 나누고 적당한 각구간별로 해당하는 관측치의 수를 구하라. .",
            "url": "https://minji219.github.io/zw/2021/10/27/(8%EC%A3%BC%EC%B0%A8)-10%EC%9B%9427%EC%9D%BC.html",
            "relUrl": "/2021/10/27/(8%EC%A3%BC%EC%B0%A8)-10%EC%9B%9427%EC%9D%BC.html",
            "date": " • Oct 27, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "(7주차) 10월25일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/5) query를 이용한 행선택 . - (2/5) fifa22자료 설명 . - (3/5) fifa22자료 데이터변형 및 시각화 (1) . - (4/5) fifa22자료 데이터변형 및 시각화 (2) . - (5/5) 과제설명 . query . import numpy as np import pandas as pd . np.random.seed(1) df=pd.DataFrame(np.random.normal(size=(15,4)),columns=list(&#39;ABCD&#39;)) df . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 7 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 10 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 13 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . 14 0.838983 | 0.931102 | 0.285587 | 0.885141 | . A&gt;0 and B&lt;0 &#51064; &#54665;&#51012; &#49440;&#53469; . - 방법1 . df.query(&#39;A&gt;0 &amp; B&lt;0&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . - 방법2 . df.query(&#39;A&gt;0 and B&lt;0&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . A&lt;B&lt;C &#51064; &#54665;&#51012; &#49440;&#53469; . df.query(&#39;A&lt;B&lt;C&#39;) . A B C D . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 13 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . A&gt;mean(A) &#51064; &#54665;&#51012; &#49440;&#53469; . - 방법1 . df.A.mean() . -0.018839420539994597 . df.query(&#39;A&gt;-0.018839420539994597&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 14 0.838983 | 0.931102 | 0.285587 | 0.885141 | . - 방법2 . meanA=df.A.mean() meanA . -0.018839420539994597 . df.query(&#39;A&gt; @meanA&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 14 0.838983 | 0.931102 | 0.285587 | 0.885141 | . A&gt;mean(A) &#51060;&#44256;, A&lt;0.8 &#51064; &#44163;&#51012; &#49440;&#53469; . - 방법1 . df.query(&#39; A&gt; @meanA and A&lt;0.8&#39;) . A B C D . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . - 방법2 . df.query(&#39; A&gt; @meanA&#39; &#39; and A&lt;0.8&#39;) . A B C D . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . - 참고사항: 아래는 에러가 발생한다. . df.query(&#39;A&gt; @meanA&#39; &#39;and A&lt;0.8&#39;) . Traceback (most recent call last): File &#34;/home/cgb4/anaconda3/envs/bda2021/lib/python3.8/site-packages/IPython/core/interactiveshell.py&#34;, line 3444, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File &#34;/tmp/ipykernel_1369917/821519992.py&#34;, line 1, in &lt;module&gt; df.query(&#39;A&gt; @meanA&#39; File &#34;/home/cgb4/anaconda3/envs/bda2021/lib/python3.8/site-packages/pandas/core/frame.py&#34;, line 4060, in query res = self.eval(expr, **kwargs) File &#34;/home/cgb4/anaconda3/envs/bda2021/lib/python3.8/site-packages/pandas/core/frame.py&#34;, line 4191, in eval return _eval(expr, inplace=inplace, **kwargs) File &#34;/home/cgb4/anaconda3/envs/bda2021/lib/python3.8/site-packages/pandas/core/computation/eval.py&#34;, line 348, in eval parsed_expr = Expr(expr, engine=engine, parser=parser, env=env) File &#34;/home/cgb4/anaconda3/envs/bda2021/lib/python3.8/site-packages/pandas/core/computation/expr.py&#34;, line 806, in __init__ self.terms = self.parse() File &#34;/home/cgb4/anaconda3/envs/bda2021/lib/python3.8/site-packages/pandas/core/computation/expr.py&#34;, line 825, in parse return self._visitor.visit(self.expr) File &#34;/home/cgb4/anaconda3/envs/bda2021/lib/python3.8/site-packages/pandas/core/computation/expr.py&#34;, line 407, in visit raise e File &#34;/home/cgb4/anaconda3/envs/bda2021/lib/python3.8/site-packages/pandas/core/computation/expr.py&#34;, line 403, in visit node = ast.fix_missing_locations(ast.parse(clean)) File &#34;/home/cgb4/anaconda3/envs/bda2021/lib/python3.8/ast.py&#34;, line 47, in parse return compile(source, filename, mode, flags, File &#34;&lt;unknown&gt;&#34;, line 1 A &gt;__pd_eval_local_meanAand A &lt;0.8 ^ SyntaxError: invalid syntax . &#45800;&#49692;&#51064;&#45937;&#49905; . df . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 7 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 10 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 13 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . 14 0.838983 | 0.931102 | 0.285587 | 0.885141 | . - 0, 3:5, 9:11 에 해당하는 row를 뽑고싶다. $ to$ 칼럼이름을 index로 받아서 사용한다. . df.query(&#39;index==0 or 3&lt;=index &lt;=5 or 9&lt;=index &lt;=11&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 10 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . - 응용사례1 . df.query(&#39;index==0 or index ==[8,9,10]&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 10 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . - 응용사례2 . i1= np.arange(3) i1 . array([0, 1, 2]) . df.query(&#39;index in @i1 or index==5&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . - 시계열자료에서 특히 유용함 . df2=pd.DataFrame(np.random.normal(size=(10,4)), columns=list(&#39;ABCD&#39;), index=pd.date_range(&#39;20201226&#39;,periods=10)) . df2 . A B C D . 2020-12-26 -0.754398 | 1.252868 | 0.512930 | -0.298093 | . 2020-12-27 0.488518 | -0.075572 | 1.131629 | 1.519817 | . 2020-12-28 2.185575 | -1.396496 | -1.444114 | -0.504466 | . 2020-12-29 0.160037 | 0.876169 | 0.315635 | -2.022201 | . 2020-12-30 -0.306204 | 0.827975 | 0.230095 | 0.762011 | . 2020-12-31 -0.222328 | -0.200758 | 0.186561 | 0.410052 | . 2021-01-01 0.198300 | 0.119009 | -0.670662 | 0.377564 | . 2021-01-02 0.121821 | 1.129484 | 1.198918 | 0.185156 | . 2021-01-03 -0.375285 | -0.638730 | 0.423494 | 0.077340 | . 2021-01-04 -0.343854 | 0.043597 | -0.620001 | 0.698032 | . df2.query( &#39; &quot;2020-12-27&quot;&lt;= index &lt;= &quot;2021-01-03&quot; &#39;) . A B C D . 2020-12-27 0.488518 | -0.075572 | 1.131629 | 1.519817 | . 2020-12-28 2.185575 | -1.396496 | -1.444114 | -0.504466 | . 2020-12-29 0.160037 | 0.876169 | 0.315635 | -2.022201 | . 2020-12-30 -0.306204 | 0.827975 | 0.230095 | 0.762011 | . 2020-12-31 -0.222328 | -0.200758 | 0.186561 | 0.410052 | . 2021-01-01 0.198300 | 0.119009 | -0.670662 | 0.377564 | . 2021-01-02 0.121821 | 1.129484 | 1.198918 | 0.185156 | . 2021-01-03 -0.375285 | -0.638730 | 0.423494 | 0.077340 | . df2.query( &#39; &quot;2020-12-27&quot;&lt;= index &lt;= &quot;2021-01-03&quot; &#39; &#39; and A+B &lt; C&#39;) . A B C D . 2020-12-27 0.488518 | -0.075572 | 1.131629 | 1.519817 | . 2020-12-31 -0.222328 | -0.200758 | 0.186561 | 0.410052 | . 2021-01-03 -0.375285 | -0.638730 | 0.423494 | 0.077340 | . FIFA &#49440;&#49688;&#46308; &#49884;&#44033;&#54868; . FIFA data . - FIFA22라는 축구게임이 있음 (굉장히 인기있음) . - 게임에 실제 선수들이 나오면서 선수들의 능력치가 세밀하게 구현되어 있음 . - 이 능력치에 대한 데이터셋은 캐글에 공개되어 있음 . Data . fifa22=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) . - Overall을 기준으로 정렬하여 보자. . fifa22=fifa22.sort_values(by=&#39;Overall&#39;,ascending=False).reset_index().rename(columns={&#39;index&#39;:&#39;index_old&#39;}) . fifa22.head() . index_old ID Name Age Photo Nationality Flag Overall Potential Club ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 29 | 158023 | L. Messi | 34 | https://cdn.sofifa.com/players/158/023/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 93 | 93 | Paris Saint-Germain | ... | 24.0 | 6.0 | 11.0 | 15.0 | 14.0 | 8.0 | RW | 93.0 | €144.3M | 20.0 | . 1 33 | 188545 | R. Lewandowski | 32 | https://cdn.sofifa.com/players/188/545/22_60.png | Poland | https://cdn.sofifa.com/flags/pl.png | 92 | 92 | FC Bayern München | ... | 19.0 | 15.0 | 6.0 | 12.0 | 8.0 | 10.0 | ST | 92.0 | €197.2M | 35.0 | . 2 14244 | 200389 | J. Oblak | 28 | https://cdn.sofifa.com/players/200/389/22_60.png | Slovenia | https://cdn.sofifa.com/flags/si.png | 91 | 93 | Atlético de Madrid | ... | 18.0 | 87.0 | 92.0 | 78.0 | 90.0 | 90.0 | GK | 91.0 | €238M | 27.0 | . 3 3 | 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 64 | 190871 | Neymar Jr | 29 | https://cdn.sofifa.com/players/190/871/22_60.png | Brazil | https://cdn.sofifa.com/flags/br.png | 91 | 91 | Paris Saint-Germain | ... | 29.0 | 9.0 | 9.0 | 15.0 | 15.0 | 11.0 | LW | 91.0 | €238.7M | 35.0 | . 5 rows × 66 columns . Overall vs Potential . from plotnine import * . ggplot(data=fifa22)+geom_point(aes(x=&#39;Overall&#39;, y=&#39;Potential&#39;)) . &lt;ggplot: (8766943203419)&gt; . - 뭔가 Potential &gt; Overall 인 관계가 성립하는것 같다. $ to$ Potetial2= Potential - Overall 인 변수를 새로 만들고 시각화해보자. . 판다스: 새로운열 추가 | . fifa22[&#39;Potential2&#39;] = fifa22[&#39;Potential&#39;] - fifa22[&#39;Overall&#39;] . ggplot(data=fifa22)+geom_point(aes(x=&#39;Overall&#39;, y=&#39;Potential2&#39;),alpha=0.1) . &lt;ggplot: (8766943123941)&gt; . ggplot(data=fifa22)+geom_point(aes(x=&#39;Overall&#39;, y=&#39;Potential2&#39;),alpha=0.1,position=&#39;jitter&#39;) . &lt;ggplot: (8766942753591)&gt; . - 포텐셜2가 너무 0근처인 선수들이 있다. (아마 은퇴한 선수가 아닐까?) $ to$ 제외하고 그리자. . ggplot(data=fifa22.query(&#39;Potential2&gt;0.1&#39;))+geom_point(aes(x=&#39;Overall&#39;, y=&#39;Potential2&#39;),alpha=0.1,position=&#39;jitter&#39;) . &lt;ggplot: (8766942938091)&gt; . - 해석 . 음의 상관관계가 있다. | 오버올이 클수록 포텐셜2의 분산이 작아진다. (오버올이 클수록 더 성장할 부분이 없으니까) | . - Overall을 구간별로 나누자: 어느정도가 적당한 구간일까? . fifa22.Overall.describe() . count 16710.000000 mean 67.646320 std 6.457695 min 28.000000 25% 63.000000 50% 68.000000 75% 72.000000 max 93.000000 Name: Overall, dtype: float64 . import matplotlib.pyplot as plt . fifa22.Overall.hist() . &lt;AxesSubplot:&gt; . def f(x): if x&gt;72: y=&#39;Q1&#39; elif x&gt;68: y=&#39;Q2&#39; elif x&gt;63: y=&#39;Q3&#39; else: y=&#39;Q4&#39; return y . fifa22[&#39;Q&#39;]=list(map(f,fifa22.Overall)) fifa22[[&#39;Q&#39;,&#39;Overall&#39;]] . Q Overall . 0 Q1 | 93 | . 1 Q1 | 92 | . 2 Q1 | 91 | . 3 Q1 | 91 | . 4 Q1 | 91 | . ... ... | ... | . 16705 Q4 | 46 | . 16706 Q4 | 46 | . 16707 Q4 | 44 | . 16708 Q4 | 44 | . 16709 Q4 | 28 | . 16710 rows × 2 columns . ggplot(data=fifa22.query(&#39;Potential2&gt;0.1&#39;)) +geom_boxplot(aes(x=&#39;Q&#39;,y=&#39;Potential2&#39;)) . &lt;ggplot: (8766938801267)&gt; . - Q1으로 갈수록 분산이 작아짐! $ to$ 헷갈린다... . - 산점도와 박스플랏을 겹쳐서 그린다면 좀더 이해가 쉬울것 같다. . - x축의 위치를 조정하면 될것 같다 $ to$ Q1, Q2, Q3, Q4 각 그룹별로 x축의 위치를 구하자. . fifa22.query(&#39;Q==&quot;Q1&quot;&#39;).Overall.mean() . 76.3506528835691 . 이런식으로 해도 되지만 | . fifa22.groupby(by=&#39;Q&#39;).mean().Overall . Q Q1 76.350653 Q2 70.411781 Q3 66.074449 Q4 59.602691 Name: Overall, dtype: float64 . l=fifa22.groupby(by=&#39;Q&#39;).mean().Overall.to_list() l . [76.3506528835691, 70.4117807472048, 66.07444942506334, 59.60269121813031] . - 이제 박스플랏이 들어갈 x축의 위치를 저장할 컬럼을 추가하고 그 이름을 Qx 라고 하자. . def g(x): if x==&#39;Q1&#39;: y=l[0] elif x==&#39;Q2&#39;: y=l[1] elif x==&#39;Q3&#39;: y=l[2] else: y=l[3] return y . fifa22[&#39;Qx&#39;]=list(map(g,fifa22.Q)) . fifa22 . index_old ID Name Age Photo Nationality Flag Overall Potential Club ... GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness Potential2 Q Qx . 0 29 | 158023 | L. Messi | 34 | https://cdn.sofifa.com/players/158/023/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 93 | 93 | Paris Saint-Germain | ... | 15.0 | 14.0 | 8.0 | RW | 93.0 | €144.3M | 20.0 | 0 | Q1 | 76.350653 | . 1 33 | 188545 | R. Lewandowski | 32 | https://cdn.sofifa.com/players/188/545/22_60.png | Poland | https://cdn.sofifa.com/flags/pl.png | 92 | 92 | FC Bayern München | ... | 12.0 | 8.0 | 10.0 | ST | 92.0 | €197.2M | 35.0 | 0 | Q1 | 76.350653 | . 2 14244 | 200389 | J. Oblak | 28 | https://cdn.sofifa.com/players/200/389/22_60.png | Slovenia | https://cdn.sofifa.com/flags/si.png | 91 | 93 | Atlético de Madrid | ... | 78.0 | 90.0 | 90.0 | GK | 91.0 | €238M | 27.0 | 2 | Q1 | 76.350653 | . 3 3 | 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | ... | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | 0 | Q1 | 76.350653 | . 4 64 | 190871 | Neymar Jr | 29 | https://cdn.sofifa.com/players/190/871/22_60.png | Brazil | https://cdn.sofifa.com/flags/br.png | 91 | 91 | Paris Saint-Germain | ... | 15.0 | 15.0 | 11.0 | LW | 91.0 | €238.7M | 35.0 | 0 | Q1 | 76.350653 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 16705 15593 | 235352 | 18 T. Käßemodel | 28 | https://cdn.sofifa.com/players/235/352/18_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 46 | 46 | FC Erzgebirge Aue | ... | 6.0 | 13.0 | 6.0 | CM | 45.0 | €47K | NaN | 0 | Q4 | 59.602691 | . 16706 15685 | 219735 | 15 T. Fletcher | 19 | https://cdn.sofifa.com/players/219/735/15_60.png | England | https://cdn.sofifa.com/flags/gb-eng.png | 46 | 52 | Wycombe Wanderers | ... | 8.0 | 14.0 | 11.0 | CB | 46.0 | NaN | NaN | 6 | Q4 | 59.602691 | . 16707 16572 | 19334 | 10 I. Baraclough | 38 | https://cdn.sofifa.com/players/019/334/10_60.png | England | https://cdn.sofifa.com/flags/gb-eng.png | 44 | 65 | NaN | ... | 46.0 | 20.0 | 20.0 | CM | 46.0 | NaN | NaN | 21 | Q4 | 59.602691 | . 16708 15999 | 220806 | 16 E. Redman | 18 | https://cdn.sofifa.com/players/220/806/16_60.png | Wales | https://cdn.sofifa.com/flags/gb-wls.png | 44 | 57 | Newport County | ... | 16.0 | 9.0 | 7.0 | CB | 44.0 | NaN | NaN | 13 | Q4 | 59.602691 | . 16709 16709 | 178453 | 07 A. Censori | 17 | https://cdn.sofifa.com/players/178/453/07_60.png | Italy | https://cdn.sofifa.com/flags/it.png | 28 | 38 | Arezzo | ... | 36.0 | 6.0 | 9.0 | ST | 36.0 | NaN | NaN | 10 | Q4 | 59.602691 | . 16710 rows × 69 columns . ggplot(data=fifa22.query(&#39;Potential2&gt;0.1&#39;)) +geom_point(aes(x=&#39;Overall&#39;, y=&#39;Potential2&#39;,color=&#39;Q&#39;),alpha=0.1,size=0.1,position=&#39;jitter&#39;) +geom_boxplot(aes(x=&#39;Qx&#39;, y=&#39;Potential2&#39;,color=&#39;Q&#39;)) . &lt;ggplot: (8766942887677)&gt; . &#49689;&#51228; . fifa22 데이터셋에서 Q==Q1이고, Potentail2&gt;20 인 선수들의 이름을 출력하라. .",
            "url": "https://minji219.github.io/zw/2021/10/25/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9425%EC%9D%BC.html",
            "relUrl": "/2021/10/25/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9425%EC%9D%BC.html",
            "date": " • Oct 25, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "(7주차) 10월20일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/3) 행을 선택하는 방법 (기본) . - (2/3) 행을 선택하는 방법 (람다사용) . - (3/3) 과제설명 . import . import numpy as np import pandas as pd . &#52395;&#48264;&#51704; &#54665;&#51012; &#49440;&#53469;&#54616;&#45716; &#48277; . np.random.seed(1) dic= {&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5), &#39;X4&#39;:np.random.normal(0,1,5), &#39;X5&#39;:np.random.normal(0,1,5), &#39;X6&#39;:np.random.normal(0,1,5)} df1=pd.DataFrame(dic) df1 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 1 -0.611756 | 1.744812 | -2.060141 | -0.172428 | 1.144724 | -0.122890 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . 3 -1.072969 | 0.319039 | -0.384054 | 0.042214 | 0.502494 | -0.267888 | . 4 0.865408 | -0.249370 | 1.133769 | 0.582815 | 0.900856 | 0.530355 | . - 방법1 . df1.iloc[0] # 이상해 . X1 1.624345 X2 -2.301539 X3 1.462108 X4 -1.099891 X5 -1.100619 X6 -0.683728 Name: 0, dtype: float64 . - 방법2 . df1.iloc[[0]] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . - 방법3 . df1.iloc[0,:] . X1 1.624345 X2 -2.301539 X3 1.462108 X4 -1.099891 X5 -1.100619 X6 -0.683728 Name: 0, dtype: float64 . - 방법4 . df1.iloc[[0],:] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . - 방법5 . df1.loc[0] # 이상해 . X1 1.624345 X2 -2.301539 X3 1.462108 X4 -1.099891 X5 -1.100619 X6 -0.683728 Name: 0, dtype: float64 . - 방법6 . df1.loc[[0]] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . - 방법7 . df1.loc[0,:] . X1 1.624345 X2 -2.301539 X3 1.462108 X4 -1.099891 X5 -1.100619 X6 -0.683728 Name: 0, dtype: float64 . - 방법8 . df1.loc[[0],:] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . - 방법9 . df1.iloc[[True,False,False,False,False]] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . - 방법10 . df1.iloc[[True,False,False,False,False],:] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . - 방법11 . df1.loc[[True,False,False,False,False]] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . - 방법12 . df1.loc[[True,False,False,False,False],:] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 1,3&#54665;&#51012; &#49440;&#53469;&#54616;&#45716; &#48169;&#48277; . df1 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 1 -0.611756 | 1.744812 | -2.060141 | -0.172428 | 1.144724 | -0.122890 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . 3 -1.072969 | 0.319039 | -0.384054 | 0.042214 | 0.502494 | -0.267888 | . 4 0.865408 | -0.249370 | 1.133769 | 0.582815 | 0.900856 | 0.530355 | . - 방법1 . df1.iloc[[0,2],:] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . - 방법2 . df1.loc[[0,2],:] . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . - 그외에 여러행을 뽑는 방법이 있음; 슬라이싱, 불인덱싱 . loc vs iloc ?? . - 인덱스가 정수가 아닌경우 . _df= pd.DataFrame({&#39;A&#39;:[1,2,3,4],&#39;B&#39;:[4,5,6,7]},index=list(&#39;abcd&#39;)) _df . A B . a 1 | 4 | . b 2 | 5 | . c 3 | 6 | . d 4 | 7 | . _df.loc[&#39;a&#39;:&#39;c&#39;,:] . A B . a 1 | 4 | . b 2 | 5 | . c 3 | 6 | . _df.iloc[0:3,:] . A B . a 1 | 4 | . b 2 | 5 | . c 3 | 6 | . _df.loc[[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;],:] . A B . a 1 | 4 | . b 2 | 5 | . c 3 | 6 | . _df.iloc[[0,1,2],:] . A B . a 1 | 4 | . b 2 | 5 | . c 3 | 6 | . - 대부분의 경우 observation에 특정한 이름이 있는 경우는 없으므로 loc이 그다지 쓸모 없음 . - 그렇지만 특정경우에는 쓸모가 있음 . np.random.normal(size=(20,4)) . array([[ 0.83600472, 1.54335911, 0.75880566, 0.88490881], [-0.87728152, -0.86778722, -1.44087602, 1.23225307], [-0.25417987, 1.39984394, -0.78191168, -0.43750898], [ 0.09542509, 0.92145007, 0.0607502 , 0.21112476], [ 0.01652757, 0.17718772, -1.11647002, 0.0809271 ], [-0.18657899, -0.05682448, 0.49233656, -0.68067814], [-0.08450803, -0.29736188, 0.417302 , 0.78477065], [-0.95542526, 0.58591043, 2.06578332, -1.47115693], [-0.8301719 , -0.8805776 , -0.27909772, 1.62284909], [ 0.01335268, -0.6946936 , 0.6218035 , -0.59980453], [ 1.12341216, 0.30526704, 1.3887794 , -0.66134424], [ 3.03085711, 0.82458463, 0.65458015, -0.05118845], [-0.72559712, -0.86776868, -0.13597733, -0.79726979], [ 0.28267571, -0.82609743, 0.6210827 , 0.9561217 ], [-0.70584051, 1.19268607, -0.23794194, 1.15528789], [ 0.43816635, 1.12232832, -0.9970198 , -0.10679399], [ 1.45142926, -0.61803685, -2.03720123, -1.94258918], [-2.50644065, -2.11416392, -0.41163916, 1.27852808], [-0.44222928, 0.32352735, -0.10999149, 0.00854895], [-0.16819884, -0.17418034, 0.4611641 , -1.17598267]]) . np.random.seed(1) _df= pd.DataFrame(np.random.normal(size=(20,4)), columns=list(&#39;ABCD&#39;), index=pd.date_range(&#39;20201225&#39;,periods=20)) _df . A B C D . 2020-12-25 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 2020-12-26 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2020-12-27 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 2020-12-28 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 2020-12-29 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 2020-12-30 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 2020-12-31 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 2021-01-01 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 2021-01-02 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 2021-01-03 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 2021-01-04 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . 2021-01-05 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 2021-01-06 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 2021-01-07 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . 2021-01-08 0.838983 | 0.931102 | 0.285587 | 0.885141 | . 2021-01-09 -0.754398 | 1.252868 | 0.512930 | -0.298093 | . 2021-01-10 0.488518 | -0.075572 | 1.131629 | 1.519817 | . 2021-01-11 2.185575 | -1.396496 | -1.444114 | -0.504466 | . 2021-01-12 0.160037 | 0.876169 | 0.315635 | -2.022201 | . 2021-01-13 -0.306204 | 0.827975 | 0.230095 | 0.762011 | . - 1월5일부터 1월8일까지의 자료만 보고싶다. . _df.loc[&#39;20210105&#39;:&#39;20210108&#39;] . A B C D . 2021-01-05 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 2021-01-06 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 2021-01-07 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . 2021-01-08 0.838983 | 0.931102 | 0.285587 | 0.885141 | . - iloc으로 하려면 힘들다. . _df.index . DatetimeIndex([&#39;2020-12-25&#39;, &#39;2020-12-26&#39;, &#39;2020-12-27&#39;, &#39;2020-12-28&#39;, &#39;2020-12-29&#39;, &#39;2020-12-30&#39;, &#39;2020-12-31&#39;, &#39;2021-01-01&#39;, &#39;2021-01-02&#39;, &#39;2021-01-03&#39;, &#39;2021-01-04&#39;, &#39;2021-01-05&#39;, &#39;2021-01-06&#39;, &#39;2021-01-07&#39;, &#39;2021-01-08&#39;, &#39;2021-01-09&#39;, &#39;2021-01-10&#39;, &#39;2021-01-11&#39;, &#39;2021-01-12&#39;, &#39;2021-01-13&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) . pd.Series(_df.index) . 0 2020-12-25 1 2020-12-26 2 2020-12-27 3 2020-12-28 4 2020-12-29 5 2020-12-30 6 2020-12-31 7 2021-01-01 8 2021-01-02 9 2021-01-03 10 2021-01-04 11 2021-01-05 12 2021-01-06 13 2021-01-07 14 2021-01-08 15 2021-01-09 16 2021-01-10 17 2021-01-11 18 2021-01-12 19 2021-01-13 dtype: datetime64[ns] . _df.iloc[11:15] . A B C D . 2021-01-05 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 2021-01-06 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 2021-01-07 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . 2021-01-08 0.838983 | 0.931102 | 0.285587 | 0.885141 | . &#51088;&#51452;&#54616;&#45716; &#49892;&#49688; . - 저는 아래와 같은 실수를 자주해요 . _df.loc[&#39;A&#39;] . ValueError Traceback (most recent call last) ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/_libs/tslibs/conversion.pyx in pandas._libs.tslibs.conversion._convert_str_to_tsobject() ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/_libs/tslibs/parsing.pyx in pandas._libs.tslibs.parsing.parse_datetime_string() ValueError: Given date string not likely a datetime. During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last) ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py in get_loc(self, key, method, tolerance) 680 try: --&gt; 681 key = self._maybe_cast_for_get_loc(key) 682 except ValueError as err: ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py in _maybe_cast_for_get_loc(self, key) 708 # needed to localize naive datetimes or dates (GH 35690) --&gt; 709 key = Timestamp(key) 710 if key.tzinfo is None: ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/_libs/tslibs/timestamps.pyx in pandas._libs.tslibs.timestamps.Timestamp.__new__() ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/_libs/tslibs/conversion.pyx in pandas._libs.tslibs.conversion.convert_to_tsobject() ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/_libs/tslibs/conversion.pyx in pandas._libs.tslibs.conversion._convert_str_to_tsobject() ValueError: could not convert string to Timestamp The above exception was the direct cause of the following exception: KeyError Traceback (most recent call last) /tmp/ipykernel_38055/4015539971.py in &lt;module&gt; -&gt; 1 _df.loc[&#39;A&#39;] ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key) 929 930 maybe_callable = com.apply_if_callable(key, self.obj) --&gt; 931 return self._getitem_axis(maybe_callable, axis=axis) 932 933 def _is_scalar_access(self, key: tuple): ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis) 1162 # fall thru to straight lookup 1163 self._validate_key(key, axis) -&gt; 1164 return self._get_label(key, axis=axis) 1165 1166 def _get_slice_axis(self, slice_obj: slice, axis: int): ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in _get_label(self, label, axis) 1111 def _get_label(self, label, axis: int): 1112 # GH#5667 this will fail if the label is not present in the axis. -&gt; 1113 return self.obj.xs(label, axis=axis) 1114 1115 def _handle_lowerdim_multi_index_axis0(self, tup: tuple): ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level) 3774 raise TypeError(f&#34;Expected label or tuple of labels, got {key}&#34;) from e 3775 else: -&gt; 3776 loc = index.get_loc(key) 3777 3778 if isinstance(loc, np.ndarray): ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py in get_loc(self, key, method, tolerance) 681 key = self._maybe_cast_for_get_loc(key) 682 except ValueError as err: --&gt; 683 raise KeyError(key) from err 684 685 elif isinstance(key, timedelta): KeyError: &#39;A&#39; . - 올바른 방법 . _df[&#39;A&#39;] . 2020-12-25 1.624345 2020-12-26 0.865408 2020-12-27 0.319039 2020-12-28 -0.322417 2020-12-29 -0.172428 2020-12-30 -1.100619 2020-12-31 0.900856 2021-01-01 -0.267888 2021-01-02 -0.687173 2021-01-03 -1.117310 2021-01-04 -0.191836 2021-01-05 0.050808 2021-01-06 0.120159 2021-01-07 -1.142518 2021-01-08 0.838983 2021-01-09 -0.754398 2021-01-10 0.488518 2021-01-11 2.185575 2021-01-12 0.160037 2021-01-13 -0.306204 Freq: D, Name: A, dtype: float64 . - 아래의 사실을 기억하자. . 기본적으로는 iloc, loc은 [2], [2:] 처럼 1차원으로 원소를 인덱싱할수도 있고, [2,3], [:,2] 와 같이 2차원으로 인덱싱할 수도 있다. . | 1차원으로 인덱싱하는 경우는 기본적으로 행을 인덱싱한다 $ to$ iloc, loc은 행과 더 친하고 열과 친하지 않다. . | 따라서 열을 선택하는 방법에 있어서 loc, iloc이 그렇제 좋은 방법은 아니다. . | 그렇지만 열을 선택하는 방법은 iloc이나 loc이 제일 편리하다. (이외의 다른 방법이 마땅하게 없음) 그래서 열을 선택할때도 iloc이나 loc을 선호한다. . | . &#49836;&#46972;&#51060;&#49905;&#50640; &#45824;&#54620; &#51025;&#50857; . _df.iloc[::2] . A B C D . 2020-12-25 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 2020-12-27 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 2020-12-29 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 2020-12-31 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 2021-01-02 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 2021-01-04 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . 2021-01-06 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 2021-01-08 0.838983 | 0.931102 | 0.285587 | 0.885141 | . 2021-01-10 0.488518 | -0.075572 | 1.131629 | 1.519817 | . 2021-01-12 0.160037 | 0.876169 | 0.315635 | -2.022201 | . - 이 방법은 칼럼에도 적용가능 . _df.iloc[:,::2] . A C . 2020-12-25 1.624345 | -0.528172 | . 2020-12-26 0.865408 | 1.744812 | . 2020-12-27 0.319039 | 1.462108 | . 2020-12-28 -0.322417 | 1.133769 | . 2020-12-29 -0.172428 | 0.042214 | . 2020-12-30 -1.100619 | 0.901591 | . 2020-12-31 0.900856 | -0.122890 | . 2021-01-01 -0.267888 | -0.691661 | . 2021-01-02 -0.687173 | -0.671246 | . 2021-01-03 -1.117310 | 1.659802 | . 2021-01-04 -0.191836 | -0.747158 | . 2021-01-05 0.050808 | 0.190915 | . 2021-01-06 0.120159 | 0.300170 | . 2021-01-07 -1.142518 | -0.208894 | . 2021-01-08 0.838983 | 0.285587 | . 2021-01-09 -0.754398 | 0.512930 | . 2021-01-10 0.488518 | 1.131629 | . 2021-01-11 2.185575 | -1.444114 | . 2021-01-12 0.160037 | 0.315635 | . 2021-01-13 -0.306204 | 0.230095 | . - 칼럼에는 잘 쓰지 않는이유? . row는 특정간격으로 뽑는 일이 빈번함. (예를들어 일별데이터를 주별데이터로 바꾸고싶을때, 바꾸고 싶을 경우?) . | col을 특정간격으로 뽑아야 하는 일은 없음 . | . lambda + map . np.random.seed(1) df2= pd.DataFrame(np.random.normal(size=(10,4)),columns=list(&#39;ABCD&#39;)) df2 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 7 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . &#52860;&#47100;A&#51032; &#44050;&#51060; 0&#48372;&#45796; &#53360; &#44221;&#50864;&#47564; . - 방법1 . df2.loc[map(lambda x: x&gt;0,df2[&#39;A&#39;]),:] . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . - 방법2 . df2.loc[lambda df: df[&#39;A&#39;]&gt;0,:] . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . ?? | map의 기능은 (1) 리스트를 원소별로 분해하여 (2) 어떠한 함수를 적용하여 아웃풋을 구한뒤 (3) 각각의 아웃풋을 다시 하나의 리스트로 묶음 | 우리는 이중에서 (1),(3)에만 집중했음 | 하지만 생각해보면 일단 (2) 일단 함수를 적용하는 기능이 있었음 | 그런데 위의 코든느 함수를 적용한 결과가 아니라 함수 오브젝트 자체를 전달하여도 동작함 | . 요약!! . True, False로 이루어진 벡터를 리스트의 형태로 전달하여 인덱상했음 (원래 우리가 알고 있는 개념) | True, False로 이루어진 벡터를 리턴할 수 있는 함수오브젝트 자체를 전달해도 인덱싱이 가능 | . - 방법3 . df2.iloc[map(lambda x: x&gt;0,df2[&#39;A&#39;]),:] . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . - 방법4: 실패 . df2.iloc[lambda df: df[&#39;A&#39;]&gt;0,:] . NotImplementedError Traceback (most recent call last) /tmp/ipykernel_38055/235064012.py in &lt;module&gt; -&gt; 1 df2.iloc[lambda df: df[&#39;A&#39;]&gt;0,:] ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key) 923 with suppress(KeyError, IndexError): 924 return self.obj._get_value(*key, takeable=self._takeable) --&gt; 925 return self._getitem_tuple(key) 926 else: 927 # we by definition only have the 0th axis ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_tuple(self, tup) 1504 def _getitem_tuple(self, tup: tuple): 1505 -&gt; 1506 self._has_valid_tuple(tup) 1507 with suppress(IndexingError): 1508 return self._getitem_lowerdim(tup) ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in _has_valid_tuple(self, key) 752 for i, k in enumerate(key): 753 try: --&gt; 754 self._validate_key(k, i) 755 except ValueError as err: 756 raise ValueError( ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis) 1393 if hasattr(key, &#34;index&#34;) and isinstance(key.index, Index): 1394 if key.index.inferred_type == &#34;integer&#34;: -&gt; 1395 raise NotImplementedError( 1396 &#34;iLocation based boolean &#34; 1397 &#34;indexing on an integer type &#34; NotImplementedError: iLocation based boolean indexing on an integer type is not available . 위에서 iloc을 loc으로 바꾸면 되는데.. | iloc입장에서는 조금 서운함 | . &#52860;&#47100;A&gt;0 &#51060;&#44256; &#52860;&#47100;C&lt;0 &#51064; &#44221;&#50864; . df2 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 7 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . - 방법1 . df2.loc[map(lambda x,y: x&gt;0 and y&lt;0, df2[&#39;A&#39;],df2[&#39;C&#39;]),:] . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . - 방법2 . df2.loc[map(lambda x,y: x&gt;0 &amp; y&lt;0, df2[&#39;A&#39;],df2[&#39;C&#39;]),:] . TypeError Traceback (most recent call last) /tmp/ipykernel_38055/232901037.py in &lt;module&gt; -&gt; 1 df2.loc[map(lambda x,y: x&gt;0 &amp; y&lt;0, df2[&#39;A&#39;],df2[&#39;C&#39;]),:] ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key) 918 def __getitem__(self, key): 919 if type(key) is tuple: --&gt; 920 key = tuple(list(x) if is_iterator(x) else x for x in key) 921 key = tuple(com.apply_if_callable(x, self.obj) for x in key) 922 if self._is_scalar_access(key): ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in &lt;genexpr&gt;(.0) 918 def __getitem__(self, key): 919 if type(key) is tuple: --&gt; 920 key = tuple(list(x) if is_iterator(x) else x for x in key) 921 key = tuple(com.apply_if_callable(x, self.obj) for x in key) 922 if self._is_scalar_access(key): /tmp/ipykernel_38055/232901037.py in &lt;lambda&gt;(x, y) -&gt; 1 df2.loc[map(lambda x,y: x&gt;0 &amp; y&lt;0, df2[&#39;A&#39;],df2[&#39;C&#39;]),:] TypeError: unsupported operand type(s) for &amp;: &#39;int&#39; and &#39;float&#39; . ??? 아래를 관찰 | . 보충학습 . 0&lt;3.2 &amp; 0&lt;2.2 . TypeError Traceback (most recent call last) /tmp/ipykernel_38055/993001292.py in &lt;module&gt; -&gt; 1 0&lt;3.2 &amp; 0&lt;2.2 TypeError: unsupported operand type(s) for &amp;: &#39;float&#39; and &#39;int&#39; . (0&lt;3.2) &amp; (0&lt;2.2) . True . 보충학습끝 . 위의코드도 괄호로 묶어주면 잘 동작한다. . df2.loc[map(lambda x,y: (x&gt;0) &amp; (y&lt;0), df2[&#39;A&#39;],df2[&#39;C&#39;]),:] . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . - 방법3 . df2.loc[lambda df: (df[&#39;A&#39;] &gt;0) &amp; (df[&#39;C&#39;]&lt;0)] . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 아래는 실행되지 않는다 . df2.loc[lambda df: (df[&#39;A&#39;] &gt;0) and (df[&#39;C&#39;]&lt;0)] . ValueError Traceback (most recent call last) /tmp/ipykernel_38055/2807753716.py in &lt;module&gt; -&gt; 1 df2.loc[lambda df: (df[&#39;A&#39;] &gt;0) and (df[&#39;C&#39;]&lt;0)] ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key) 928 axis = self.axis or 0 929 --&gt; 930 maybe_callable = com.apply_if_callable(key, self.obj) 931 return self._getitem_axis(maybe_callable, axis=axis) 932 ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/common.py in apply_if_callable(maybe_callable, obj, **kwargs) 356 &#34;&#34;&#34; 357 if callable(maybe_callable): --&gt; 358 return maybe_callable(obj, **kwargs) 359 360 return maybe_callable /tmp/ipykernel_38055/2807753716.py in &lt;lambda&gt;(df) -&gt; 1 df2.loc[lambda df: (df[&#39;A&#39;] &gt;0) and (df[&#39;C&#39;]&lt;0)] ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/pandas/core/generic.py in __nonzero__(self) 1535 @final 1536 def __nonzero__(self): -&gt; 1537 raise ValueError( 1538 f&#34;The truth value of a {type(self).__name__} is ambiguous. &#34; 1539 &#34;Use a.empty, a.bool(), a.item(), a.any() or a.all().&#34; ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). . 실행되지 않는이유 . np.array([True, False]) &amp; np.array([True, True]) . array([ True, False]) . np.array([True, False]) and np.array([True, True]) . ValueError Traceback (most recent call last) /tmp/ipykernel_38055/1293310712.py in &lt;module&gt; -&gt; 1 np.array([True, False]) and np.array([True, True]) ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all() . - iloc을 이용한 방법은 생략 . &#49689;&#51228; . df2 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 7 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . A&gt; -1 이고 C &lt; 1.5 인 row를 선택 .",
            "url": "https://minji219.github.io/zw/2021/10/20/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9420%EC%9D%BC.html",
            "relUrl": "/2021/10/20/(7%EC%A3%BC%EC%B0%A8)-10%EC%9B%9420%EC%9D%BC.html",
            "date": " • Oct 20, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "(6주차) 10월18일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/4) 아이스크림을 많이 먹으면 걸리는 병 . - (2/4) 기상청기온자료를 활용하여 가짜자료 구축 및 해석 (1) . - (3/4) 기상청기온자료를 활용하여 가짜자료 구축 및 해석 (2) . - (4/4) plotnine을 활용한 시각화 . &#50500;&#51060;&#49828;&#53356;&#47548;&#51012; &#47566;&#51060; &#47673;&#51004;&#47732; &#44152;&#47532;&#45716; &#48337; . - ref- 데이터 과학자의 사고법: 더 나은 선택을 위한 통계학적 통찰의 힘 . https://books.google.co.kr/books?id=qy4iEAAAQBAJ&amp;pg=PT87&amp;lpg=PT87&amp;dq=%EC%95%84%EC%9D%B4%EC%8A%A4%ED%81%AC%EB%A6%BC%EC%9D%84+%EB%A7%8E%EC%9D%B4+%EB%A8%B9%EC%9C%BC%EB%A9%B4+%EA%B1%B8%EB%A6%AC%EB%8A%94+%EB%B3%91+%EC%86%8C%EC%95%84%EB%A7%88%EB%B9%84&amp;source=bl&amp;ots=V9B7ZG6oR-&amp;sig=ACfU3U0UMd4ehuRXYxI69TT6lIlU-r91bA&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj13JSV19LzAhVEGaYKHdgfDgcQ6AF6BAgCEAM#v=onepage&amp;q=%EC%95%84%EC%9D%B4%EC%8A%A4%ED%81%AC%EB%A6%BC%EC%9D%84%20%EB%A7%8E%EC%9D%B4%20%EB%A8%B9%EC%9C%BC%EB%A9%B4%20%EA%B1%B8%EB%A6%AC%EB%8A%94%20%EB%B3%91%20%EC%86%8C%EC%95%84%EB%A7%88%EB%B9%84&amp;f=false . - 내용요약 . 여름 $ to$ 수영장 $ to$ 소아마비 | 여름 $ to$ 아이스크림 | 아이스크림과 소아마비는 상관관계가 높다: 아이스크림 성분중에서 소아마비를 유발하는 유해물질이 있을 것이다 (?) | . - 아래와 같이 모형을 간단하게 하자. . 온도 $ to$ 소아마비 | 온도 $ to$ 아이스크림 | . Toy exam . import numpy as np import matplotlib.pyplot as plt import pandas as pd . - 교재의 예제상황은 예를들면 아래와 같다. . - 아이스크림 판매량 = 20 + 온도 $ times$ 2 + $ epsilon$ . np.random.seed(1) temp= np.array([-10.2, -5.2, 0.1, 10.1, 12.2, 14.7, 25.4, 26.8, 28.9, 35.1, 32.2, 34.6]) ϵ1= np.random.normal(size=12,scale=5) icecream= 20 + temp * 2 + ϵ1 . plt.plot(temp,icecream,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc550768e80&gt;] . 온도와 아이스크림 판매량의 산점도 | . - 소아마비 = 30 + 온도 $ times$ 0.5 + $ epsilon^*$ . np.random.seed(2) ϵ2= np.random.normal(size=12,scale=5) disease = 30+ temp* 0.5 + ϵ2 . plt.plot(temp,disease,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc550480c40&gt;] . 온도와 소아마비의 산점도 | . - 아이스크림과 질병의 산점도를 그려보자. . plt.plot(icecream,disease,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc55071b5e0&gt;] . 양의 상관관계에 있다. | . - 아이스크림 중 어떠한 물질이 소아마비를 일으키는것이 분명하므로 (인과성이 분명해보이니까) 아래와 같은 모형을 세우자. &lt;-- 여기서부터 틀렸음 . $${ tt disease}_i = beta_0 + beta_1 { tt icecream}_i + epsilon_i, quad textbf{for} ~~ i=1,2, dots, 12$$ . - 적절한 $ beta_0$와 $ beta_1$을 추정하면 우리는 아이스크림과 소아마비의 관계를 알 수 있다. &lt;-- 틀린주장 . 틀린 모형 | 도데체 우리가 뭘 잘못했는가? | . - 두 변수 사이에 상관관계가 있어도 실제 원인은 다른 변수에 숨겨져 있는 경우가 많다. . 예제의상황: 아이스크림과 익사자도 양의 상관관계에 있을것이다. | 아이스크림을 먹이면 물에 빠져 죽는다 $ to$ 틀린주장 | 사실 기온이 숨겨진 원인이다. 기온이 증가하면 아이스크림 판매량도 증가하고 폭염때문에 익사사고율도 높아지는 구조이다. | . - 아래와 같은 예제를 생각하자. . 인구수 $ to$ 교회 | 인구수 $ to$ 범죄건수 | 지역별 교회와 범죄건수를 살펴보면 상관관계가 높게 나올것임 | . - 교회를 많이 지으면 범죄건수도 증가한다? . 사실 그렇지 않다. | 인구수가 비슷한 도시끼리 묶어서 비교해보면 교회와 범죄건수는 양의 상관관계에 있지 않을것임 | . - 올바른 분석: 온도가 비슷한 그룹끼리 묶어서 그려보자. $ to$ 상관계수가 줄어들 것이다. . plt.plot(icecream[:6],disease[:6],&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc54dd5aac0&gt;] . plt.plot(icecream[6:],disease[6:],&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc54db7ee20&gt;] . - 진짜로 선형관계가 약해졌다.. . &#51328; &#45908; &#44536;&#47092;&#46319;&#54620; &#51088;&#47308; . - 위의 toy example은 데이터가 너무 작아서 억지스러움 . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/extremum.csv&#39;) . df . 지점번호 지점명 일시 평균기온(℃) 최고기온(℃) 최고기온시각 최저기온(℃) 최저기온시각일교차 Unnamed: 8 . 0 146 | 전주 | 2020-01-01 | -0.5 | 4.3 | 15:09 | -6.4 | 1:42 | 10.7 | . 1 146 | 전주 | 2020-01-02 | 1.4 | 6.5 | 14:12 | -3.0 | 7:55 | 9.5 | . 2 146 | 전주 | 2020-01-03 | 2.6 | 7.6 | 13:32 | -0.5 | 23:53 | 8.1 | . 3 146 | 전주 | 2020-01-04 | 2.0 | 7.7 | 13:51 | -2.6 | 5:30 | 10.3 | . 4 146 | 전주 | 2020-01-05 | 2.5 | 8.6 | 14:05 | -3.2 | 7:36 | 11.8 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 651 146 | 전주 | 2021-10-13 | 19.9 | 25.5 | 14:29 | 15.6 | 3:49 | 9.9 | . 652 146 | 전주 | 2021-10-14 | 20.4 | 25.5 | 13:36 | 17.0 | 6:15 | 8.5 | . 653 146 | 전주 | 2021-10-15 | 18.3 | 22.0 | 13:47 | 15.7 | 4:48 | 6.3 | . 654 146 | 전주 | 2021-10-16 | 12.8 | 17.4 | 0:01 | 6.5 | 23:31 | 10.9 | . 655 146 | 전주 | 2021-10-17 | 6.7 | 12.4 | 15:18 | 2.2 | 6:43 | 10.2 | . 656 rows × 9 columns . - 평균기온만 선택하여 뽑자. . pd.Series(df.columns) . 0 지점번호 1 지점명 2 일시 3 평균기온(℃) 4 최고기온(℃) 5 최고기온시각 6 최저기온(℃) 7 최저기온시각일교차 8 Unnamed: 8 dtype: object . temp=np.array(df.iloc[:,3]) . len(temp) . 656 . - 아이스크림 판매량 . np.random.seed(1) ϵ1=np.random.normal(size=656, scale=10) icecream=temp*2 + 30 + ϵ1 . plt.plot(temp,icecream,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc54b3e69d0&gt;] . - 소아마비 . np.random.seed(2) ϵ2=np.random.normal(size=656,scale=1) disease=temp*0.5 + 40 +ϵ2 . plt.plot(temp,disease,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc54b3c6be0&gt;] . - 아이스크림과 소아마비 . plt.plot(icecream,disease,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc54b32c3d0&gt;] . np.corrcoef(icecream,disease) . array([[1. , 0.86298975], [0.86298975, 1. ]]) . 0.86정도.. | . - 여름만 뽑아서 그러보면? . plt.plot(icecream[temp&gt;25],disease[temp&gt;25], &#39;.&#39;) ## 평균기온이 25도가 넘어가면 여름 . [&lt;matplotlib.lines.Line2D at 0x7fc54b30c9a0&gt;] . - 산점도 . fig , ((ax1,ax2), (ax3,ax4)) = plt.subplots(2,2) ax1.plot(temp,icecream,&#39;.&#39;) ax2.plot(temp,disease,&#39;.&#39;) ax3.plot(icecream,disease,&#39;.&#39;) ax4.plot(icecream[temp&gt;25],disease[temp&gt;25],&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc54b1b6220&gt;] . fig , ((ax1,ax2), (ax3,ax4)) = plt.subplots(2,2) ax1.plot(temp,icecream,&#39;.&#39;) ax2.plot(temp,disease,&#39;.&#39;) ax3.plot(icecream,disease,&#39;.&#39;) ax4.plot(icecream,disease,&#39;.&#39;) ax4.plot(icecream[temp&gt;25],disease[temp&gt;25],&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fc54b06ffa0&gt;] . &#50728;&#46020;&#44396;&#44036;&#51012; &#49464;&#48516;&#54868; &#54616;&#50668; &#49884;&#44033;&#54868; . - 목표: 모든 온도구간에 대하여 각각 색을 다르게 하여 그려보자. . 사실 지금 변수는 온도, 아이스크림판매량, 소아마비 | 지금까지는 기본산점도만 사용하였기에 2차원플랏만 그렸음 $ to$ 그래서 각각의 산점도를 정신없이 그려왔음 | 온도가 유사한 지역을 색으로 묶으면 3차원 플랏이 가능함 | . - 일단 데이터 프레임을 정리하자. . df1=pd.DataFrame({&#39;temp&#39;:temp, &#39;icecream&#39;:icecream, &#39;disease&#39;:disease}) . df1 . temp icecream disease . 0 -0.5 | 45.243454 | 39.333242 | . 1 1.4 | 26.682436 | 40.643733 | . 2 2.6 | 29.918282 | 39.163804 | . 3 2.0 | 23.270314 | 42.640271 | . 4 2.5 | 43.654076 | 39.456564 | . ... ... | ... | ... | . 651 19.9 | 78.839992 | 49.633906 | . 652 20.4 | 86.554679 | 48.920443 | . 653 18.3 | 78.666079 | 49.882650 | . 654 12.8 | 52.771364 | 46.613159 | . 655 6.7 | 40.736731 | 44.902513 | . 656 rows × 3 columns . - 온도를 카테고리화 하자 $ to$ 적당한 구긴을 설정하기 위해서 히스토그램을 그려보자. . df1.temp.hist() . &lt;AxesSubplot:&gt; . plt.hist(df1.temp) . (array([ 3., 9., 29., 60., 92., 86., 65., 93., 139., 80.]), array([-12.4 , -8.16, -3.92, 0.32, 4.56, 8.8 , 13.04, 17.28, 21.52, 25.76, 30. ]), &lt;BarContainer object of 10 artists&gt;) . - 구간은 5정도로 하면 적당할것 같다. . def f(x): if x&lt;0: y=&#39;group0&#39; elif x&lt;5: y=&#39;group5&#39; elif x&lt;10: y=&#39;group10&#39; elif x&lt;15: y=&#39;group15&#39; elif x&lt;20: y=&#39;group20&#39; elif x&lt;25: y=&#39;group25&#39; else: y=&#39;group30&#39; return y . df1[&#39;temp2&#39;]=list(map(f,df1.temp)) . df1 . temp icecream disease temp2 . 0 -0.5 | 45.243454 | 39.333242 | group0 | . 1 1.4 | 26.682436 | 40.643733 | group5 | . 2 2.6 | 29.918282 | 39.163804 | group5 | . 3 2.0 | 23.270314 | 42.640271 | group5 | . 4 2.5 | 43.654076 | 39.456564 | group5 | . ... ... | ... | ... | ... | . 651 19.9 | 78.839992 | 49.633906 | group20 | . 652 20.4 | 86.554679 | 48.920443 | group25 | . 653 18.3 | 78.666079 | 49.882650 | group20 | . 654 12.8 | 52.771364 | 46.613159 | group15 | . 655 6.7 | 40.736731 | 44.902513 | group10 | . 656 rows × 4 columns . from plotnine import * . ggplot(data=df1)+geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),alpha=0.5) . &lt;ggplot: (8780268732441)&gt; . ggplot(data=df1)+geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),alpha=0.2)+geom_smooth(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),size=2,linetype=&#39;dashed&#39;) . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8780268015601)&gt; . - 온도를 통제하니까 아이스크림과 질병은 관련이 없어보인다. . &#51652;&#51676; &#47564;&#50557;&#50640; &#50500;&#51060;&#49828;&#53356;&#47548;&#44284; &#49548;&#50500;&#47560;&#48708;&#44032; &#44288;&#47144;&#51080;&#45716; &#44221;&#50864;&#46972;&#47732;? . np.random.seed(1) ϵ1=np.random.normal(size=656, scale=10) icecream=temp*2 + 30 + ϵ1 . np.random.seed(2) ϵ2=np.random.normal(size=656,scale=1) disease= 30+ temp*0.0 + icecream*0.15 +ϵ2*2 . df2=pd.DataFrame({&#39;temp&#39;:temp,&#39;icecream&#39;:icecream,&#39;disease&#39;:disease}) df2[&#39;temp2&#39;]=list(map(f,df2.temp)) . df2 . temp icecream disease temp2 . 0 -0.5 | 45.243454 | 35.953002 | group0 | . 1 1.4 | 26.682436 | 33.889832 | group5 | . 2 2.6 | 29.918282 | 30.215350 | group5 | . 3 2.0 | 23.270314 | 36.771089 | group5 | . 4 2.5 | 43.654076 | 32.961240 | group5 | . ... ... | ... | ... | ... | . 651 19.9 | 78.839992 | 41.193811 | group20 | . 652 20.4 | 86.554679 | 40.424088 | group25 | . 653 18.3 | 78.666079 | 43.265212 | group20 | . 654 12.8 | 52.771364 | 38.342022 | group15 | . 655 6.7 | 40.736731 | 39.215537 | group10 | . 656 rows × 4 columns . ggplot(data=df2)+geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),alpha=0.2)+geom_smooth(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),size=2,linetype=&#39;dashed&#39;) . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8780335021228)&gt; . df1.corr() . temp icecream disease . temp 1.000000 | 0.884366 | 0.975609 | . icecream 0.884366 | 1.000000 | 0.862990 | . disease 0.975609 | 0.862990 | 1.000000 | . df2.corr() . temp icecream disease . temp 1.000000 | 0.884366 | 0.725505 | . icecream 0.884366 | 1.000000 | 0.830539 | . disease 0.725505 | 0.830539 | 1.000000 | . &#49689;&#51228; . - 온도구간을 10으로 변경하고 df1, df2에서 아이스크림과 소아마비의 산점도를 시각화한뒤 스크린샷 제출 .",
            "url": "https://minji219.github.io/zw/2021/10/18/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9418%EC%9D%BC.html",
            "relUrl": "/2021/10/18/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9418%EC%9D%BC.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "(6주차) 10월13일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/1) rpy2 . - (2/7) 데이터를 읽어오는법, 기본산점도 . - (3/7) 산점도응용 (3차원) . - (4/7) 산점도응용 (4차원) . - (5/7) 판다스에서 열을 선택하는 방법 . - (6/7) 판다스에서 lambda와 map을 이용하여 열을 선택하는 방법 . - (7/7) 판다스에서 lambda와 map을 이용하여 열을 선택하는 방법 (2) . &#54644;&#46308;&#47532;&#50948;&#52980; &#44536;&#47000;&#54532;&#47112;&#51060;&#50612; . import . import pandas as pd from plotnine import * . data . - ref: https://r4ds.had.co.nz/index.html . rpy2 . import rpy2 . %load_ext rpy2.ipython . %%R ### 여기는 R처럼 쓸 수 있다. a&lt;-c(1,2,3) a+1 . [1] 2 3 4 . a . NameError Traceback (most recent call last) /tmp/ipykernel_2170811/2167009006.py in &lt;module&gt; -&gt; 1 a NameError: name &#39;a&#39; is not defined . %%R library(tidyverse) mpg . R[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── R[write to console]: ✔ ggplot2 3.3.5 ✔ purrr 0.3.4 ✔ tibble 3.1.3 ✔ dplyr 1.0.7 ✔ tidyr 1.1.3 ✔ stringr 1.4.0 ✔ readr 1.4.0 ✔ forcats 0.5.1 R[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ✖ dplyr::filter() masks stats::filter() ✖ dplyr::lag() masks stats::lag() . # A tibble: 234 × 11 manufacturer model displ year cyl trans drv cty hwy fl class &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 1 audi a4 1.8 1999 4 auto… f 18 29 p comp… 2 audi a4 1.8 1999 4 manu… f 21 29 p comp… 3 audi a4 2 2008 4 manu… f 20 31 p comp… 4 audi a4 2 2008 4 auto… f 21 30 p comp… 5 audi a4 2.8 1999 6 auto… f 16 26 p comp… 6 audi a4 2.8 1999 6 manu… f 18 26 p comp… 7 audi a4 3.1 2008 6 auto… f 18 27 p comp… 8 audi a4 quattro 1.8 1999 4 manu… 4 18 26 p comp… 9 audi a4 quattro 1.8 1999 4 auto… 4 16 25 p comp… 10 audi a4 quattro 2 2008 4 manu… 4 20 28 p comp… # … with 224 more rows . mpg . NameError Traceback (most recent call last) /tmp/ipykernel_2170811/602803287.py in &lt;module&gt; -&gt; 1 mpg NameError: name &#39;mpg&#39; is not defined . %R -o mpg # R에 있던 자료가 파이썬으로 넘어옴 . mpg . manufacturer model displ year cyl trans drv cty hwy fl class . 1 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 2 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 4 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 5 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 230 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 231 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 233 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 234 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . &#51200;&#51109;&#46108; &#54028;&#51068;&#51012; &#53685;&#54616;&#50668; &#45936;&#51060;&#53552;&#47484; &#54869;&#48372; . mpg.to_csv(&quot;mpg.csv&quot;) . pd.read_csv(&quot;mpg.csv&quot;) # mpg = pd.read_csv(&quot;mpg.csv&quot;) . Unnamed: 0 manufacturer model displ year cyl trans drv cty hwy fl class . 0 1 | audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 2 | audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 3 | audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 4 | audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 5 | audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 229 230 | volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 230 231 | volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 231 232 | volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 232 233 | volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 233 234 | volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 12 columns . - 무언가 잘못되었다? . - 다시 저장하자. . mpg.to_csv(&quot;mpg.csv&quot;,index=False) . pd.read_csv(&quot;mpg.csv&quot;) # mpg=pd.read_csv(&quot;mpg.csv&quot;) . manufacturer model displ year cyl trans drv cty hwy fl class . 0 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 229 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 230 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 231 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 233 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . 제대로 불러졌음 | . github&#46321;&#50640; &#44277;&#44060;&#46108; csv&#47484; &#51069;&#50612;&#50724;&#44592; . pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/mpg.csv&#39;) # mpg=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/mpg.csv&#39;) . manufacturer model displ year cyl trans drv cty hwy fl class . 0 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 1 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 2 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 4 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 229 volkswagen | passat | 2.0 | 2008 | 4 | auto(s6) | f | 19 | 28 | p | midsize | . 230 volkswagen | passat | 2.0 | 2008 | 4 | manual(m6) | f | 21 | 29 | p | midsize | . 231 volkswagen | passat | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | midsize | . 232 volkswagen | passat | 2.8 | 1999 | 6 | manual(m5) | f | 18 | 26 | p | midsize | . 233 volkswagen | passat | 3.6 | 2008 | 6 | auto(s6) | f | 17 | 26 | p | midsize | . 234 rows × 11 columns . - 깃허브 저장소에 아예 데이터만 따로 모아서 관리하는 것도 좋은 방법입니다. . data &#49444;&#47749; . - displ: 자동차의 엔진크기 . - hwy: 연료의 효율, 동일한 연료로 얼마나 멀리 가느냐? . - 자세한 설명은 R에서 ?mpg로 알아볼것 . &#44592;&#48376;&#49328;&#51216;&#46020; (2&#52264;&#50896;) . ggplot(data = mpg) + geom_point(mapping = aes(x = &quot;displ&quot;, y = &quot;hwy&quot;)) ## plotnine . &lt;ggplot: (8784362403904)&gt; . 산점도: 엔진크기와 연료효율은 반비례. (엔진이 큰 차일수록 연비가 좋지 않다) | . - ggplot2를 이용한 산점도 . %%R -w 800 ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) ## 진짜 ggplot에서 그릴때에는 변수이름에 &quot;&quot; 를 제거함 . - 객체지향적인 느낌으로 산점도 그리기 . step1: 도화지를 준비한다 . fig=ggplot(data=mpg) fig . &lt;ggplot: (8784356495638)&gt; . step2: 변수와 에스테틱사이의 맵핑을 설정한다. . a1=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;) a1 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;} . step3: 점들의 집합을 만든다. 즉 포인트지옴을 만든다. . point1=geom_point(mapping=a1) . geom_point(): 점들을 그려! 어떻게? | a1에서 설정된 표를 보고 | . step4: 도화지와 지옴을 합친다. . fig+point1 . &lt;ggplot: (8784356403231)&gt; . - 빠르게 그리기: mapping = 와 data=는 생략가능함 . ggplot(mpg) + geom_point(aes(x = &quot;displ&quot;, y = &quot;hwy&quot;)) ## plotnine . &lt;ggplot: (8784356355518)&gt; . &#49328;&#51216;&#46020;&#51025;&#50857; (3&#52264;&#50896;) . - 데이터를 다시관찰 . mpg.head() . manufacturer model displ year cyl trans drv cty hwy fl class . 1 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 2 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 4 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 5 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . - class도 함께 plot에 표시하면 데이터를 탐색할때 좀 더 좋을것 같다. . &#49328;&#51216;&#46020; + &#51216;&#53356;&#44592;&#48320;&#44221; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,size= &#39;class&#39;)) . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8784356327762)&gt; . &#49328;&#51216;&#46020; + &#53804;&#47749;&#46020;&#48320;&#44221; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,alpha= &#39;class&#39;)) . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_alpha.py:68: PlotnineWarning: Using alpha for a discrete variable is not advised. . &lt;ggplot: (8784356297638)&gt; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,size= &#39;class&#39;,alpha=&#39;class&#39;)) . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_alpha.py:68: PlotnineWarning: Using alpha for a discrete variable is not advised. . &lt;ggplot: (8784356241740)&gt; . &#49328;&#51216;&#46020; + &#54805;&#53468; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,shape=&#39;class&#39;)) . &lt;ggplot: (8784356201093)&gt; . &#49328;&#51216;&#46020; + &#49353;&#44628; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;)) . &lt;ggplot: (8784356360406)&gt; . - 객체지향적으로? . a2=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;) . a1,a2 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . point2=geom_point(a2) . fig+point2 . &lt;ggplot: (8784356129871)&gt; . &#51648;&#50740;&#51012; &#45908; &#52628;&#44032; (&#51201;&#54633;&#49440;) . fig+point1 . &lt;ggplot: (8784181694823)&gt; . sline1=geom_smooth(a1) . fig+point1+sline1 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8784181645499)&gt; . fig+point2+sline1 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8784181617902)&gt; . - 명령어로 한번에 그리기 . ggplot(data=mpg)+geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;))+geom_smooth(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;)) . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8784181506021)&gt; . - 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함) . ggplot(data=mpg,mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;))+geom_point(mapping=aes(color=&#39;class&#39;))+geom_smooth() . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8784181519761)&gt; . - R에서는 confidence interval도 geom_smooth()를 이용하여 확인할 수 있다. . %%R -w 800 ggplot(data=mpg,mapping=aes(x=displ,y=hwy))+geom_point(mapping=aes(color=class))+geom_smooth() . R[write to console]: `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; . &#49328;&#51216;&#46020;&#51025;&#50857;2 (4&#52264;&#50896;) . - 데이터를 살펴보자. . mpg.head() . manufacturer model displ year cyl trans drv cty hwy fl class . 1 audi | a4 | 1.8 | 1999 | 4 | auto(l5) | f | 18 | 29 | p | compact | . 2 audi | a4 | 1.8 | 1999 | 4 | manual(m5) | f | 21 | 29 | p | compact | . 3 audi | a4 | 2.0 | 2008 | 4 | manual(m6) | f | 20 | 31 | p | compact | . 4 audi | a4 | 2.0 | 2008 | 4 | auto(av) | f | 21 | 30 | p | compact | . 5 audi | a4 | 2.8 | 1999 | 6 | auto(l5) | f | 16 | 26 | p | compact | . - drv (전륜, 후륜, 4륜 구동)에 따라서 데이터를 시각화 하고 싶다. . ggplot(data=mpg,mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;))+geom_point(mapping=aes(size=&#39;class&#39;,color=&#39;drv&#39;),alpha=0.2) . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8784181695124)&gt; . 모든 $x$에 대하여 붉은색 점들이 대부분 초록선과 보라색 점들에 비하여 아래쪽에 위치하여 있음 $ to$ 4륜구동방식이 연비가 좋지 않음 | . - 객체지향적 . a1,a2 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . a3=a2.copy() . id(a1),id(a2),id(a3) . (140549703310128, 140549698707184, 140549699928368) . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . a3[&#39;color&#39;]=&#39;drv&#39; a3[&#39;size&#39;]=&#39;class&#39; . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}) . 아래와 같이 선언해도 괜찮음 a3=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;drv&#39;,size=&#39;class&#39;) . | . point3=geom_point(a3) . fig+point3 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8784181514132)&gt; . 앗 투명도 조절 | . point3=geom_point(a3,alpha=0.2) fig+point3 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (8784356384317)&gt; . - 여기에 선을 추가하여 보자. . fig+point3+sline1 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8784356334797)&gt; . - 각 그룹별로 선을 따로 그릴수도 있을까? . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}) . a4=a2.copy() . a4[&#39;color&#39;]=&#39;drv&#39; . sline2=geom_smooth(a4) . fig+sline2+point3 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8784356384500)&gt; . - 선의 색깔을 동일하게 하고 선의 타입을 변경하여 그룹을 표시할수도 있지 않을까? . a1,a2,a3,a4 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;}) . a5=a1.copy() . a5[&#39;linetype&#39;]=&#39;drv&#39; . a5 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;linetype&#39;: &#39;drv&#39;} . sline3=geom_smooth(a5,size=0.5,color=&#39;gray&#39;) . fig+point3+sline3 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8784176884764)&gt; . fig+point3+sline3+sline1 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8784176769018)&gt; . - 그래도 색깔로 구분하는것이 나은것 같다. . sline2=geom_smooth(a4,size=0.5,linetype=&#39;dashed&#39;) fig+point3+sline2+sline1 . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/scales/scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (8784176718963)&gt; . - 고차원의 변수를 표현할 수 있는 무기는 다양하다. . 산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도 | 라인플랏(스무스지옴, 라인지옴): 선의형태, 선의색깔, 선의굵기 | . &#44208;&#47200; . - 잘 훈련한다면 여러가지 형태의 고차원 그래프를 우리도 그릴 수 있다. (마치 미나드처럼) . - 해들리위컴은 이러한 방법을 체계적으로 정리했다고 보여진다. . - 해들리위컴: 그래프는 데이터 + 지옴 + 맵핑(변수와 에스테틱간의 맵핑) + 스탯(통계) + 포지션 + 축 + 패싯그리드 7개의 조합으로 그릴수 있다. . 내생각: 지옴과 맵핑만 잘 이용해도 아주 다양한 그래프를 그릴 수 있음. | . &#54032;&#45796;&#49828;&#50640;&#49436; column&#51012; &#49440;&#53469;&#54616;&#45716; &#48169;&#48277; . import . &#50696;&#51228;1 . import numpy as np . dic={&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5)} df=pd.DataFrame(dic) df . X1 X2 X3 . 0 1.364717 | 0.775949 | 1.685477 | . 1 0.853549 | -0.401712 | -1.285741 | . 2 -0.383503 | -0.950388 | 0.028700 | . 3 -0.639761 | -0.384636 | 2.567487 | . 4 -0.742307 | -1.738164 | 1.022246 | . - 방법1 . df.X1 . 0 1.364717 1 0.853549 2 -0.383503 3 -0.639761 4 -0.742307 Name: X1, dtype: float64 . - 방법2 . df[&#39;X1&#39;] . 0 1.364717 1 0.853549 2 -0.383503 3 -0.639761 4 -0.742307 Name: X1, dtype: float64 . - 방법3 . df[[&#39;X1&#39;]] . X1 . 0 1.364717 | . 1 0.853549 | . 2 -0.383503 | . 3 -0.639761 | . 4 -0.742307 | . df[&#39;X1&#39;]는 series를 리턴하고 df[[&#39;X1&#39;]]는 dataframe을 리턴한다. | . - 방법4 . df.loc[:,&#39;X1&#39;] . 0 1.364717 1 0.853549 2 -0.383503 3 -0.639761 4 -0.742307 Name: X1, dtype: float64 . - 방법5 . df.loc[:,[&#39;X1&#39;]] . X1 . 0 1.364717 | . 1 0.853549 | . 2 -0.383503 | . 3 -0.639761 | . 4 -0.742307 | . df.loc[:,&#39;X1&#39;]는 series를 리턴하고 df.loc[:,[&#39;X1&#39;]]는 dataframe을 리턴한다. | . - 방법6 . df.loc[:,[True,False,False]] . X1 . 0 1.364717 | . 1 0.853549 | . 2 -0.383503 | . 3 -0.639761 | . 4 -0.742307 | . 불인덱싱가능 | . - 방법7 . df.iloc[:,0] . 0 1.364717 1 0.853549 2 -0.383503 3 -0.639761 4 -0.742307 Name: X1, dtype: float64 . - 방법8 . df.iloc[:,[0]] . X1 . 0 1.364717 | . 1 0.853549 | . 2 -0.383503 | . 3 -0.639761 | . 4 -0.742307 | . - 방법9 . df.iloc[:,[True,False,False]] . X1 . 0 1.364717 | . 1 0.853549 | . 2 -0.383503 | . 3 -0.639761 | . 4 -0.742307 | . &#52280;&#44256;&#49324;&#54637;: &#50676;&#51060;&#47492;&#51060; interger&#51068; &#44221;&#50864; . import numpy as np . _df = pd.DataFrame(np.array([[1,2,3],[3,4,5],[5,6,7]])) _df . 0 1 2 . 0 1 | 2 | 3 | . 1 3 | 4 | 5 | . 2 5 | 6 | 7 | . - 아래가 모두 가능하다. . _df[0] . 0 1 1 3 2 5 Name: 0, dtype: int64 . _df[[0]] . 0 . 0 1 | . 1 3 | . 2 5 | . _df.loc[:,0] . 0 1 1 3 2 5 Name: 0, dtype: int64 . _df.loc[:,[0]] . 0 . 0 1 | . 1 3 | . 2 5 | . _df.iloc[:,0] . 0 1 1 3 2 5 Name: 0, dtype: int64 . data . _df.iloc[:,[0]] . 0 . 0 1 | . 1 3 | . 2 5 | . &#48169;&#48277;1~9&#51032; &#50836;&#50557; (&#51228; &#49373;&#44033;) . - df.X1로 열을 선택하는게 간단하고 편리함. . 단점1: 변수이름을 알고 있어야 한다는 단점이 있음. | 단점2: 변수이름에 .이 있거나 변수이름에서 공백이 있을경우 사용할 수 없음. | . - 언급한 단점의 예시 . dic={&#39;X.1&#39;:np.random.normal(0,1,5), &#39;X.2&#39;:np.random.normal(0,1,5), &#39;X.3&#39;:np.random.normal(0,1,5)} _df=pd.DataFrame(dic) _df . X.1 X.2 X.3 . 0 -0.674886 | 0.248970 | -0.168482 | . 1 0.217904 | -0.633454 | 0.261744 | . 2 -0.338874 | 0.876894 | -2.196765 | . 3 2.476408 | 0.901102 | 0.199516 | . 4 0.710193 | -1.691488 | -0.907115 | . _df[&#39;X.1&#39;] . 0 -0.674886 1 0.217904 2 -0.338874 3 2.476408 4 0.710193 Name: X.1, dtype: float64 . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) . _df.X.1 . File &#34;/tmp/ipykernel_2170811/58401248.py&#34;, line 1 _df.X.1 ^ SyntaxError: invalid syntax . &#50696;&#51228;2: &#50668;&#47084;&#44060;&#51032; &#50676;&#51012; &#49440;&#53469; . - 데이터 . dic={&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5), &#39;X4&#39;:np.random.normal(0,1,5)} df=pd.DataFrame(dic) df . X1 X2 X3 X4 . 0 1.408453 | -0.170602 | -1.454650 | -0.047064 | . 1 1.093401 | 1.108376 | -0.746791 | -0.037699 | . 2 -0.320964 | -1.183577 | 1.228422 | 0.415494 | . 3 -1.460182 | -0.912314 | -0.262836 | -1.569006 | . 4 0.160380 | 0.824893 | 1.442562 | -0.450621 | . - 목표: 1,2,3열을 선택 . - 방법1 . df[[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;]] . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . - 방법2 . df.loc[:,[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;]] . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . - 방법3 . df.loc[:,&#39;X1&#39;:&#39;X3&#39;] . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . - 방법4 . df.loc[:,[True,True,True,False]] . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . - 방법5 . df.iloc[:,[0,1,2]] . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . - 방법6 . df.iloc[:,:3] . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . df.iloc[:,0:3] . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . df.iloc[:,range(3)] . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . - 방법7 . df.iloc[:,[True,True,True,False]] . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . (주의) loc에서의 슬라이싱은 마지막변수를 포함하지만 iloc에서는 포함하지 않음 . - 아래를 비교하라. . df.iloc[:,0:3] ## 0,1,2,3중 3은 포함되지 않는다. . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . df.loc[:,&#39;X1&#39;:&#39;X3&#39;] ## &#39;X3&#39;도 포함된다. . X1 X2 X3 . 0 1.408453 | -0.170602 | -1.454650 | . 1 1.093401 | 1.108376 | -0.746791 | . 2 -0.320964 | -1.183577 | 1.228422 | . 3 -1.460182 | -0.912314 | -0.262836 | . 4 0.160380 | 0.824893 | 1.442562 | . - 그래서 column의 이름이 integer일 경우는 종종 매우 헷갈리는 일이 일어남 . _df = pd.DataFrame(np.array([[1,2,3,4],[3,4,5,6],[5,6,7,8]])) _df . 0 1 2 3 . 0 1 | 2 | 3 | 4 | . 1 3 | 4 | 5 | 6 | . 2 5 | 6 | 7 | 8 | . _df.loc[:,0:2] . 0 1 2 . 0 1 | 2 | 3 | . 1 3 | 4 | 5 | . 2 5 | 6 | 7 | . _df.iloc[:,0:2] . 0 1 . 0 1 | 2 | . 1 3 | 4 | . 2 5 | 6 | . . Note: 사실 이것은 일부러 헷갈리게 예제를 구성한 것이다. 실제로는 헷갈리는 상황이 그렇게 자주 발생하지 않는다. 왜냐하면 보통 위와 같은 형태의 자료는 ndarray로 처리하고 colname이 있는 경우만 데이터프레임으로 처리하기 때문. . &#50696;&#51228;3: movie data - &#53945;&#51221;&#51312;&#44148;&#50640; &#47582;&#45716; &#50676;&#51012; &#49440;&#53469; . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) df . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres ... num_user_for_reviews language country content_rating budget title_year actor_2_facebook_likes imdb_score aspect_ratio movie_facebook_likes . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | ... | 3054.0 | English | USA | PG-13 | 237000000.0 | 2009.0 | 936.0 | 7.9 | 1.78 | 33000 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | ... | 1238.0 | English | USA | PG-13 | 300000000.0 | 2007.0 | 5000.0 | 7.1 | 2.35 | 0 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | ... | 994.0 | English | UK | PG-13 | 245000000.0 | 2015.0 | 393.0 | 6.8 | 2.35 | 85000 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | ... | 2701.0 | English | USA | PG-13 | 250000000.0 | 2012.0 | 23000.0 | 8.5 | 2.35 | 164000 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | ... | NaN | NaN | NaN | NaN | NaN | NaN | 12.0 | 7.1 | NaN | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | ... | 6.0 | English | Canada | NaN | NaN | 2013.0 | 470.0 | 7.7 | NaN | 84 | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | ... | 359.0 | English | USA | TV-14 | NaN | NaN | 593.0 | 7.5 | 16.00 | 32000 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | ... | 3.0 | English | USA | NaN | 1400.0 | 2013.0 | 0.0 | 6.3 | NaN | 16 | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | ... | 9.0 | English | USA | PG-13 | NaN | 2012.0 | 719.0 | 6.3 | 2.35 | 660 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | ... | 84.0 | English | USA | PG | 1100.0 | 2004.0 | 23.0 | 6.6 | 1.85 | 456 | . 4916 rows × 28 columns . - 열의 이름을 출력하여 보자. . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . - color ~ num_voted_user 를 뽑고 + aspect_ratio 도 추가적으로 뽑고싶다. . df.loc[:,[&#39;color&#39;:&#39;num_voted_users&#39;,&#39;aspect_ratio&#39;]] . File &#34;/tmp/ipykernel_2170811/1210972629.py&#34;, line 1 df.loc[:,[&#39;color&#39;:&#39;num_voted_users&#39;,&#39;aspect_ratio&#39;]] ^ SyntaxError: invalid syntax . - (팁) 복잡한 조건은 iloc으로 쓰는게 편할때가 있다. $ to$ 그런데 df.columns 변수들이 몇번인지 알아보기 힘듬 $ to$ 아래와 같이 하면 열의 이름을 인덱스와 함께 출력할 수 있음 . pd.Series(df.columns) . 0 color 1 director_name 2 num_critic_for_reviews 3 duration 4 director_facebook_likes 5 actor_3_facebook_likes 6 actor_2_name 7 actor_1_facebook_likes 8 gross 9 genres 10 actor_1_name 11 movie_title 12 num_voted_users 13 cast_total_facebook_likes 14 actor_3_name 15 facenumber_in_poster 16 plot_keywords 17 movie_imdb_link 18 num_user_for_reviews 19 language 20 country 21 content_rating 22 budget 23 title_year 24 actor_2_facebook_likes 25 imdb_score 26 aspect_ratio 27 movie_facebook_likes dtype: object . list(range(13))+[26] . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26] . df.iloc[:,list(range(13))+[26]] . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres actor_1_name movie_title num_voted_users aspect_ratio . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | CCH Pounder | Avatar | 886204 | 1.78 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | Johnny Depp | Pirates of the Caribbean: At World&#39;s End | 471220 | 2.35 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | Christoph Waltz | Spectre | 275868 | 2.35 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | Tom Hardy | The Dark Knight Rises | 1144337 | 2.35 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | Doug Walker | Star Wars: Episode VII - The Force Awakens | 8 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | Eric Mabius | Signed Sealed Delivered | 629 | NaN | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | Natalie Zea | The Following | 73839 | 16.00 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | Eva Boehnke | A Plague So Pleasant | 38 | NaN | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | Alan Ruck | Shanghai Calling | 1255 | 2.35 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | John August | My Date with Drew | 4285 | 1.85 | . 4916 rows × 14 columns . - 다시열의 이름들을 확인 . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . actor&#46972;&#45716; &#45800;&#50612;&#44032; &#54252;&#54632;&#46108; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . - 방법1 . df.iloc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns) )] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법2 . df.loc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns) )] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법3 . df.iloc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법4 . df.loc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법5 . df.loc[:,filter(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . &#48320;&#49688;&#51060;&#47492;&#51060; s&#47196; &#45149;&#45208;&#45716; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . df.iloc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . num_critic_for_reviews director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes gross genres num_voted_users cast_total_facebook_likes plot_keywords num_user_for_reviews actor_2_facebook_likes movie_facebook_likes . 0 723.0 | 0.0 | 855.0 | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | 886204 | 4834 | avatar|future|marine|native|paraplegic | 3054.0 | 936.0 | 33000 | . 1 302.0 | 563.0 | 1000.0 | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | 471220 | 48350 | goddess|marriage ceremony|marriage proposal|pi... | 1238.0 | 5000.0 | 0 | . 2 602.0 | 0.0 | 161.0 | 11000.0 | 200074175.0 | Action|Adventure|Thriller | 275868 | 11700 | bomb|espionage|sequel|spy|terrorist | 994.0 | 393.0 | 85000 | . 3 813.0 | 22000.0 | 23000.0 | 27000.0 | 448130642.0 | Action|Thriller | 1144337 | 106759 | deception|imprisonment|lawlessness|police offi... | 2701.0 | 23000.0 | 164000 | . 4 NaN | 131.0 | NaN | 131.0 | NaN | Documentary | 8 | 143 | NaN | NaN | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 1.0 | 2.0 | 318.0 | 637.0 | NaN | Comedy|Drama | 629 | 2283 | fraud|postal worker|prison|theft|trial | 6.0 | 470.0 | 84 | . 4912 43.0 | NaN | 319.0 | 841.0 | NaN | Crime|Drama|Mystery|Thriller | 73839 | 1753 | cult|fbi|hideout|prison escape|serial killer | 359.0 | 593.0 | 32000 | . 4913 13.0 | 0.0 | 0.0 | 0.0 | NaN | Drama|Horror|Thriller | 38 | 0 | NaN | 3.0 | 0.0 | 16 | . 4914 14.0 | 0.0 | 489.0 | 946.0 | 10443.0 | Comedy|Drama|Romance | 1255 | 2386 | NaN | 9.0 | 719.0 | 660 | . 4915 43.0 | 16.0 | 16.0 | 86.0 | 85222.0 | Documentary | 4285 | 163 | actress name in title|crush|date|four word tit... | 84.0 | 23.0 | 456 | . 4916 rows × 12 columns . df.loc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . num_critic_for_reviews director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes gross genres num_voted_users cast_total_facebook_likes plot_keywords num_user_for_reviews actor_2_facebook_likes movie_facebook_likes . 0 723.0 | 0.0 | 855.0 | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | 886204 | 4834 | avatar|future|marine|native|paraplegic | 3054.0 | 936.0 | 33000 | . 1 302.0 | 563.0 | 1000.0 | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | 471220 | 48350 | goddess|marriage ceremony|marriage proposal|pi... | 1238.0 | 5000.0 | 0 | . 2 602.0 | 0.0 | 161.0 | 11000.0 | 200074175.0 | Action|Adventure|Thriller | 275868 | 11700 | bomb|espionage|sequel|spy|terrorist | 994.0 | 393.0 | 85000 | . 3 813.0 | 22000.0 | 23000.0 | 27000.0 | 448130642.0 | Action|Thriller | 1144337 | 106759 | deception|imprisonment|lawlessness|police offi... | 2701.0 | 23000.0 | 164000 | . 4 NaN | 131.0 | NaN | 131.0 | NaN | Documentary | 8 | 143 | NaN | NaN | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 1.0 | 2.0 | 318.0 | 637.0 | NaN | Comedy|Drama | 629 | 2283 | fraud|postal worker|prison|theft|trial | 6.0 | 470.0 | 84 | . 4912 43.0 | NaN | 319.0 | 841.0 | NaN | Crime|Drama|Mystery|Thriller | 73839 | 1753 | cult|fbi|hideout|prison escape|serial killer | 359.0 | 593.0 | 32000 | . 4913 13.0 | 0.0 | 0.0 | 0.0 | NaN | Drama|Horror|Thriller | 38 | 0 | NaN | 3.0 | 0.0 | 16 | . 4914 14.0 | 0.0 | 489.0 | 946.0 | 10443.0 | Comedy|Drama|Romance | 1255 | 2386 | NaN | 9.0 | 719.0 | 660 | . 4915 43.0 | 16.0 | 16.0 | 86.0 | 85222.0 | Documentary | 4285 | 163 | actress name in title|crush|date|four word tit... | 84.0 | 23.0 | 456 | . 4916 rows × 12 columns . &#48320;&#49688;&#51060;&#47492;&#51060; c &#54841;&#51008; d&#47196; &#49884;&#51089;&#54616;&#45716; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . df.iloc[:,map(lambda x: &#39;c&#39; == x[0] or &#39;d&#39; == x[0] ,df.columns )] . color director_name duration director_facebook_likes cast_total_facebook_likes country content_rating . 0 Color | James Cameron | 178.0 | 0.0 | 4834 | USA | PG-13 | . 1 Color | Gore Verbinski | 169.0 | 563.0 | 48350 | USA | PG-13 | . 2 Color | Sam Mendes | 148.0 | 0.0 | 11700 | UK | PG-13 | . 3 Color | Christopher Nolan | 164.0 | 22000.0 | 106759 | USA | PG-13 | . 4 NaN | Doug Walker | NaN | 131.0 | 143 | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 87.0 | 2.0 | 2283 | Canada | NaN | . 4912 Color | NaN | 43.0 | NaN | 1753 | USA | TV-14 | . 4913 Color | Benjamin Roberds | 76.0 | 0.0 | 0 | USA | NaN | . 4914 Color | Daniel Hsia | 100.0 | 0.0 | 2386 | USA | PG-13 | . 4915 Color | Jon Gunn | 90.0 | 16.0 | 163 | USA | PG | . 4916 rows × 7 columns . &#49689;&#51228; . movie data frame에서 &#39;face&#39;라는 단어가 포함된 변수열을 선택하라. .",
            "url": "https://minji219.github.io/zw/2021/10/13/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9413%EC%9D%BC.html",
            "relUrl": "/2021/10/13/(6%EC%A3%BC%EC%B0%A8)-10%EC%9B%9413%EC%9D%BC.html",
            "date": " • Oct 13, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "(5주차) 10월6일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/9) 공지사항 . - (2/9) qqplot . - (3/9) 정규분포, t분포 qqplot 비교 . - (4/9) 분위수를 구하는 다양한 방법 . - (5/9) lambda . - (6/9) map (1) . - (7/9) map (2) . - (8/9) 에드워드 터프티, 찰스미나드의 도표. . - (9/9) 과제설명 . &#50696;&#51228; (qqplot): . - 히스토그램이나 박스플랏보다 분포를 특정하기에 좋은 시각화는 없을까? . import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns from scipy import stats . np.random.seed(43052) x=np.random.normal(size=1000,loc=2,scale=1.5) y=stats.t.rvs(df=10,size=1000)/np.sqrt(10/8)*1.5 + 2 . - 우리가 관측한 $x_1, dots,x_{1000}$이 $N(2,1.5^2)$에서 나온 샘플인지 궁금하다. . - 아이디어 . (1) 관측한 값을 순서대로 나열하여 $x_{(1)},x_{(2)}, dots, x_{(1000)}$을 만든다. . x[:2] . array([2.57513073, 3.62626175]) . $x_1=2.57513073, quad x_2=3.62626175$ | . x.sort() . x[:2] . array([-2.44398446, -2.14071467]) . $x_{(1)}= -2.44398446, quad x_{(2)}=-2.14071467$ | . (2) 파이썬이나 R로 $N(2,1.5^2)$에서 1000개의 정규분포를 생성. 그리고 순서대로 나열하여 $ tilde{x}_{(1)}, tilde{x}_{(2)}, dots, tilde{x}_{(1000)}$를 만든다. . (3) $x_{(1)} approx tilde{x}_{(1)}, dots , x_{(1000)} approx tilde{x}_{(1000)}$ 이면 x는 정규분포일것 . - 그런데 $ tilde{x}_{(1)}, tilde{x}_{(2)}, dots, tilde{x}_{(1000)}$은 시뮬레이션을 할때마다 다른값이 나올테니까 불안정한 느낌이 든다. $ to$ 이론적인 값을 계산하자. . xx = (x-np.mean(x)) / np.std(x,ddof=1) xx[:2] . array([-3.05569305, -2.84275629]) . 실제우리가 관측한값 | . print(stats.norm.ppf(0.001)) print(stats.norm.ppf(0.002)) . -3.090232306167813 -2.878161739095483 . 이론적인 값 | . - 분위수 . m=[i/1000 for i in np.arange(1000)+1] . q=[] for i in range(len(m)): q=q+[stats.norm.ppf(m[i])] . q[:2] . [-3.090232306167813, -2.878161739095483] . - $xx approx q$ 을 확인하기 위해서 $(q,q)$그래프와 $(q,xx)$의 그래프를 그려서 겹쳐보자. . plt.plot(q,xx,&#39;o&#39;) plt.plot(q,q,&#39;-&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f9da16b5df0&gt;] . 해석: 점들이 주황색선 근처에 모여있을수록 정규분포에 가깝다. | . - 아래와 같이 쉽게 그릴수도 있다. (우리가 그린그림과 조금 다르게 보인다) . _ = stats.probplot(x,plot=plt) . 자세히보면 조금 다르게 그려지긴 하는데 이는 $m=( frac{1}{1000}, dots, frac{999}{1000}, frac{1000}{1000})$와 같이 계산하지 않고 약간 보정한값을 계산하기 때문임 | stats.probplot? 을 통하여 확인한 결과 아래와 같은 코드로 구현됨### 보정하는방법1 n=len(xx) m=[((i+1)-0.3175)/(n+0.365) for i in range(n)] m[-n]=0.5**(1/n) m[0]=1-m[-n] . | 프로그램에 따라서 아래와 같이 보정하는 경우도 있음### 보정하는방법2 m=[(i-3/8)/(n+1/4) for i in np.arange(1000)+1] . | 또 자세히보면 stats.probplot은 y축에 표준화전의 x값이 있음을 알 수 있음. | . - 정규분포와 t분포의 qqplot을 그려서 비교해보자. . _ = stats.probplot(x,plot=plt) # 정규분포 . 정규분포 | . _ = stats.probplot(y,plot=plt) # t분포 . t분포: 푸른점들이 대체로 붉은선위에 놓여있는듯 하지만 양끝단에서는 그렇지 않다. (중앙부근은 정규분포와 비슷하지만, 꼬리부분은 정규분포와 확실히 다르다) | 왼쪽꼬리: 이론적으로 나와야 할 값보다 더 작은값이 실제로 관측됨 | 오른쪽꼬리: 이론적으로 나와야 할 값보다 더 큰값이 실제로 관측됨 | 해석: 이 분포는 정규분포보다 두꺼운 꼬리를 가진다. | . - 서브플랏팅: 두 분포를 양옆에 나란히 비교하고 싶음 . fig , (ax1,ax2) = plt.subplots(1,2) . _ = stats.probplot(x,plot=ax1) _ = stats.probplot(y,plot=ax2) . fig . fig.set_figwidth(8) . fig . ax1.set_title(&#39;normal dist&#39;) ax2.set_title(&#39;t dist&#39;) . Text(0.5, 1.0, &#39;t dist&#39;) . fig . &#50696;&#51228;4 (boxplot, histrogram, qqplot) . - 박스플랏, 히스토그램, qqplot을 그려보자. . fig, ax =plt.subplots(2,3) . (ax1,ax2,ax3), (ax4,ax5,ax6) = ax . sns.boxplot(x,ax=ax1) sns.histplot(x,kde=True,ax=ax2) _ = stats.probplot(x,plot=ax3) sns.boxplot(y,ax=ax4) sns.histplot(y,kde=True,ax=ax5) _ = stats.probplot(y,plot=ax6) . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( . fig . fig.set_figwidth(10) fig.set_figheight(8) fig.tight_layout() . fig . Appendix: &#48516;&#50948;&#49688;&#47484; &#44396;&#54616;&#45716; &#45796;&#50577;&#54620;&#48169;&#48277; . m=[i/1000 for i in np.arange(1000)+1] . $m= big { frac{i}{1000}: i in {1,2,3, dots,1000 } big }= big { frac{1}{1000}, frac{2}{1000}, dots, frac{1000}{1000} big }$ | . - 방법1 . q=[] for i in range(len(m)): q=q+[stats.norm.ppf(m[i])] q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . - 방법2 . q=[stats.norm.ppf(m[i]) for i in range(len(m))] . q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . - 방법3 . q=list(map(stats.norm.ppf, m)) q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . - 방법4 . stats.norm.ppf(m)[:5] . array([-3.09023231, -2.87816174, -2.74778139, -2.65206981, -2.5758293 ]) . Appendix: lambda, map . lambda . - 예제1: 사용방법 . f = lambda x,y,z : x+y+z ## lambda 입력:출력 . f(2,3,4) . 9 . - 예제2: 디폴트입력값 . x= (lambda a=&#39;fee&#39;,b=&#39;fie&#39;,c=&#39;foe&#39;: a+b+c) . x(&#39;wee&#39;) . &#39;weefiefoe&#39; . - 예제3: 람다들의 리스트가능 . l=[lambda x: x**2, lambda x: x**3, lambda x: x**4] . for f in l: print(f(2)) . 4 8 16 . - 예제4: 람다들의 딕셔너리 가능 . dct={&#39;f1&#39;: (lambda x: x+1), &#39;f2&#39;: (lambda x: x+22), &#39;f3&#39;: (lambda x: x+333)} . dct[&#39;f1&#39;](1), dct[&#39;f2&#39;](1), dct[&#39;f3&#39;](1) . (2, 23, 334) . - 예제5: 조건부 출력 . (예비학습) 문자열의 대소비교 . &#39;a&#39; &lt; &#39;b&#39; . True . &#39;c&#39; &lt; &#39;b&#39; . False . (예제시작) . lower = lambda x,y : x if x&lt;y else y . lower(&#39;a&#39;,&#39;b&#39;) . &#39;a&#39; . lower(&#39;c&#39;,&#39;b&#39;) . &#39;b&#39; . - 예제6 : lambda expression 을 return력가능 . def action(x): return (lambda y: x+y) . act = action(99) ## act는 99+y를 수행하는 함수 act2 = action(98) ## act2는 99+y를 수행하는 함수 . action은 마치 함수를 만드는 함수같다.. | . print(act(2)) print(act2(2)) . 101 100 . - 예제7: 예제6의 발전 . action = lambda x: (lambda y: x+y) . act= action(99) act2=action(98) . print(act(2)) print(act2(2)) . 101 100 . 괄호를 생략하여 선언하면 . action = lambda x: lambda y: x+y act= action(99) act2=action(98) print(act(2)) print(act2(2)) . 101 100 . map . - 예제1: 사용방법 . def inc(x): return x+1 . list(map(inc,[1,2,3,4])) . [2, 3, 4, 5] . - 예제1의 변형(람다사용) . list(map(lambda x: x+1,[1,2,3,4])) . [2, 3, 4, 5] . list(map(def inc(x): return x+1,[1,2,3,4])) . File &#34;/tmp/ipykernel_814922/3165935467.py&#34;, line 1 list(map(def inc(x): return x+1,[1,2,3,4])) ^ SyntaxError: invalid syntax . 함수명을 쓰는 자리에 lambda로 표현한 오브젝트 자체를 전달할 수 있다. $ to$ 코드가 간단하다. | . - 예제2: map과 리스트컴프리헨션 비교 . (함수선언) . f = lambda x: &#39;X&#39; in x . f(&#39;X1&#39;),f(&#39;X2&#39;),f(&#39;Y1&#39;),f(&#39;Y2&#39;) . (True, True, False, False) . (map) . list(map(f,[&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;])) . [True, True, False, False] . (리스트컴프리헨션과 비교) . [f(x) for x in [&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;]] . [True, True, False, False] . - 예제3: 두개의 입력을 받는 함수(pow) map, 리스트컴프리헨션 비교 . (함수소개) . pow(2,4) . 16 . (map) . list(map(pow,[2,2,2,3,3,3],[0,1,2,0,1,2])) . [1, 2, 4, 1, 3, 9] . (리스트컴프리헨션과 비교) . [pow(x,y) for x,y in zip([2,2,2,3,3,3],[0,1,2,0,1,2])] . [1, 2, 4, 1, 3, 9] . - 예제4: map은 (하나의 함수,다양한 입력)인 경우 사용가능 . l=[lambda x: x+1, lambda x: x+2, lambda x: x+3 ] . list(map(l,[100,200,300])) . TypeError Traceback (most recent call last) /tmp/ipykernel_814922/3486466812.py in &lt;module&gt; -&gt; 1 list(map(l,[100,200,300])) TypeError: &#39;list&#39; object is not callable . 리스트컴프리헨션은 (다양한함수,다양한입력)이 가능함 . [l[i](x) for i,x in zip([0,1,2],[100,200,300])] . [101, 202, 303] . - 종합: 리스트컴프리헨션과 비교하면 (1) 반복인덱스를 쓰지 않는 장점이 있는 반면 (2) 좀 더 제약적으로 사용할 수밖에 없다는 단점이 있음 . &#50528;&#46300;&#50892;&#46300; &#53552;&#54532;&#54000; . - 시각화계의 거장 . - 터프티의 이론중 백미: 엄격한 미니멀리즘 . 최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다. | 작은 지면 내에서 잉크를 최대한 적게 써서 짧은 시간 안에 많은 영감을 주어야 한다. | . - 데이터-잉크비: 데이터를 표현하는데 들아가는 잉크의 양 / 그래픽을 인쇄하는데 들어가는 잉크의 총량 . - 차트정크 (나이젤홈즈의 그래프) . . “Lurking behind chartjunk is contempt both for information and for the audience. Chartjunk promoters imagine that numbers and details are boring, dull, and tedious, requiring ornament to enliven. Cosmetic decoration, which frequently distorts the data, will never salvage an underlying lack of content. If the numbers are boring, then you’ve got the wrong numbers (...) Worse is contempt for our audience, designing as if readers were obtuse and uncaring. In fact, consumers of graphics are often more intelligent about the information at hand than those who fabricate the data decoration (...) The operating moral premise of information design should be that our readers are alert and caring; they may be busy, eager to get on with it, but they are not stupid.” . 차트정크 = 대중을 멸시 + 데이터에 대한 모독 | 차트정크 옹호가는 숫자와 데이터가 지루하여 활기가 필요하다고 생각하는 모양이다.. | . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 글쎼... . &#52272;&#49828;&#48120;&#45208;&#46300;&#51032; &#46020;&#54364; (&#51064;&#47448;&#50669;&#49324;&#49345; &#44032;&#51109; &#54988;&#47469;&#54620; &#49884;&#44033;&#54868;) . . - 터프티의 평 . 지금까지 그려진 최고의 통계 그래픽일지도 모른다. | 여기에서는 군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스코바에서 퇴각하는 동안의 여러날짜, 온도 $ to$ 6차원의 변수 | 백만번에 한번 이런 그림을 그릴수는 있겠지만 이러한 멋진 그래픽을 만드는 방법에 대한 원칙은 없다. $ to$ 미니멀리즘.. | . - 왜 우수한 그래프일까? . 자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존 | 이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임 | 미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함. | . &#50696;&#51228; . x=[44,48,49,58,62,68,69,70,76,79] ## 몸무게 y=[159,160,162,165,167,162,165,175,165,172] ## 키 g= &#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;m&#39;,&#39;f&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39; df=pd.DataFrame({&#39;w&#39;:x,&#39;h&#39;:y,&#39;g&#39;:g}) . df . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 4 62 | 167 | m | . 5 68 | 162 | f | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . - 미나드의 접근방법 . sns.scatterplot(data=df,x=&#39;w&#39;,y=&#39;h&#39;,hue=&#39;g&#39;) . &lt;AxesSubplot:xlabel=&#39;w&#39;, ylabel=&#39;h&#39;&gt; . - 일반적인 사람들 (보통 색깔을 사용할 생각을 못한다.) . figs = sns.FacetGrid(df,col=&#39;g&#39;) figs.map (sns.scatterplot,&#39;w&#39;,&#39;h&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f9e04cff0a0&gt; . - 생각보다 데이터가 정리된 형태에 따라서 시각화에 대한 사고방식이 달라진다. 아래와 같은 자료를 받았다고 하자. . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv . df1 . w h . 4 62 | 167 | . 6 69 | 165 | . 7 70 | 175 | . 8 76 | 165 | . 9 79 | 172 | . df2 . w h . 4 62 | 167 | . 6 69 | 165 | . 7 70 | 175 | . 8 76 | 165 | . 9 79 | 172 | . - 데이터프레임을 바꿀 생각을 하는게 쉽지 않다. . (방법1) . df1[&#39;g&#39;]= &#39;f&#39; . df1 . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . df2[&#39;g&#39;]= &#39;m&#39; . df2 . w h g . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . pd.concat([df1,df2]) . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . (방법2) . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv . pd.concat([df1,df2],keys=[&#39;f&#39;,&#39;m&#39;]).reset_index().iloc[:,[0,2,3]].rename(columns={&#39;level_0&#39;:&#39;g&#39;}) . g w h . 0 f | 44 | 159 | . 1 f | 48 | 160 | . 2 f | 49 | 162 | . 3 f | 58 | 165 | . 4 f | 68 | 162 | . 5 m | 62 | 167 | . 6 m | 69 | 165 | . 7 m | 70 | 175 | . 8 m | 76 | 165 | . 9 m | 79 | 172 | . - 어려운점: (1) 센스가 없어서 색깔을 넣어서 그룹을 구분할 생각을 못함 (2) 변형해야할 데이터를 생각못함 (3) 데이터를 변형할 생각을 한다고 해도 변형하는 실제적인 코드를 구현할 수 없음 (그래서 엑셀을 킨다..) . (1) 기획력부족 -&gt; 훌륭한 시각화를 많이 볼것 | (2) 데이터프레임에 대한 이해도가 부족 -&gt; tidydata에 대한 개념 | (3) 프로그래밍 능력 부족 -&gt; 코딩공부열심히.. | . - 목표: (2) 어떠한 데이터 형태로 변형해야하는가? (3) 그러한 데이터 형태로 바꾸기 위한 pandas 숙련도 . &#49689;&#51228; . x=np.random.chisquare(df=5, size=100) . sns.histplot(x,kde=True) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 자유도가5인 카이제곱분포에서 100개의 랜덤변수를 만들고, boxplot / histogram / qqplot . _ = stats.probplot(x,plot=plt) .",
            "url": "https://minji219.github.io/zw/2021/10/06/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%946%EC%9D%BC.html",
            "relUrl": "/2021/10/06/(5%EC%A3%BC%EC%B0%A8)-10%EC%9B%946%EC%9D%BC.html",
            "date": " • Oct 6, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "(4주차) 9월29일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/2) matplotlib + seaborn (1) . - (2/2) matplotlib + seaborn (2) . maplotlib + seaborn . import matplotlib.pyplot as plt import numpy as np import seaborn as sns . x=[44,48,49,58,62,68,69,70,76,79] # 몸무게 y=[159,160,162,165,167,162,165,175,165,172] #키 g=&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39; . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fad1f1c0bb0&gt;] . sns.scatterplot(x=x,y=y,hue=g) . &lt;AxesSubplot:&gt; . - 두 그림을 나란히 겹쳐 그릴수 있을까? . fig, (ax1,ax2) = plt.subplots(1,2) ax1.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fad1f023070&gt;] . sns.scatterplot(x=x,y=y,hue=g,ax=ax2) . &lt;AxesSubplot:&gt; . fig . fig.set_figwidth(8) . fig . ax1.set_title(&#39;matplotlib&#39;) ax2.set_title(&#39;seaborn&#39;) . Text(0.5, 1.0, &#39;seaborn&#39;) . fig . - 마치 matplotlib에 seaborn을 plugin하듯이 사용할 수 있다. . matplotlib vs seaborn . - 디자인이 예쁜 패키지를 선택하여 하나만 공부하는 것은 그렇게 좋은 전략이 아니다. . sns.set_theme() . plt.plot([1,2,3],[3,4,5],&#39;or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fad1e572d60&gt;] . &#50696;&#51228; . - 아래와 같은 자료가 있다고 하자. . np.random.seed(43052) x=np.random.normal(size=1000,loc=2,scale=1.5) . - 이 자료가 정규분포를 따르는지 어떻게 체크할 수 있을까? . plt.hist(x) . (array([ 10., 24., 99., 176., 232., 222., 165., 53., 16., 3.]), array([-2.44398446, -1.53832428, -0.6326641 , 0.27299608, 1.17865626, 2.08431645, 2.98997663, 3.89563681, 4.80129699, 5.70695718, 6.61261736]), &lt;BarContainer object of 10 artists&gt;) . - 종모양이므로 정규분포인듯 하다. . - 밀도추정곡선이 있었으면 좋겠다. (KDE로 추정) $ to$ seaborn을 활용하여 그려보자. . sns.histplot(x,kde=True) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 종모양인것 같다. . - 그렇다면 아래는 어떤가? . np.random.seed(43052) from scipy import stats . y=stats.t.rvs(10,size=1000) . sns.histplot(y,kde=True) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 종모양이다..? . - 비교 . fig, (ax1,ax2) = plt.subplots(1,2) sns.histplot(x,kde=True,ax=ax1) sns.histplot(y,kde=True,ax=ax2) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . xx= (x-np.mean(x)) / np.std(x,ddof=1) yy= (y-np.mean(y)) / np.std(y,ddof=1) fig, (ax1,ax2) = plt.subplots(1,2) sns.histplot(xx,kde=True,ax=ax1) sns.histplot(yy,kde=True,ax=ax2) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . xx= (x-np.mean(x)) / np.std(x,ddof=1) yy= (y-np.mean(y)) / np.std(y,ddof=1) fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2) ax1.boxplot(xx) sns.histplot(xx,kde=True,ax=ax2) ax3.boxplot(yy) sns.histplot(yy,kde=True,ax=ax4) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . fig.tight_layout() . fig . - 주의: 아래와 같이 해석하면 잘못된 해석이다. . $y$ 히스토그램을 그려보니 모양이 종모양이다. $ to$ $y$는 정규분포이다 | . - 관찰: boxplot을 그려보니 $y$의 꼬리가 정규분포보다 두꺼워 보인다. . &#49689;&#51228; . sns.set_theme(style=&quot;whitegrid&quot;, palette=&quot;pastel&quot;) plt.plot([1,2,3]) . [&lt;matplotlib.lines.Line2D at 0x7fad7db14790&gt;] . 와 같이 테마를 바꿔서 그림을 그려보고 스샷제출 .",
            "url": "https://minji219.github.io/zw/2021/09/29/(4%EC%A3%BC%EC%B0%A8)-9%EC%9B%9429%EC%9D%BC.html",
            "relUrl": "/2021/09/29/(4%EC%A3%BC%EC%B0%A8)-9%EC%9B%9429%EC%9D%BC.html",
            "date": " • Sep 29, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "(3주차) 9월27일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/9): 공지사항 . - (2/9): 액시즈를 이용한 플랏 (1) . - (3/9): 액시즈를 이용한 플랏 (2) . - (4/9): 액시즈를 이용한 플랏 (3) . - (5/9): 액시즈를 이용한 플랏 (4) . - (6/9): 액시즈를 이용한 플랏 (5) . - (7/9): title 설정 . - (8/9): 축의 범위를 설정, 독립과 상관계수 (1) . - (9/9): 독립과 상관계수 (2) . matplotlib&#47196; (&#51652;&#51676; &#50612;&#47157;&#44172;) &#44536;&#47548;&#51012; &#44536;&#47532;&#45716; &#48169;&#48277; . &#50640;&#51228;1: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54620; &#54540;&#46991; . - 목표: plt.plot() 을 사용하지 않고 아래 그림을 그려보자. . import matplotlib.pyplot as plt plt.plot([1,2,3],&#39;or&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fbe36af0&gt;] . - 구조: axis $ subset$ axes $ subset$ figure . https://matplotlib.org/stable/gallery/showcase/anatomy.html#sphx-glr-gallery-showcase-anatomy-py | . - 전략: 그림을 만들고 (도화지를 준비) $ to$ 액시즈를 만들고 (네모틀을 만든다) $ to$ 액시즈에 그림을 그린다. (.plot()을 이용) . - 우선 그림객체를 생성한다. . fig = plt.figure() # 도화지를 준비한다. . &lt;Figure size 432x288 with 0 Axes&gt; . fig # 현재 도화지상태를 체크 . &lt;Figure size 432x288 with 0 Axes&gt; . 그림객체를 출력해봐야 아무것도 나오지 않는다. (아무것도 없으니까..) | . fig.add_axes() ## 액시즈를 fig에 추가하라. fig.axes ## 현재 fig에 있는 액시즈 정보 . fig.axes # 현재 네모틀 상태를 체크 . [] . fig.add_axes([0,0,1,1]) # 도화지안에 (0,0) 위치에 길이가 (1,1) 인 네모틀을 만든다. . &lt;Axes:&gt; . fig.axes # 현재 네모틀 상태를 체크 --&gt; 네모틀이 하나 있음. . [&lt;Axes:&gt;] . fig # 현재도화지 상태 체크 --&gt; 도화지에 (하나의) 네모틀이 잘 들어가 있음 . axs1=fig.axes[0] ## 첫번째 액시즈 . axs1.plot([1,2,3],&#39;or&#39;) # 첫번쨰 액시즈에 접근하여 그림을 그림 . [&lt;matplotlib.lines.Line2D at 0x7ff0fc072070&gt;] . fig #현재 도화지 상태 체크 --&gt; 그림이 잘 그려짐 . &#50696;&#51228;2: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54620; &#49436;&#48652;&#54540;&#46991; (&#48169;&#48277;1) . - 목표: subplot . fig # 현재 도화지 출력 . - 액시즈추가 . fig.add_axes([1,0,1,1]) . &lt;Axes:&gt; . fig.axes . [&lt;Axes:&gt;, &lt;Axes:&gt;] . fig . axs2=fig.axes[1] ## 두번째 액시즈 . - 두번째 액시즈에 그림그림 . axs2.plot([1,2,3],&#39;ok&#39;) ## 두번째 액시즈에 그림그림 . [&lt;matplotlib.lines.Line2D at 0x7ff0fc0846d0&gt;] . fig ## 현재 도화지 체크 . - 첫번째 액시즈에 그림추가 . axs1.plot([1,2,3],&#39;--&#39;) ### 액시즈1에 점선추가 . [&lt;matplotlib.lines.Line2D at 0x7ff0fc084fa0&gt;] . fig ## 현재 도화지 체크 . &#50696;&#51228;3: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54616;&#50668; &#49436;&#48652;&#54540;&#46991; (&#48169;&#48277;2) . - 예제2의 레이아웃이 좀 아쉽다. . - 다시 그려보자. . fig = plt.figure() . &lt;Figure size 432x288 with 0 Axes&gt; . fig.axes . [] . fig.subplots(1,2) . array([&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], dtype=object) . fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1,ax2 = fig.axes . ax1.plot([1,2,3],&#39;or&#39;) ax2.plot([1,2,3],&#39;ob&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fc072190&gt;] . fig . 그림이 좀 좁은것 같다. (도화지를 늘려보자) | . fig.set_figwidth(10) . fig . ax1.plot([1,2,3],&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fb906d60&gt;] . fig . &#50696;&#51228;4: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; &#44536;&#47532;&#44592; . fig = plt.figure() fig.axes . [] . &lt;Figure size 432x288 with 0 Axes&gt; . fig.subplots(2,2) fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1,ax2,ax3,ax4=fig.axes . ax1.plot([1,2,3],&#39;ob&#39;) ax2.plot([1,2,3],&#39;or&#39;) ax3.plot([1,2,3],&#39;ok&#39;) ax4.plot([1,2,3],&#39;oy&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fb177430&gt;] . fig . &#50696;&#51228;5: plt.subplots()&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; (&#48373;&#49845;) . x=[1,2,3,4] y=[1,2,4,3] _, axs = plt.subplots(2,2) axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fac18dc0&gt;] . - 단계적으로 코드를 실행하고 싶을때 . x=[1,2,3,4] y=[1,2,4,3] . _, axs = plt.subplots(2,2) . axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0faaa0940&gt;] . 어? 그림을 볼려면 어떻게 하지? | . _ . 이렇게 하면된다. | . - 단계적으로 그림을 그릴경우에는 도화지객체를 fig라는 변수로 명시하여 받는것이 가독성이 좋다. . x=[1,2,3,4] y=[1,2,4,3] . fig, axs = plt.subplots(2,2) . axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fa935160&gt;] . fig # 현재 도화지 확인 . &#50696;&#51228;6: plt.subplots()&#47484; 2$ times$2 subplot &#44536;&#47532;&#44592; -- &#50529;&#49884;&#51592;&#47484; &#44033;&#44033; &#48320;&#49688;&#47749;&#51004;&#47196; &#51200;&#51109; . x=[1,2,3,4] y=[1,2,4,3] fig, axs = plt.subplots(2,2) . ax1,ax2,ax3,ax4 =axs . ValueError Traceback (most recent call last) /tmp/ipykernel_1794991/648347195.py in &lt;module&gt; -&gt; 1 ax1,ax2,ax3,ax4 =axs ValueError: not enough values to unpack (expected 4, got 2) . (ax1,ax2), (ax3,ax4) = axs . ax1.plot(x,y,&#39;o:r&#39;) ax2.plot(x,y,&#39;Xb&#39;) ax3.plot(x,y,&#39;xm&#39;) ax4.plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fb3650d0&gt;] . fig . &#50696;&#51228;7: plt.subplots()&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; &#44536;&#47532;&#44592; -- fig.axes&#50640;&#49436; &#51217;&#44540;! . fig, _ = plt.subplots(2,2) . fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1, ax2, ax3, ax4= fig.axes . ax1.plot(x,y,&#39;o:r&#39;) ax2.plot(x,y,&#39;Xb&#39;) ax3.plot(x,y,&#39;xm&#39;) ax4.plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0faddc670&gt;] . fig . - 예제7, 예제4와 비교해볼것: 거의 비슷함 . - matplotlib은 그래프를 쉽게 그릴수도 있지만 어렵게 그릴수도 있다. . - 오브젝트를 컨트르로 하기 어려우므로 여러가지 축약버전이 존재함. . 사실 그래서 서브플랏을 그리는 방법 1,2,3... 와 같은 식으로 정리하여 암기하기에는 무리가 있다. | . - 원리를 꺠우치면 다양한 방법을 자유자재로 쓸 수 있음. (자유도가 높음) . &#51228;&#47785;&#49444;&#51221; . &#50696;&#51228;1: plt.plot() . x=[1,2,3] y=[1,2,2] . plt.plot(x,y) plt.title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . &#50696;&#51228;2: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857; . fig = plt.figure() fig.subplots() . &lt;AxesSubplot:&gt; . ax1=fig.axes[0] . ax1.set_title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . fig . - 문법을 잘 이해했으면 각 서브플랏의 제목을 설정하는 방법도 쉽게 알 수 있다. . &#50696;&#51228;3: subplot&#50640;&#49436; &#44033;&#44033;&#51032; &#51228;&#47785;&#49444;&#51221; . fig, ax = plt.subplots(2,2) . (ax1,ax2),(ax3,ax4) =ax . ax1.set_title(&#39;title1&#39;) ax2.set_title(&#39;title2&#39;) ax3.set_title(&#39;title3&#39;) ax4.set_title(&#39;title4&#39;) . Text(0.5, 1.0, &#39;title4&#39;) . fig . - 보기싫음 $ to$ 서브플랏의 레이아웃 재정렬 . fig.tight_layout() # 외우세요.. . &#50696;&#51228;4: &#50529;&#49884;&#51592;&#51032; &#51228;&#47785; + Figure&#51228;&#47785; . fig.suptitle(&#39;sup title&#39;) . Text(0.5, 0.98, &#39;sup title&#39;) . fig . fig.tight_layout() . fig . &#52629;&#48276;&#50948;&#49444;&#51221; . &#50696;&#51228;1 . x=[1,2,3] y=[4,5,6] . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fa3e0f40&gt;] . plt.plot(x,y,&#39;o&#39;) plt.xlim(-1,5) plt.ylim(3,7) . (3.0, 7.0) . &#50696;&#51228;2 . fig = plt.figure() fig.subplots() . &lt;AxesSubplot:&gt; . ax1=fig.axes[0] . import numpy as np . ax1.plot(np.random.normal(size=100),&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fa2b4d60&gt;] . fig . ax1.set_xlim(-10,110) ax1.set_ylim(-5,5) . (-5.0, 5.0) . fig . &#53685;&#44228;&#50696;&#51228; . - 여러가지 경우의 산점도와 표본상관계수 . &#50696;&#51228;1 . np.random.seed(43052) x1=np.linspace(-1,1,100,endpoint=True) y1=x1**2+np.random.normal(scale=0.1,size=100) . plt.plot(x1,y1,&#39;o&#39;) plt.title(&#39;y=x**2&#39;) . Text(0.5, 1.0, &#39;y=x**2&#39;) . np.corrcoef(x1,y1) . array([[1. , 0.00688718], [0.00688718, 1. ]]) . - (표본)상관계수의 값이 0에 가까운 것은 두 변수의 직선관계가 약한것을 의미한 것이지 두 변수 사이에 아무런 함수관계가 없다는 것을 의미하는 것은 아니다. . &#50696;&#51228;2 . - 아래와 같은 자료를 고려하자. . np.random.seed(43052) x2=np.random.uniform(low=-1,high=1,size=100000) y2=np.random.uniform(low=-1,high=1,size=100000) . plt.plot(x2,y2,&#39;.&#39;) plt.title(&#39;rect&#39;) . Text(0.5, 1.0, &#39;rect&#39;) . np.corrcoef(x2,y2) . array([[1. , 0.00521001], [0.00521001, 1. ]]) . &#50696;&#51228;3 . np.random.seed(43052) _x3=np.random.uniform(low=-1,high=1,size=100000) _y3=np.random.uniform(low=-1,high=1,size=100000) . plt.plot(_x3,_y3,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0fadd4760&gt;] . radius = _x3**2+_y3**2 . x3=_x3[radius&lt;1] y3=_y3[radius&lt;1] plt.plot(_x3,_y3,&#39;.&#39;) plt.plot(x3,y3,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0faf53730&gt;] . plt.plot(x3,y3,&#39;.&#39;) plt.title(&#39;circ&#39;) . Text(0.5, 1.0, &#39;circ&#39;) . np.corrcoef(x3,y3) . array([[ 1. , -0.00362687], [-0.00362687, 1. ]]) . &#49689;&#51228; 1 . - 예제1,2,3 을 하나의 figure안에 subplot 으로 그려보기 (1$ times$3 행렬처럼 그릴것) . &#50696;&#51228;2~3&#51004;&#47196; &#50508;&#50500;&#48372;&#45716; &#46160; &#48320;&#49688;&#51032; &#46021;&#47549;&#49457; . - 예제2,3에 대하여 아래와 같은 절차를 고려하여 보자. . (1) $X in [-h,h]$일 경우 $Y$의 분포를 생각해보자. 그리고 히스토그램을 그려보자. . (2) $X in [0.9-h,0.9+h]$일 경우 $Y$의 분포를 생각해보자. 그리고 히스토그램을 그려보자. . (3) (1)-(2)를 비교해보자. . - 그림으로 살펴보자. . h=0.05 plt.hist(y2[(x2&gt; -h )*(x2&lt; h )]) . (array([508., 527., 450., 512., 500., 521., 500., 515., 494., 506.]), array([-9.99973293e-01, -7.99983163e-01, -5.99993034e-01, -4.00002904e-01, -2.00012774e-01, -2.26437887e-05, 1.99967486e-01, 3.99957616e-01, 5.99947746e-01, 7.99937876e-01, 9.99928006e-01]), &lt;BarContainer object of 10 artists&gt;) . h=0.05 _,axs= plt.subplots(2,2) axs[0,0].hist(y2[(x2&gt; -h )*(x2&lt; h )]) axs[0,1].hist(y2[(x2&gt; 0.9-h )*(x2&lt; 0.9+h )]) axs[1,0].hist(y3[(x3&gt; -h )*(x3&lt; h )]) axs[1,1].hist(y3[(x3&gt; 0.9-h )*(x3&lt; 0.9+h )]) . (array([105., 194., 256., 259., 262., 270., 244., 245., 188., 64.]), array([-0.5171188 , -0.41349885, -0.30987891, -0.20625896, -0.10263902, 0.00098093, 0.10460087, 0.20822082, 0.31184076, 0.41546071, 0.51908066]), &lt;BarContainer object of 10 artists&gt;) . - 축의범위를 조절하여보자. . h=0.05 _,axs= plt.subplots(2,2) axs[0,0].hist(y2[(x2&gt; -h )*(x2&lt; h )]) axs[0,0].set_xlim(-1.1,1.1) axs[0,1].hist(y2[(x2&gt; 0.9-h )*(x2&lt; 0.9+h )]) axs[0,1].set_xlim(-1.1,1.1) axs[1,0].hist(y3[(x3&gt; -h )*(x3&lt; h )]) axs[1,0].set_xlim(-1.1,1.1) axs[1,1].hist(y3[(x3&gt; 0.9-h )*(x3&lt; 0.9+h )]) axs[1,1].set_xlim(-1.1,1.1) . (-1.1, 1.1) . &#50696;&#51228;4 . np.random.seed(43052) x4=np.random.normal(size=10000) y4=np.random.normal(size=10000) . plt.plot(x4,y4,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0f36d0b20&gt;] . plt.plot(x4,y4,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x7ff0f3649400&gt;] . - 디자인적인 측면에서 보면 올바른 시각화라 볼 수 없다. (이 그림이 밀도를 왜곡시킨다) . - 아래와 같은 그림이 더 우수하다. (밀도를 표현하기 위해 투명도라는 개념을 도입) . plt.scatter(x4,y4,alpha=0.01) . &lt;matplotlib.collections.PathCollection at 0x7ff0f352d610&gt; . np.corrcoef(x4,y4) . array([[ 1. , -0.01007718], [-0.01007718, 1. ]]) . h=0.05 fig, _ = plt.subplots(3,3) . fig.tight_layout() . fig . fig.set_figwidth(10) fig.set_figheight(10) fig . fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . k=np.linspace(-2,2,9) k . array([-2. , -1.5, -1. , -0.5, 0. , 0.5, 1. , 1.5, 2. ]) . h . 0.05 . h=0.2 for i in range(9): fig.axes[i].hist(y4[(x4&gt;k[i]-h) * (x4&lt;k[i]+h)]) . fig . &#49689;&#51228; 2 . plt.scatter(x4,y4,alpha=0.01) . &lt;matplotlib.collections.PathCollection at 0x7ff0f30f1a60&gt; . - 이 그림의 색깔을 붉은색으로 바꿔서 그려보자. (주의: 수업시간에 알려주지 않은 방법임) . plt.scatter(x4,y4,alpha=0.01,&#39;r&#39;) . File &#34;/tmp/ipykernel_1794991/399356376.py&#34;, line 1 plt.scatter(x4,y4,alpha=0.01,&#39;r&#39;) ^ SyntaxError: positional argument follows keyword argument .",
            "url": "https://minji219.github.io/zw/2021/09/27/(3%EC%A3%BC%EC%B0%A8)-9%EC%9B%9427%EC%9D%BC.html",
            "relUrl": "/2021/09/27/(3%EC%A3%BC%EC%B0%A8)-9%EC%9B%9427%EC%9D%BC.html",
            "date": " • Sep 27, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "(3주차) 9월15일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/4) 라인플랏과 산점도 . - (2/4) 여러그림 그리기 . - (3/4) 앤스콤의 플랏 . - (4/4) 앤스콤의 플랏, 과제설명 . &#46972;&#51064;&#54540;&#46991;&#51012; &#44536;&#47532;&#45716; &#48169;&#48277; . import matplotlib.pyplot as plt x=[1,2,3,4] y=[1,2,4,3] plt.plot(x,y) . [&lt;matplotlib.lines.Line2D at 0x7f7a165e8130&gt;] . matplotlib&#50640;&#49436; &#49328;&#51216;&#46020;&#50752; &#46972;&#51064;&#54540;&#46991; &#44536;&#47532;&#44592; (&#51333;&#54633;) . - plt.plot()를 사용하면 산점도와 라인플랏을 다양한 조합으로 쉽고 편리하게 그릴수 있음 . x=[1,2,3,4] y=[1,2,4,3] plt.plot(x,y,&#39;o:r&#39;) # 20정도의 점의 모양, 4개의 선의모양, 8개의 색깔 . [&lt;matplotlib.lines.Line2D at 0x7f7a14865eb0&gt;] . &#50668;&#47084;&#44536;&#47548;&#51012; &#44536;&#47532;&#44592; . (1) &#44217;&#52432;&#44536;&#47532;&#44592; . import numpy as np x=np.arange(-5,5,0.1) y=2*x+np.random.normal(loc=0,scale=1,size=100) plt.plot(x,y,&#39;.b&#39;) plt.plot(x,2*x,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f7a1439fa60&gt;] . (2) &#46384;&#47196;&#44536;&#47532;&#44592; - subplots . x=[1,2,3,4] y=[1,2,4,3] _, axs = plt.subplots(2,2) axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f7a13e092b0&gt;] . plt.subplots?? . Signature: plt.subplots( nrows=1, ncols=1, *, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **fig_kw, ) Source: @_api.make_keyword_only(&#34;3.3&#34;, &#34;sharex&#34;) def subplots(nrows=1, ncols=1, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **fig_kw): &#34;&#34;&#34; Create a figure and a set of subplots. This utility wrapper makes it convenient to create common layouts of subplots, including the enclosing figure object, in a single call. Parameters - nrows, ncols : int, default: 1 Number of rows/columns of the subplot grid. sharex, sharey : bool or {&#39;none&#39;, &#39;all&#39;, &#39;row&#39;, &#39;col&#39;}, default: False Controls sharing of properties among x (*sharex*) or y (*sharey*) axes: - True or &#39;all&#39;: x- or y-axis will be shared among all subplots. - False or &#39;none&#39;: each subplot x- or y-axis will be independent. - &#39;row&#39;: each subplot row will share an x- or y-axis. - &#39;col&#39;: each subplot column will share an x- or y-axis. When subplots have a shared x-axis along a column, only the x tick labels of the bottom subplot are created. Similarly, when subplots have a shared y-axis along a row, only the y tick labels of the first column subplot are created. To later turn other subplots&#39; ticklabels on, use `~matplotlib.axes.Axes.tick_params`. When subplots have a shared axis that has units, calling `~matplotlib.axis.Axis.set_units` will update each axis with the new units. squeeze : bool, default: True - If True, extra dimensions are squeezed out from the returned array of `~matplotlib.axes.Axes`: - if only one subplot is constructed (nrows=ncols=1), the resulting single Axes object is returned as a scalar. - for Nx1 or 1xM subplots, the returned object is a 1D numpy object array of Axes objects. - for NxM, subplots with N&gt;1 and M&gt;1 are returned as a 2D array. - If False, no squeezing at all is done: the returned Axes object is always a 2D array containing Axes instances, even if it ends up being 1x1. subplot_kw : dict, optional Dict with keywords passed to the `~matplotlib.figure.Figure.add_subplot` call used to create each subplot. gridspec_kw : dict, optional Dict with keywords passed to the `~matplotlib.gridspec.GridSpec` constructor used to create the grid the subplots are placed on. **fig_kw All additional keyword arguments are passed to the `.pyplot.figure` call. Returns - fig : `~.figure.Figure` ax : `.axes.Axes` or array of Axes *ax* can be either a single `~matplotlib.axes.Axes` object or an array of Axes objects if more than one subplot was created. The dimensions of the resulting array can be controlled with the squeeze keyword, see above. Typical idioms for handling the return value are:: # using the variable ax for single a Axes fig, ax = plt.subplots() # using the variable axs for multiple Axes fig, axs = plt.subplots(2, 2) # using tuple unpacking for multiple Axes fig, (ax1, ax2) = plt.subplots(1, 2) fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2) The names ``ax`` and pluralized ``axs`` are preferred over ``axes`` because for the latter it&#39;s not clear if it refers to a single `~.axes.Axes` instance or a collection of these. See Also -- .pyplot.figure .pyplot.subplot .pyplot.axes .Figure.subplots .Figure.add_subplot Examples -- :: # First create some toy data: x = np.linspace(0, 2*np.pi, 400) y = np.sin(x**2) # Create just a figure and only one subplot fig, ax = plt.subplots() ax.plot(x, y) ax.set_title(&#39;Simple plot&#39;) # Create two subplots and unpack the output array immediately f, (ax1, ax2) = plt.subplots(1, 2, sharey=True) ax1.plot(x, y) ax1.set_title(&#39;Sharing Y axis&#39;) ax2.scatter(x, y) # Create four polar axes and access them through the returned array fig, axs = plt.subplots(2, 2, subplot_kw=dict(projection=&#34;polar&#34;)) axs[0, 0].plot(x, y) axs[1, 1].scatter(x, y) # Share a X axis with each column of subplots plt.subplots(2, 2, sharex=&#39;col&#39;) # Share a Y axis with each row of subplots plt.subplots(2, 2, sharey=&#39;row&#39;) # Share both X and Y axes with all subplots plt.subplots(2, 2, sharex=&#39;all&#39;, sharey=&#39;all&#39;) # Note that this is the same as plt.subplots(2, 2, sharex=True, sharey=True) # Create figure number 10 with a single subplot # and clears it if it already exists. fig, ax = plt.subplots(num=10, clear=True) &#34;&#34;&#34; fig = figure(**fig_kw) axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey, squeeze=squeeze, subplot_kw=subplot_kw, gridspec_kw=gridspec_kw) return fig, axs File: ~/anaconda3/envs/dv2021/lib/python3.8/site-packages/matplotlib/pyplot.py Type: function . subplots의 리턴값이 (fig,axs) 이 나오게된다. 우리는 뒤의 axs만 관심이 있으므로 앞의 fig는 _로 처리한다. | . Anscombe&#39;s quartet . - 교과서에 나오는 그림임. . - 교훈: 데이터를 분석하기 전에 항상 시각화를 하라. . x = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5] y1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68] y2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74] y3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73] x4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8] y4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89] . _, axs = plt.subplots(2,2) axs[0,0].plot(x,y1,&#39;o&#39;) axs[0,1].plot(x,y2,&#39;o&#39;) axs[1,0].plot(x,y3,&#39;o&#39;) axs[1,1].plot(x4,y4,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7f7a1370fb80&gt;] . - 상관계수를 잠깐 복습해보자. . 상관계수는 -1 ~ 1 사이의 값을 가진다. (코쉬슈바르츠 부등식을 사용하여 증명가능) | 완전한 직선이라면 상관계수가 1 또는 -1이다. | 상관계수가 1에 가까우면 양의 상관관계에 있다고 말하고 -1에 가까우면 음의 상관관계에 있다고 말한다. | . - 의문: 자료의 모양이 직선모양에 가까우면 상관계수가 큰것이 맞나? . $x,y$ 값이 모두 큰 하나의 관측치가 상관계수값을 키울 수 있지 않나? | . - 상관계수가 좋은것은 맞나? (=상관계수는 두 변수의 관계를 설명하기에 충분히 적절한 통계량인가?) . n=len(x) # xtilde = (x-np.mean(x)) / (np.std(x)*np.sqrt(n)) y1tilde = (y1-np.mean(y1)) / (np.std(y1)*np.sqrt(n)) . sum(xtilde*y1tilde) . 0.81642051634484 . np.corrcoef(x,y1) . array([[1. , 0.81642052], [0.81642052, 1. ]]) . np.corrcoef([x,y1,y2,y3]) . array([[1. , 0.81642052, 0.81623651, 0.81628674], [0.81642052, 1. , 0.7500054 , 0.46871668], [0.81623651, 0.7500054 , 1. , 0.58791933], [0.81628674, 0.46871668, 0.58791933, 1. ]]) . np.corrcoef([x4,y4]) . array([[1. , 0.81652144], [0.81652144, 1. ]]) . - 위의 4개의 그림에 대한 상관계수는 모두 같다. (0.81652) . - 상관계수는 두 변수의 관계를 설명하기에 부적절하다. . 상관계수는 1번그림과 같이 두 변수가 선형관계에 있을때 그 정도를 나타내는 통계량일뿐이다. | 선형관계가 아닌것처럼 보이는 자료에서는 상관계수를 계산할수는 있겠으나 의미가 없다. | . - 교훈2: 기본적인 통계량들은 실제자료를 분석하기에 부적절할수 있다. (=통계량은 적절한 가정이 동반되어야 의미가 있다) . . Note: 통계학자는 (1) 적절한 가정을 수학적인 언어로 정의하고 (2) 그 가정하에서 통계량이 의미있다는 것을 증명해야 한다. (3) 그리고 그 결과를 시각화하여 설득한다. . &#49689;&#51228; . - 앤스콤의 플랏을 붉은색을 사용하여 그려보기! .",
            "url": "https://minji219.github.io/zw/2021/09/15/(3%EC%A3%BC%EC%B0%A8)-9%EC%9B%9415%EC%9D%BC.html",
            "relUrl": "/2021/09/15/(3%EC%A3%BC%EC%B0%A8)-9%EC%9B%9415%EC%9D%BC.html",
            "date": " • Sep 15, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "(2주차) 9월13일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/3) 이미지 자료에 대한 이해 . - (2/3) 산점도와 상관계수 1 . - (3/3) 산점도와 상관계수 2 . (&#51648;&#45212;&#44053;&#51032;&#45432;&#53944; &#48372;&#52649;) &#51060;&#48120;&#51648; &#51088;&#47308;&#50640; &#45824;&#54620; &#51060;&#54644; . - 흑백이미지 . 차원: 세로픽셀수 $ times$ 가로픽셀수 | 값: 0~255 (값이 클수록 흰색) | . - 칼라이미지 . 차원: 세로픽셀수 $ times$ 가로픽셀수 $ times$ 3 | 값: 0~255 (값이 클수록 진한빨강, 진한파랑, 진한녹색) | . import cv2 as cv . hani=cv.imread(&#39;2021-08-25-Hani01.jpeg&#39;) . import matplotlib.pyplot as plt plt.imshow(hani) . &lt;matplotlib.image.AxesImage at 0x7fcfe613afd0&gt; . hani.shape . (1009, 757, 3) . import numpy as np hani_red=np.zeros_like(hani) hani_green=np.zeros_like(hani) hani_blue=np.zeros_like(hani) hani_red[:,:,0]=hani[:,:,0] hani_green[:,:,1]=hani[:,:,1] hani_blue[:,:,2]=hani[:,:,2] . plt.imshow(hani_red) . &lt;matplotlib.image.AxesImage at 0x7fcfe6118f70&gt; . plt.imshow(hani_green) . &lt;matplotlib.image.AxesImage at 0x7fcfe607e070&gt; . plt.imshow(hani_blue) . &lt;matplotlib.image.AxesImage at 0x7fcfe6068730&gt; . plt.imshow(hani_blue+hani_red) . &lt;matplotlib.image.AxesImage at 0x7fcfe5fd60d0&gt; . plt.imshow(hani_blue+hani_green) . &lt;matplotlib.image.AxesImage at 0x7fcfe5f32a60&gt; . plt.imshow(hani_red+hani_green) . &lt;matplotlib.image.AxesImage at 0x7fcfe5f1f430&gt; . plt.imshow(hani_red+hani_green+hani_blue) . &lt;matplotlib.image.AxesImage at 0x7fcfe5e7ee50&gt; . &#49328;&#51216;&#46020; (scatter plot) . import matplotlib.pyplot as plt . - 산점도: 직교 좌표계(도표)를 이용해 좌표상의 점들을 표시함으로써 두 개 변수 간의 관계를 나타내는 그래프 방법이다. . ref: https://ko.wikipedia.org/wiki/%EC%82%B0%EC%A0%90%EB%8F%84 | . x=[1,2,3,4] y=[2,3,5,5] plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcfe5e67d90&gt;] . - 산점도는 보통 $X$와 $Y$의 관계를 알고 싶을 경우 그린다. . 박스플랏, 히스토그램은 그림을 그리기 위해서 하나의 변수만 필요함; 산점도를 위해서는 두개의 변수가 필요함. | 두변수 $ to$ 두변수의 관계 | . &#47800;&#47924;&#44172;&#50752; &#53412; . - 아래와 같은 자료를 수집하였다고 하자. . 몸무게 = [44,48,49,58,62,68,69,70,76,79] | 키 = [159,160,162,165,167,162,165,175,165,172] | . x=[44,48,49,58,62,68,69,70,76,79] y=[159,160,162,165,167,162,165,175,165,172] . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcfe5dd5a00&gt;] . 키가 큰 사람일수록 몸무게도 많이 나간다. (반대도 성립) | 키와 몸무게는 관계가 있어보인다. (정비례) | . - 얼만큼 정비례인지? . 이 질문에 대답하기 위해서는 상관계수의 개념을 알아야 한다. | 상관계수에 대한 개념은 산점도를 이해함에 있어서 핵심개념이다. | . &#49345;&#44288;&#44228;&#49688; (&#47800;&#47924;&#44172;-&#53412; &#50696;&#51228;&#47484; &#45908; &#44618;&#44172; &#51060;&#54644;&#54616;&#44592; &#50948;&#54644; &#54596;&#50836;&#54620; &#44060;&#45392;) . - (표본)상관계수 . $$r= frac{ sum_{i=1}^{n}(x_i- bar{x})(y_i- bar{y}) }{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2 sum_{i=1}^{n}(y_i- bar{y})^2 }} $$ . 복잡해 보이지만 아무튼 (1) 분자를 계산하고 (2) 분모를 계산하고 분자를 분모로 나누면 되는 것. | 분모를 계산했다고 치자. 계산한 값을 어떤 상수 $c$라고 생각하자. 이 값을 분자안에 넣을수도 있다. | . $$r= sum_{i=1}^{n} frac{1}{c}(x_i- bar{x})(y_i- bar{y}) $$ . 위의 식은 아래와 같이 다시 쓸 수 있다. | . $$r= sum_{i=1}^{n} left( frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}} frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}} right)$$ . 편의상 아래와 같이 정의하자. $ tilde{x}_i= frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^n(x_i- bar{x})^2}}$, $ tilde{y}_i= frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^n(y_i- bar{y})^2}}$ | . 결국 $r$은 아래와 같은 모양이다. | . $$r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i $$ . - 의미? . import numpy as np x=np.array(x) y=np.array(y) . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcfe5d48640&gt;] . plt.plot(x-np.mean(x), y-np.mean(y),&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcfe5cbb3d0&gt;] . - $a= sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}, b= sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}$ . a=np.sqrt(np.sum((x-np.mean(x))**2)) b=np.sqrt(np.sum((y-np.mean(y))**2)) a,b . (36.58004920718396, 15.218409903797438) . $a&gt;b$ 이므로 $ {x_i }$들이 $ {y_i }$들 보다 좀 더 퍼져있다. (=평균근처에 몰려있지 않다) | . - 사실 $a,b$는 아래와 같이 계산할 수 있다. . $a= sqrt{n} times{ tt np.std(x)}$ . $b= sqrt{n} times{ tt np.std(y)}$ . n=len(x) np.sqrt(n)*np.std(x), np.sqrt(n)*np.std(y) . (36.58004920718397, 15.21840990379744) . ${ tt np.std(x)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(x_i- bar{x})^2}$ | ${ tt np.std(y)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(y_i- bar{y})^2}$ | . . Note: ${ tt np.std(x,ddof=1)}= sqrt{ frac{1}{n-1} sum_{i=1}^{n}(x_i- bar{x})^2}$ . - 이제 $( tilde{x}_i, tilde{y}_i)$를 그려보자. . xx= (x-np.mean(x))/a yy= (y-np.mean(y))/b plt.plot(xx,yy,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcfe5caa7f0&gt;] . 평균도 비슷하고 퍼진정도도 비슷하다. | . - 질문1: $r$의 값이 양수인가? 음수인가? . plotly 사용하여 그려보자. . import plotly.express as px from IPython.display import HTML fig=px.scatter(x=xx, y=yy) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . $ tilde{x}_i$, $ tilde{y}_i$ 를 곱한값이 양수인것과 음수인것을 체크해보자. | 양수인쪽이 많은지 음수인쪽이 많은지 생각해보자. | $r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i$ 의 부호는? | . - 질문2: 아래와 같은 두개의 데이터set이 있다고 하자. . x1=np.arange(0,10,0.1) y1=x1+np.random.normal(loc=0,scale=1.0,size=len(x1)) . plt.plot(x1,y1,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcfe5bbd0d0&gt;] . x2=np.arange(0,10,0.1) y2=x2+np.random.normal(loc=0,scale=7.0,size=len(x2)) plt.plot(x2,y2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcfe5b91ee0&gt;] . plt.plot(x1,y1,&#39;o&#39;) plt.plot(x2,y2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x7fcfe5b025e0&gt;] . 각 데이터셋의 표준상관계수를 각각 $r_1$(파란색), $r_2$(주황색)라고 하자. . (1) $r_1$, $r_2$의 부호는 양수인가? 음수인가? . (2) $r_1,r_2$의 값중 어떠한 값이 더 절대값이 큰가? . n=len(x1) xx1= (x1-np.mean(x1)) / (np.std(x1) * np.sqrt(n)) yy1= (y1-np.mean(y1)) / (np.std(y1) * np.sqrt(n)) xx2= (x2-np.mean(x2)) / (np.std(x2) * np.sqrt(n)) yy2= (y2-np.mean(y2)) / (np.std(y2) * np.sqrt(n)) . plt.plot(xx1,yy1,&#39;o&#39;) ## 파란색 plt.plot(xx2,yy2,&#39;x&#39;) ## 주황색 . [&lt;matplotlib.lines.Line2D at 0x7fcfe5aee8e0&gt;] . sum(xx1*yy1), sum(xx2*yy2) . (0.9422426257344966, 0.4539974817112052) . &#49689;&#51228; . - 임의의 이미지를 cv.imread() 로 불러온뒤에 아래와 같이 blue+green의 조합으로 이미지를 변경해볼것 . plt.imshow(hani_blue+hani_green) . &lt;matplotlib.image.AxesImage at 0x7fcfe5a52970&gt; .",
            "url": "https://minji219.github.io/zw/2021/09/13/(2%EC%A3%BC%EC%B0%A8)-9%EC%9B%9413%EC%9D%BC.html",
            "relUrl": "/2021/09/13/(2%EC%A3%BC%EC%B0%A8)-9%EC%9B%9413%EC%9D%BC.html",
            "date": " • Sep 13, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "(2주차) 9월8일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/2): 히스토그램 평활화 . - (2/2): 히스토그램 평활화, 과제안내 . Histogram Equalization, HE . - ref: https://en.wikipedia.org/wiki/Histogram_equalization . - 히스토그램 평활화: 이미지의 명암대비 개선 . !pip install opencv-python . import cv2 as cv import matplotlib.pyplot as plt import pandas as pd . img = cv.imread(&#39;Unequalized_Hawkes_Bay_NZ.jpeg&#39;,0) . plt.imshow(img,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f9bdd809c10&gt; . - 이미지자료는 사실 0~255 사이의 어떠한 숫자들이 포함된 매트릭스일 뿐이다. . img . array([[127, 145, 149, ..., 168, 167, 166], [165, 152, 143, ..., 168, 169, 168], [171, 145, 140, ..., 156, 154, 151], ..., [147, 132, 134, ..., 146, 145, 144], [146, 130, 132, ..., 146, 145, 144], [145, 128, 129, ..., 146, 145, 144]], dtype=uint8) . 확인: 이미지가 있다고 믿었던 img는 그냥 넘파이 매트릭스 | 위의 매트릭스에 있는 숫자들을 색깔로 표현하여 값이 클수록 하얗게, 값이 작을수록 검게 그린다. 극단적으로 0은 검은색, 255는 흰색이다. | . - 이미지가 넘파이 매트릭스일 뿐이라는 것을 판다스를 활용하면 더 잘 시각화하여 이해할 수 있다. . plt.imshow(img[200:300,400:500],cmap=&#39;gray&#39;,vmin=0,vmax=255) . &lt;matplotlib.image.AxesImage at 0x7f9bdd776f70&gt; . df=pd.DataFrame(img) df.iloc[200:300,400:500].style.set_properties(**{&#39;font-size&#39;:&#39;10pt&#39;}).background_gradient(&#39;gray&#39;,vmin=0,vmax=255) . &nbsp; 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 . 200 155 | 155 | 151 | 149 | 152 | 152 | 151 | 152 | 152 | 152 | 152 | 153 | 154 | 155 | 157 | 158 | 164 | 157 | 150 | 148 | 146 | 143 | 139 | 138 | 138 | 140 | 142 | 140 | 138 | 137 | 137 | 137 | 131 | 142 | 147 | 143 | 143 | 150 | 153 | 151 | 149 | 148 | 146 | 143 | 141 | 141 | 142 | 143 | 143 | 143 | 140 | 138 | 137 | 138 | 136 | 133 | 133 | 134 | 133 | 131 | 128 | 127 | 129 | 131 | 128 | 129 | 132 | 129 | 130 | 129 | 125 | 131 | 128 | 128 | 128 | 130 | 132 | 133 | 132 | 131 | 137 | 136 | 135 | 138 | 140 | 133 | 127 | 129 | 132 | 130 | 130 | 132 | 135 | 135 | 134 | 134 | 137 | 138 | 137 | 134 | . 201 139 | 148 | 152 | 149 | 145 | 142 | 147 | 156 | 150 | 152 | 154 | 154 | 153 | 153 | 155 | 157 | 158 | 159 | 155 | 149 | 144 | 142 | 139 | 136 | 138 | 139 | 140 | 139 | 137 | 136 | 136 | 137 | 141 | 140 | 139 | 141 | 147 | 152 | 152 | 150 | 151 | 150 | 149 | 147 | 145 | 143 | 143 | 143 | 141 | 142 | 142 | 141 | 141 | 141 | 138 | 134 | 133 | 132 | 132 | 131 | 130 | 131 | 133 | 135 | 128 | 128 | 132 | 130 | 132 | 131 | 126 | 132 | 129 | 129 | 128 | 129 | 130 | 132 | 132 | 133 | 137 | 135 | 132 | 133 | 134 | 129 | 126 | 130 | 129 | 129 | 131 | 133 | 134 | 133 | 134 | 136 | 136 | 137 | 137 | 135 | . 202 138 | 145 | 149 | 149 | 149 | 144 | 138 | 139 | 144 | 148 | 153 | 155 | 153 | 152 | 153 | 155 | 153 | 158 | 157 | 147 | 140 | 140 | 139 | 136 | 137 | 135 | 135 | 137 | 137 | 135 | 134 | 136 | 142 | 138 | 139 | 145 | 147 | 144 | 145 | 151 | 150 | 150 | 151 | 150 | 149 | 147 | 145 | 143 | 140 | 140 | 140 | 140 | 140 | 141 | 139 | 135 | 133 | 131 | 129 | 128 | 129 | 130 | 132 | 133 | 128 | 128 | 131 | 131 | 134 | 133 | 128 | 133 | 132 | 132 | 131 | 130 | 129 | 131 | 133 | 135 | 133 | 132 | 129 | 129 | 132 | 131 | 133 | 140 | 135 | 136 | 137 | 137 | 134 | 131 | 131 | 134 | 135 | 136 | 136 | 136 | . 203 152 | 151 | 148 | 150 | 156 | 152 | 141 | 134 | 137 | 141 | 147 | 151 | 152 | 152 | 153 | 154 | 152 | 155 | 153 | 144 | 137 | 138 | 139 | 139 | 134 | 130 | 130 | 134 | 135 | 133 | 133 | 136 | 133 | 132 | 137 | 146 | 147 | 141 | 141 | 147 | 146 | 147 | 148 | 149 | 150 | 149 | 147 | 145 | 143 | 142 | 140 | 137 | 137 | 139 | 139 | 137 | 136 | 133 | 129 | 127 | 127 | 128 | 128 | 128 | 129 | 127 | 130 | 129 | 133 | 134 | 130 | 136 | 136 | 136 | 134 | 132 | 130 | 131 | 133 | 135 | 132 | 133 | 132 | 133 | 137 | 137 | 140 | 147 | 144 | 143 | 142 | 140 | 137 | 133 | 134 | 136 | 136 | 136 | 135 | 135 | . 204 155 | 156 | 153 | 151 | 153 | 153 | 152 | 155 | 141 | 141 | 142 | 144 | 147 | 149 | 151 | 151 | 153 | 152 | 149 | 145 | 140 | 137 | 138 | 140 | 133 | 130 | 129 | 131 | 132 | 131 | 132 | 134 | 130 | 127 | 130 | 139 | 147 | 147 | 144 | 141 | 144 | 144 | 144 | 146 | 147 | 147 | 147 | 146 | 147 | 146 | 143 | 140 | 139 | 140 | 139 | 137 | 138 | 134 | 130 | 127 | 128 | 129 | 129 | 128 | 129 | 127 | 129 | 127 | 131 | 134 | 131 | 139 | 139 | 138 | 136 | 133 | 131 | 130 | 132 | 134 | 137 | 140 | 141 | 141 | 143 | 140 | 139 | 143 | 145 | 141 | 138 | 139 | 140 | 141 | 142 | 144 | 138 | 136 | 134 | 133 | . 205 145 | 151 | 152 | 153 | 154 | 152 | 152 | 156 | 151 | 147 | 141 | 139 | 141 | 144 | 147 | 148 | 151 | 149 | 149 | 148 | 145 | 138 | 135 | 136 | 134 | 133 | 131 | 130 | 130 | 130 | 131 | 132 | 134 | 133 | 134 | 136 | 139 | 142 | 143 | 143 | 145 | 144 | 142 | 143 | 144 | 145 | 144 | 144 | 146 | 146 | 145 | 143 | 141 | 140 | 137 | 133 | 134 | 131 | 127 | 126 | 128 | 129 | 130 | 129 | 129 | 128 | 130 | 127 | 130 | 133 | 132 | 141 | 140 | 138 | 136 | 133 | 130 | 130 | 132 | 133 | 139 | 143 | 143 | 143 | 145 | 141 | 137 | 139 | 144 | 138 | 134 | 136 | 141 | 144 | 145 | 145 | 141 | 137 | 134 | 134 | . 206 143 | 147 | 149 | 151 | 155 | 152 | 146 | 145 | 154 | 151 | 146 | 143 | 142 | 143 | 144 | 145 | 144 | 146 | 147 | 146 | 142 | 138 | 136 | 134 | 133 | 135 | 134 | 130 | 129 | 132 | 134 | 134 | 135 | 136 | 137 | 136 | 133 | 135 | 142 | 150 | 147 | 145 | 143 | 143 | 144 | 145 | 144 | 143 | 145 | 145 | 144 | 142 | 141 | 140 | 136 | 132 | 130 | 128 | 126 | 126 | 127 | 128 | 129 | 129 | 129 | 129 | 131 | 129 | 130 | 133 | 133 | 143 | 143 | 139 | 135 | 132 | 131 | 132 | 134 | 136 | 138 | 141 | 140 | 139 | 142 | 141 | 139 | 140 | 143 | 137 | 133 | 136 | 141 | 143 | 143 | 142 | 143 | 139 | 136 | 136 | . 207 148 | 151 | 150 | 149 | 151 | 150 | 149 | 151 | 150 | 150 | 151 | 150 | 148 | 145 | 144 | 144 | 137 | 144 | 145 | 139 | 135 | 137 | 138 | 135 | 131 | 136 | 136 | 130 | 129 | 135 | 138 | 137 | 134 | 129 | 128 | 132 | 137 | 140 | 146 | 153 | 147 | 145 | 144 | 144 | 145 | 146 | 145 | 143 | 147 | 147 | 144 | 142 | 141 | 141 | 139 | 136 | 132 | 131 | 129 | 128 | 128 | 128 | 128 | 129 | 128 | 130 | 133 | 131 | 131 | 133 | 133 | 144 | 145 | 141 | 135 | 132 | 132 | 135 | 138 | 140 | 141 | 141 | 137 | 135 | 139 | 140 | 139 | 140 | 139 | 135 | 133 | 136 | 141 | 143 | 143 | 143 | 144 | 140 | 137 | 138 | . 208 150 | 148 | 151 | 145 | 143 | 147 | 148 | 153 | 158 | 153 | 150 | 152 | 149 | 143 | 141 | 144 | 145 | 145 | 144 | 142 | 140 | 137 | 133 | 131 | 130 | 133 | 131 | 130 | 137 | 143 | 140 | 135 | 141 | 139 | 130 | 134 | 147 | 142 | 135 | 144 | 147 | 143 | 146 | 148 | 144 | 146 | 149 | 144 | 148 | 144 | 140 | 141 | 143 | 144 | 141 | 137 | 132 | 128 | 126 | 127 | 128 | 127 | 125 | 125 | 128 | 127 | 129 | 135 | 138 | 138 | 138 | 139 | 138 | 133 | 129 | 130 | 133 | 135 | 138 | 140 | 140 | 136 | 135 | 137 | 138 | 136 | 136 | 139 | 139 | 137 | 137 | 138 | 139 | 140 | 141 | 143 | 141 | 144 | 143 | 143 | . 209 153 | 147 | 147 | 143 | 144 | 147 | 144 | 146 | 150 | 149 | 150 | 152 | 153 | 151 | 146 | 143 | 142 | 142 | 141 | 139 | 137 | 135 | 134 | 134 | 133 | 131 | 130 | 129 | 130 | 132 | 134 | 133 | 136 | 139 | 137 | 130 | 132 | 146 | 151 | 142 | 145 | 146 | 153 | 156 | 154 | 156 | 156 | 149 | 145 | 148 | 149 | 148 | 143 | 140 | 139 | 140 | 143 | 137 | 130 | 125 | 122 | 122 | 126 | 129 | 128 | 128 | 129 | 132 | 137 | 139 | 139 | 137 | 133 | 130 | 129 | 133 | 138 | 139 | 137 | 135 | 140 | 136 | 134 | 136 | 136 | 133 | 132 | 135 | 137 | 136 | 136 | 137 | 136 | 136 | 137 | 140 | 137 | 140 | 139 | 139 | . 210 154 | 147 | 147 | 145 | 145 | 145 | 141 | 145 | 143 | 145 | 147 | 149 | 153 | 155 | 151 | 144 | 144 | 143 | 141 | 139 | 137 | 136 | 137 | 137 | 136 | 130 | 132 | 135 | 129 | 129 | 133 | 133 | 137 | 128 | 138 | 144 | 135 | 141 | 149 | 139 | 141 | 142 | 146 | 146 | 145 | 152 | 155 | 150 | 145 | 145 | 144 | 144 | 144 | 143 | 141 | 140 | 142 | 139 | 135 | 132 | 127 | 124 | 125 | 127 | 126 | 126 | 127 | 128 | 133 | 137 | 136 | 133 | 132 | 130 | 131 | 137 | 143 | 142 | 138 | 134 | 138 | 135 | 134 | 136 | 136 | 134 | 134 | 135 | 135 | 135 | 136 | 137 | 135 | 134 | 136 | 140 | 137 | 140 | 139 | 138 | . 211 153 | 149 | 152 | 151 | 148 | 146 | 143 | 150 | 143 | 143 | 143 | 145 | 148 | 150 | 150 | 148 | 149 | 146 | 142 | 140 | 139 | 139 | 138 | 137 | 137 | 131 | 137 | 143 | 137 | 139 | 141 | 134 | 145 | 129 | 145 | 167 | 157 | 144 | 144 | 140 | 139 | 142 | 143 | 140 | 141 | 149 | 153 | 151 | 148 | 145 | 141 | 141 | 142 | 143 | 142 | 141 | 139 | 138 | 139 | 139 | 135 | 129 | 124 | 122 | 125 | 124 | 124 | 127 | 130 | 132 | 133 | 134 | 133 | 131 | 132 | 137 | 140 | 140 | 137 | 135 | 138 | 135 | 133 | 134 | 134 | 133 | 134 | 135 | 133 | 134 | 136 | 136 | 135 | 134 | 136 | 140 | 139 | 141 | 139 | 139 | . 212 156 | 151 | 153 | 151 | 150 | 149 | 145 | 149 | 147 | 144 | 144 | 146 | 146 | 143 | 144 | 149 | 149 | 144 | 139 | 138 | 139 | 139 | 136 | 132 | 136 | 132 | 138 | 142 | 141 | 147 | 147 | 132 | 137 | 136 | 145 | 155 | 154 | 147 | 141 | 135 | 133 | 140 | 142 | 141 | 144 | 148 | 148 | 147 | 149 | 151 | 152 | 149 | 143 | 140 | 141 | 144 | 146 | 142 | 140 | 139 | 137 | 133 | 129 | 127 | 127 | 123 | 124 | 128 | 130 | 127 | 130 | 135 | 130 | 131 | 133 | 136 | 136 | 134 | 134 | 134 | 138 | 135 | 132 | 131 | 131 | 131 | 131 | 133 | 131 | 132 | 134 | 135 | 133 | 131 | 134 | 137 | 135 | 139 | 137 | 136 | . 213 160 | 152 | 151 | 149 | 151 | 153 | 145 | 142 | 148 | 145 | 146 | 150 | 148 | 141 | 141 | 147 | 146 | 142 | 137 | 137 | 139 | 139 | 135 | 131 | 134 | 132 | 134 | 134 | 136 | 144 | 143 | 131 | 128 | 132 | 130 | 129 | 134 | 138 | 137 | 137 | 132 | 138 | 138 | 137 | 141 | 143 | 144 | 147 | 148 | 150 | 151 | 152 | 150 | 148 | 145 | 144 | 145 | 142 | 140 | 142 | 143 | 141 | 139 | 137 | 129 | 125 | 123 | 126 | 127 | 125 | 127 | 131 | 129 | 131 | 135 | 138 | 137 | 134 | 133 | 134 | 135 | 133 | 132 | 132 | 133 | 135 | 136 | 138 | 135 | 135 | 136 | 136 | 134 | 132 | 132 | 135 | 133 | 137 | 136 | 134 | . 214 160 | 157 | 157 | 150 | 150 | 153 | 146 | 143 | 146 | 146 | 147 | 149 | 147 | 144 | 143 | 144 | 144 | 142 | 138 | 137 | 138 | 137 | 136 | 134 | 132 | 133 | 133 | 132 | 132 | 135 | 136 | 133 | 131 | 130 | 129 | 131 | 133 | 135 | 139 | 146 | 140 | 142 | 138 | 137 | 141 | 141 | 142 | 152 | 147 | 144 | 143 | 147 | 153 | 155 | 151 | 147 | 142 | 142 | 143 | 146 | 148 | 146 | 143 | 142 | 134 | 132 | 127 | 124 | 126 | 129 | 128 | 124 | 130 | 131 | 134 | 137 | 137 | 134 | 133 | 134 | 135 | 134 | 134 | 135 | 137 | 140 | 141 | 142 | 138 | 137 | 138 | 138 | 136 | 134 | 133 | 135 | 134 | 140 | 139 | 135 | . 215 157 | 162 | 167 | 156 | 148 | 151 | 149 | 151 | 145 | 145 | 145 | 143 | 144 | 146 | 146 | 143 | 143 | 142 | 139 | 137 | 135 | 134 | 134 | 135 | 130 | 134 | 136 | 136 | 134 | 130 | 131 | 138 | 128 | 130 | 138 | 141 | 136 | 138 | 143 | 140 | 137 | 140 | 138 | 140 | 143 | 137 | 134 | 143 | 147 | 147 | 146 | 147 | 148 | 150 | 153 | 155 | 149 | 147 | 146 | 146 | 143 | 141 | 141 | 143 | 141 | 141 | 133 | 124 | 128 | 137 | 134 | 122 | 129 | 128 | 129 | 131 | 132 | 132 | 132 | 133 | 138 | 138 | 138 | 138 | 138 | 139 | 138 | 137 | 137 | 136 | 136 | 137 | 136 | 134 | 133 | 134 | 136 | 142 | 141 | 136 | . 216 156 | 146 | 149 | 163 | 166 | 153 | 146 | 152 | 145 | 144 | 143 | 144 | 145 | 145 | 143 | 141 | 139 | 141 | 136 | 133 | 138 | 136 | 130 | 131 | 131 | 132 | 136 | 137 | 134 | 130 | 130 | 132 | 132 | 135 | 126 | 136 | 141 | 137 | 146 | 141 | 135 | 137 | 138 | 141 | 143 | 138 | 137 | 143 | 146 | 146 | 146 | 148 | 149 | 145 | 143 | 148 | 147 | 147 | 146 | 144 | 142 | 141 | 140 | 140 | 142 | 143 | 143 | 144 | 144 | 143 | 140 | 138 | 123 | 126 | 137 | 137 | 141 | 131 | 133 | 132 | 138 | 141 | 137 | 135 | 138 | 135 | 132 | 137 | 137 | 135 | 135 | 137 | 136 | 132 | 131 | 134 | 134 | 137 | 139 | 137 | . 217 155 | 156 | 158 | 158 | 159 | 158 | 154 | 148 | 150 | 146 | 142 | 143 | 145 | 145 | 142 | 138 | 136 | 135 | 131 | 132 | 137 | 138 | 135 | 133 | 136 | 131 | 129 | 130 | 132 | 131 | 128 | 127 | 143 | 144 | 130 | 132 | 134 | 132 | 144 | 141 | 134 | 138 | 138 | 136 | 137 | 136 | 135 | 138 | 132 | 144 | 151 | 146 | 144 | 150 | 152 | 147 | 142 | 143 | 143 | 143 | 143 | 142 | 142 | 142 | 144 | 144 | 144 | 145 | 146 | 146 | 146 | 145 | 136 | 133 | 132 | 135 | 136 | 136 | 133 | 133 | 133 | 134 | 133 | 135 | 139 | 138 | 135 | 135 | 134 | 133 | 134 | 136 | 134 | 129 | 129 | 132 | 133 | 134 | 135 | 135 | . 218 153 | 161 | 162 | 156 | 157 | 164 | 164 | 156 | 152 | 150 | 148 | 145 | 142 | 141 | 141 | 141 | 141 | 135 | 132 | 133 | 135 | 136 | 135 | 130 | 135 | 130 | 127 | 128 | 130 | 129 | 127 | 124 | 139 | 145 | 136 | 135 | 134 | 132 | 139 | 132 | 132 | 139 | 137 | 132 | 134 | 136 | 137 | 137 | 135 | 141 | 154 | 158 | 153 | 152 | 151 | 144 | 142 | 142 | 143 | 142 | 142 | 140 | 139 | 138 | 144 | 143 | 142 | 142 | 142 | 143 | 144 | 145 | 144 | 138 | 127 | 134 | 132 | 138 | 129 | 127 | 131 | 127 | 129 | 135 | 138 | 137 | 135 | 130 | 130 | 131 | 132 | 134 | 131 | 127 | 127 | 131 | 134 | 134 | 134 | 135 | . 219 153 | 155 | 157 | 158 | 159 | 161 | 164 | 165 | 157 | 155 | 151 | 147 | 144 | 142 | 142 | 142 | 148 | 139 | 137 | 136 | 132 | 131 | 132 | 126 | 129 | 130 | 131 | 131 | 130 | 128 | 126 | 126 | 127 | 137 | 136 | 136 | 135 | 134 | 136 | 127 | 131 | 136 | 136 | 134 | 137 | 139 | 138 | 140 | 133 | 133 | 146 | 155 | 150 | 150 | 152 | 145 | 143 | 142 | 141 | 140 | 139 | 138 | 136 | 135 | 142 | 141 | 140 | 138 | 137 | 137 | 137 | 138 | 152 | 147 | 139 | 143 | 142 | 144 | 135 | 130 | 131 | 125 | 128 | 135 | 134 | 134 | 134 | 129 | 131 | 132 | 134 | 134 | 131 | 128 | 130 | 135 | 133 | 133 | 134 | 136 | . 220 151 | 151 | 153 | 157 | 157 | 156 | 158 | 162 | 164 | 159 | 153 | 150 | 150 | 148 | 144 | 140 | 145 | 137 | 137 | 137 | 130 | 129 | 131 | 129 | 127 | 129 | 131 | 131 | 130 | 129 | 128 | 128 | 125 | 134 | 133 | 130 | 129 | 132 | 136 | 130 | 130 | 133 | 134 | 137 | 140 | 136 | 134 | 137 | 137 | 146 | 156 | 151 | 140 | 147 | 154 | 144 | 141 | 139 | 138 | 137 | 137 | 137 | 137 | 136 | 138 | 138 | 139 | 138 | 137 | 136 | 136 | 137 | 147 | 146 | 149 | 145 | 148 | 142 | 141 | 136 | 136 | 130 | 133 | 138 | 133 | 131 | 134 | 133 | 133 | 135 | 136 | 136 | 133 | 132 | 135 | 140 | 131 | 132 | 133 | 134 | . 221 147 | 151 | 154 | 154 | 155 | 158 | 160 | 159 | 161 | 164 | 164 | 160 | 152 | 146 | 144 | 145 | 142 | 137 | 137 | 136 | 130 | 127 | 129 | 131 | 131 | 129 | 127 | 126 | 128 | 130 | 130 | 127 | 126 | 132 | 133 | 129 | 128 | 132 | 134 | 130 | 131 | 131 | 131 | 135 | 137 | 131 | 127 | 131 | 136 | 148 | 162 | 161 | 146 | 141 | 144 | 142 | 142 | 140 | 136 | 135 | 135 | 135 | 134 | 134 | 131 | 134 | 137 | 138 | 138 | 138 | 139 | 139 | 139 | 140 | 147 | 140 | 143 | 137 | 142 | 141 | 147 | 143 | 144 | 144 | 136 | 129 | 128 | 131 | 131 | 133 | 135 | 135 | 134 | 134 | 137 | 140 | 134 | 134 | 134 | 132 | . 222 146 | 151 | 153 | 152 | 154 | 159 | 160 | 158 | 156 | 162 | 168 | 166 | 157 | 150 | 148 | 150 | 145 | 142 | 138 | 136 | 133 | 127 | 125 | 129 | 131 | 131 | 129 | 126 | 126 | 128 | 128 | 127 | 125 | 129 | 134 | 132 | 132 | 134 | 130 | 127 | 130 | 132 | 131 | 131 | 133 | 132 | 129 | 131 | 130 | 133 | 144 | 155 | 152 | 140 | 138 | 145 | 143 | 140 | 137 | 135 | 134 | 134 | 132 | 130 | 129 | 132 | 137 | 139 | 139 | 140 | 140 | 141 | 141 | 144 | 147 | 143 | 142 | 142 | 145 | 147 | 149 | 149 | 149 | 148 | 142 | 130 | 124 | 129 | 129 | 132 | 135 | 137 | 138 | 138 | 139 | 140 | 138 | 136 | 133 | 131 | . 223 151 | 149 | 149 | 151 | 152 | 151 | 152 | 153 | 159 | 157 | 157 | 162 | 167 | 165 | 155 | 145 | 147 | 146 | 139 | 136 | 137 | 130 | 124 | 130 | 128 | 134 | 136 | 132 | 126 | 124 | 126 | 127 | 125 | 126 | 131 | 129 | 131 | 134 | 131 | 130 | 129 | 133 | 131 | 128 | 132 | 136 | 136 | 136 | 154 | 150 | 143 | 141 | 145 | 146 | 142 | 140 | 138 | 136 | 135 | 134 | 135 | 136 | 134 | 133 | 133 | 136 | 140 | 142 | 141 | 141 | 142 | 142 | 141 | 146 | 143 | 145 | 138 | 144 | 141 | 143 | 140 | 144 | 145 | 148 | 147 | 135 | 127 | 133 | 131 | 134 | 139 | 142 | 144 | 145 | 144 | 142 | 139 | 135 | 130 | 129 | . 224 152 | 151 | 150 | 150 | 150 | 151 | 152 | 152 | 151 | 155 | 160 | 161 | 161 | 161 | 164 | 167 | 146 | 149 | 145 | 136 | 131 | 132 | 131 | 126 | 128 | 126 | 126 | 128 | 130 | 130 | 127 | 124 | 125 | 126 | 127 | 128 | 130 | 133 | 133 | 131 | 128 | 129 | 130 | 133 | 135 | 132 | 131 | 137 | 144 | 143 | 151 | 151 | 146 | 139 | 133 | 137 | 137 | 135 | 136 | 136 | 132 | 131 | 134 | 133 | 133 | 138 | 140 | 139 | 138 | 134 | 133 | 139 | 141 | 142 | 143 | 144 | 142 | 140 | 139 | 141 | 139 | 146 | 146 | 140 | 139 | 138 | 132 | 127 | 129 | 137 | 145 | 145 | 144 | 145 | 147 | 149 | 141 | 127 | 124 | 130 | . 225 151 | 149 | 147 | 146 | 146 | 147 | 149 | 149 | 151 | 153 | 155 | 156 | 157 | 159 | 161 | 164 | 162 | 151 | 144 | 143 | 140 | 132 | 128 | 129 | 132 | 129 | 127 | 127 | 128 | 129 | 128 | 127 | 126 | 128 | 129 | 130 | 131 | 132 | 130 | 127 | 131 | 131 | 130 | 132 | 134 | 130 | 129 | 134 | 130 | 134 | 146 | 147 | 143 | 138 | 132 | 136 | 133 | 132 | 134 | 135 | 130 | 130 | 132 | 130 | 133 | 136 | 136 | 136 | 138 | 136 | 136 | 142 | 144 | 143 | 143 | 143 | 141 | 139 | 138 | 139 | 142 | 143 | 141 | 141 | 142 | 136 | 128 | 127 | 137 | 145 | 148 | 143 | 141 | 143 | 144 | 140 | 141 | 132 | 128 | 128 | . 226 148 | 147 | 146 | 146 | 148 | 150 | 151 | 151 | 152 | 151 | 150 | 151 | 153 | 156 | 159 | 160 | 164 | 162 | 155 | 147 | 142 | 140 | 135 | 130 | 125 | 125 | 126 | 127 | 129 | 129 | 128 | 127 | 131 | 132 | 131 | 131 | 132 | 132 | 130 | 127 | 132 | 132 | 129 | 129 | 131 | 128 | 127 | 132 | 131 | 138 | 149 | 146 | 140 | 137 | 132 | 133 | 131 | 131 | 134 | 135 | 131 | 131 | 132 | 130 | 131 | 134 | 133 | 133 | 135 | 135 | 139 | 147 | 147 | 144 | 142 | 142 | 141 | 138 | 137 | 138 | 144 | 141 | 138 | 140 | 139 | 130 | 127 | 135 | 139 | 146 | 146 | 139 | 138 | 144 | 143 | 136 | 141 | 137 | 132 | 126 | . 227 148 | 149 | 149 | 150 | 151 | 151 | 150 | 149 | 150 | 150 | 150 | 151 | 153 | 155 | 156 | 157 | 157 | 165 | 166 | 156 | 148 | 146 | 143 | 137 | 126 | 126 | 126 | 126 | 126 | 126 | 127 | 128 | 133 | 133 | 131 | 129 | 130 | 131 | 131 | 129 | 129 | 130 | 128 | 127 | 128 | 126 | 128 | 134 | 144 | 148 | 153 | 145 | 139 | 140 | 136 | 135 | 133 | 132 | 135 | 136 | 132 | 132 | 134 | 132 | 129 | 132 | 133 | 132 | 133 | 133 | 137 | 147 | 147 | 144 | 140 | 140 | 139 | 138 | 136 | 136 | 143 | 141 | 139 | 137 | 132 | 125 | 131 | 147 | 142 | 144 | 142 | 138 | 140 | 145 | 145 | 140 | 141 | 139 | 135 | 130 | . 228 153 | 152 | 150 | 149 | 148 | 146 | 145 | 143 | 147 | 149 | 151 | 153 | 153 | 153 | 154 | 155 | 154 | 157 | 163 | 166 | 160 | 150 | 146 | 148 | 140 | 136 | 130 | 125 | 122 | 124 | 127 | 130 | 130 | 130 | 129 | 129 | 130 | 131 | 130 | 128 | 126 | 129 | 129 | 127 | 127 | 127 | 132 | 140 | 146 | 147 | 150 | 143 | 142 | 147 | 142 | 139 | 134 | 133 | 135 | 135 | 131 | 131 | 133 | 132 | 131 | 131 | 130 | 131 | 136 | 136 | 135 | 138 | 143 | 139 | 137 | 137 | 137 | 136 | 135 | 135 | 140 | 141 | 138 | 134 | 132 | 131 | 138 | 150 | 148 | 144 | 141 | 142 | 144 | 143 | 142 | 142 | 143 | 140 | 141 | 141 | . 229 155 | 152 | 149 | 147 | 146 | 146 | 147 | 147 | 144 | 146 | 149 | 151 | 150 | 150 | 151 | 153 | 153 | 155 | 158 | 162 | 163 | 161 | 154 | 149 | 141 | 138 | 134 | 131 | 129 | 128 | 127 | 127 | 127 | 129 | 131 | 133 | 134 | 135 | 132 | 128 | 127 | 131 | 130 | 128 | 128 | 130 | 134 | 143 | 142 | 144 | 148 | 146 | 148 | 151 | 143 | 137 | 132 | 131 | 132 | 132 | 128 | 128 | 131 | 130 | 135 | 132 | 128 | 132 | 142 | 142 | 134 | 130 | 137 | 135 | 135 | 136 | 136 | 135 | 134 | 135 | 137 | 138 | 134 | 132 | 136 | 140 | 140 | 143 | 145 | 140 | 139 | 143 | 143 | 138 | 137 | 140 | 143 | 141 | 144 | 148 | . 230 154 | 153 | 151 | 149 | 149 | 149 | 149 | 149 | 145 | 145 | 145 | 145 | 147 | 149 | 151 | 152 | 151 | 157 | 157 | 153 | 157 | 166 | 163 | 154 | 141 | 139 | 137 | 136 | 136 | 134 | 131 | 128 | 129 | 131 | 132 | 133 | 134 | 135 | 133 | 129 | 131 | 132 | 129 | 126 | 128 | 130 | 132 | 137 | 139 | 140 | 147 | 147 | 148 | 148 | 138 | 133 | 131 | 130 | 132 | 132 | 128 | 129 | 131 | 129 | 134 | 134 | 134 | 139 | 145 | 142 | 134 | 132 | 135 | 135 | 137 | 139 | 139 | 137 | 137 | 138 | 134 | 136 | 134 | 133 | 137 | 138 | 138 | 140 | 138 | 137 | 139 | 141 | 140 | 136 | 134 | 136 | 138 | 138 | 142 | 144 | . 231 156 | 155 | 155 | 154 | 152 | 148 | 145 | 142 | 148 | 144 | 141 | 141 | 145 | 149 | 152 | 153 | 155 | 153 | 152 | 154 | 156 | 158 | 163 | 168 | 154 | 147 | 139 | 135 | 134 | 136 | 136 | 136 | 130 | 130 | 128 | 127 | 129 | 131 | 131 | 129 | 134 | 133 | 127 | 123 | 127 | 128 | 128 | 130 | 135 | 135 | 143 | 143 | 143 | 142 | 133 | 130 | 131 | 130 | 134 | 135 | 131 | 131 | 133 | 131 | 129 | 137 | 144 | 146 | 144 | 138 | 135 | 140 | 136 | 137 | 141 | 143 | 143 | 140 | 140 | 141 | 131 | 136 | 136 | 135 | 132 | 130 | 133 | 143 | 139 | 143 | 145 | 143 | 139 | 135 | 133 | 131 | 131 | 134 | 138 | 137 | . 232 156 | 156 | 155 | 153 | 153 | 152 | 150 | 146 | 147 | 146 | 146 | 147 | 147 | 147 | 146 | 145 | 150 | 152 | 153 | 153 | 154 | 156 | 159 | 161 | 170 | 158 | 142 | 133 | 134 | 137 | 136 | 132 | 132 | 134 | 135 | 132 | 129 | 127 | 129 | 131 | 136 | 135 | 134 | 132 | 132 | 133 | 134 | 135 | 135 | 135 | 136 | 139 | 141 | 139 | 136 | 135 | 134 | 131 | 129 | 134 | 140 | 136 | 130 | 132 | 132 | 135 | 142 | 144 | 141 | 143 | 146 | 143 | 147 | 138 | 138 | 142 | 140 | 136 | 135 | 135 | 132 | 129 | 129 | 131 | 131 | 130 | 134 | 140 | 143 | 139 | 136 | 137 | 137 | 135 | 132 | 132 | 133 | 134 | 134 | 133 | . 233 153 | 157 | 160 | 158 | 153 | 151 | 150 | 149 | 146 | 148 | 149 | 149 | 147 | 145 | 143 | 142 | 144 | 146 | 148 | 150 | 151 | 154 | 156 | 158 | 163 | 165 | 161 | 150 | 139 | 134 | 136 | 139 | 137 | 136 | 135 | 136 | 135 | 133 | 129 | 126 | 129 | 132 | 135 | 139 | 142 | 143 | 144 | 143 | 144 | 141 | 139 | 137 | 134 | 131 | 131 | 133 | 130 | 137 | 140 | 138 | 132 | 126 | 130 | 142 | 131 | 130 | 134 | 139 | 137 | 137 | 140 | 141 | 140 | 134 | 136 | 141 | 140 | 139 | 138 | 137 | 133 | 130 | 129 | 130 | 129 | 127 | 130 | 135 | 141 | 140 | 141 | 142 | 140 | 136 | 134 | 134 | 129 | 130 | 132 | 133 | . 234 157 | 155 | 154 | 153 | 155 | 156 | 152 | 147 | 144 | 147 | 149 | 148 | 145 | 144 | 144 | 145 | 144 | 145 | 146 | 149 | 152 | 154 | 155 | 155 | 156 | 161 | 166 | 163 | 156 | 148 | 141 | 136 | 137 | 135 | 135 | 136 | 138 | 137 | 134 | 131 | 128 | 128 | 129 | 130 | 133 | 135 | 138 | 140 | 146 | 146 | 148 | 148 | 145 | 141 | 140 | 141 | 131 | 137 | 139 | 137 | 134 | 130 | 130 | 136 | 137 | 131 | 134 | 140 | 139 | 136 | 140 | 144 | 143 | 139 | 139 | 138 | 135 | 135 | 134 | 130 | 132 | 130 | 129 | 131 | 130 | 129 | 131 | 135 | 135 | 138 | 141 | 142 | 138 | 133 | 132 | 134 | 132 | 133 | 133 | 133 | . 235 159 | 156 | 151 | 151 | 155 | 158 | 155 | 150 | 148 | 149 | 148 | 146 | 144 | 144 | 145 | 147 | 147 | 147 | 146 | 148 | 151 | 153 | 153 | 153 | 154 | 155 | 157 | 161 | 165 | 163 | 153 | 143 | 140 | 139 | 137 | 136 | 135 | 136 | 138 | 139 | 137 | 135 | 132 | 130 | 130 | 131 | 133 | 135 | 135 | 136 | 139 | 142 | 143 | 141 | 141 | 142 | 137 | 136 | 131 | 129 | 135 | 136 | 132 | 129 | 134 | 129 | 130 | 135 | 133 | 132 | 135 | 137 | 140 | 138 | 138 | 135 | 133 | 138 | 141 | 137 | 131 | 129 | 129 | 130 | 130 | 129 | 130 | 132 | 132 | 135 | 138 | 137 | 133 | 130 | 131 | 133 | 137 | 137 | 135 | 134 | . 236 155 | 159 | 161 | 159 | 155 | 156 | 158 | 160 | 156 | 155 | 153 | 150 | 148 | 147 | 145 | 144 | 144 | 143 | 142 | 143 | 145 | 148 | 150 | 150 | 155 | 156 | 156 | 155 | 157 | 160 | 163 | 164 | 154 | 149 | 143 | 139 | 139 | 140 | 141 | 141 | 138 | 139 | 139 | 139 | 137 | 135 | 133 | 132 | 134 | 129 | 125 | 126 | 128 | 130 | 132 | 134 | 137 | 137 | 131 | 126 | 128 | 131 | 133 | 136 | 130 | 129 | 132 | 132 | 129 | 130 | 132 | 129 | 139 | 139 | 139 | 137 | 135 | 140 | 142 | 137 | 131 | 129 | 128 | 128 | 127 | 125 | 125 | 125 | 136 | 137 | 135 | 133 | 131 | 131 | 132 | 133 | 133 | 134 | 135 | 136 | . 237 154 | 158 | 162 | 161 | 160 | 159 | 158 | 157 | 157 | 157 | 156 | 156 | 156 | 154 | 150 | 147 | 141 | 140 | 139 | 140 | 143 | 146 | 149 | 150 | 151 | 154 | 155 | 153 | 153 | 156 | 160 | 162 | 162 | 154 | 147 | 146 | 149 | 151 | 148 | 143 | 140 | 140 | 139 | 138 | 136 | 134 | 132 | 131 | 137 | 131 | 126 | 127 | 129 | 130 | 130 | 130 | 133 | 135 | 132 | 131 | 133 | 133 | 131 | 134 | 131 | 134 | 138 | 137 | 133 | 134 | 135 | 131 | 137 | 137 | 139 | 138 | 134 | 135 | 134 | 128 | 131 | 129 | 128 | 128 | 128 | 129 | 129 | 129 | 139 | 138 | 135 | 131 | 130 | 132 | 133 | 132 | 128 | 132 | 135 | 138 | . 238 160 | 158 | 157 | 157 | 161 | 162 | 158 | 153 | 154 | 155 | 156 | 157 | 157 | 157 | 156 | 156 | 146 | 146 | 145 | 144 | 144 | 146 | 148 | 149 | 148 | 150 | 152 | 153 | 155 | 156 | 154 | 151 | 159 | 156 | 152 | 151 | 151 | 152 | 151 | 150 | 150 | 148 | 145 | 142 | 140 | 138 | 138 | 138 | 132 | 130 | 130 | 132 | 134 | 133 | 131 | 130 | 132 | 130 | 129 | 134 | 139 | 135 | 129 | 128 | 128 | 130 | 136 | 137 | 132 | 129 | 131 | 130 | 130 | 130 | 134 | 136 | 135 | 136 | 137 | 134 | 130 | 130 | 129 | 130 | 133 | 135 | 136 | 136 | 139 | 139 | 136 | 132 | 131 | 131 | 131 | 130 | 129 | 132 | 135 | 136 | . 239 163 | 163 | 161 | 158 | 157 | 158 | 159 | 159 | 155 | 156 | 156 | 154 | 153 | 154 | 157 | 161 | 153 | 153 | 152 | 149 | 146 | 144 | 144 | 145 | 149 | 152 | 153 | 151 | 150 | 152 | 155 | 157 | 156 | 159 | 159 | 152 | 145 | 142 | 147 | 153 | 147 | 148 | 150 | 150 | 149 | 146 | 142 | 140 | 137 | 135 | 133 | 134 | 135 | 135 | 136 | 138 | 135 | 131 | 127 | 129 | 132 | 128 | 128 | 134 | 128 | 127 | 134 | 139 | 133 | 126 | 129 | 133 | 140 | 137 | 138 | 138 | 135 | 135 | 137 | 137 | 132 | 131 | 130 | 131 | 133 | 136 | 137 | 137 | 139 | 140 | 139 | 135 | 133 | 132 | 131 | 129 | 129 | 130 | 131 | 132 | . 240 158 | 159 | 162 | 165 | 165 | 163 | 158 | 155 | 166 | 156 | 150 | 153 | 155 | 153 | 153 | 157 | 156 | 153 | 150 | 149 | 150 | 150 | 148 | 146 | 144 | 148 | 151 | 151 | 150 | 150 | 153 | 157 | 162 | 154 | 153 | 158 | 156 | 146 | 141 | 143 | 148 | 147 | 148 | 150 | 150 | 147 | 145 | 146 | 140 | 134 | 131 | 133 | 136 | 136 | 135 | 135 | 141 | 133 | 128 | 129 | 130 | 129 | 128 | 129 | 124 | 132 | 136 | 140 | 132 | 123 | 132 | 140 | 142 | 135 | 140 | 142 | 145 | 131 | 134 | 139 | 133 | 132 | 130 | 129 | 130 | 132 | 133 | 133 | 141 | 140 | 139 | 137 | 135 | 133 | 131 | 130 | 126 | 130 | 131 | 129 | . 241 156 | 157 | 159 | 161 | 163 | 163 | 161 | 160 | 158 | 162 | 161 | 154 | 151 | 155 | 157 | 156 | 152 | 155 | 157 | 154 | 149 | 147 | 148 | 150 | 147 | 146 | 146 | 148 | 152 | 155 | 156 | 156 | 152 | 160 | 162 | 157 | 157 | 159 | 152 | 141 | 135 | 143 | 146 | 142 | 144 | 149 | 146 | 136 | 140 | 134 | 130 | 130 | 131 | 131 | 132 | 133 | 136 | 130 | 127 | 130 | 133 | 131 | 130 | 130 | 130 | 129 | 126 | 133 | 135 | 132 | 137 | 139 | 127 | 135 | 142 | 137 | 135 | 132 | 134 | 132 | 130 | 130 | 129 | 130 | 132 | 133 | 132 | 132 | 136 | 135 | 134 | 133 | 131 | 130 | 129 | 128 | 131 | 131 | 129 | 128 | . 242 155 | 155 | 155 | 157 | 160 | 162 | 164 | 164 | 160 | 160 | 161 | 161 | 157 | 152 | 154 | 158 | 155 | 155 | 154 | 154 | 154 | 152 | 150 | 148 | 148 | 146 | 145 | 147 | 151 | 155 | 155 | 153 | 155 | 156 | 156 | 155 | 156 | 157 | 155 | 151 | 135 | 133 | 131 | 131 | 133 | 137 | 140 | 141 | 145 | 140 | 135 | 132 | 131 | 131 | 133 | 135 | 135 | 131 | 130 | 133 | 135 | 132 | 128 | 127 | 130 | 130 | 127 | 130 | 130 | 128 | 137 | 140 | 137 | 135 | 133 | 137 | 135 | 134 | 129 | 127 | 131 | 130 | 129 | 129 | 130 | 130 | 130 | 130 | 135 | 135 | 133 | 132 | 130 | 130 | 129 | 129 | 128 | 129 | 128 | 127 | . 243 155 | 154 | 153 | 154 | 157 | 160 | 162 | 164 | 164 | 157 | 157 | 162 | 162 | 155 | 153 | 156 | 156 | 153 | 152 | 153 | 156 | 156 | 153 | 150 | 149 | 149 | 149 | 148 | 147 | 147 | 149 | 151 | 157 | 153 | 151 | 154 | 156 | 155 | 157 | 161 | 161 | 152 | 143 | 138 | 134 | 131 | 135 | 142 | 145 | 143 | 140 | 136 | 134 | 132 | 133 | 134 | 134 | 132 | 131 | 134 | 135 | 132 | 128 | 127 | 130 | 133 | 130 | 129 | 126 | 123 | 132 | 135 | 147 | 139 | 130 | 136 | 133 | 135 | 127 | 128 | 131 | 129 | 127 | 126 | 127 | 128 | 130 | 131 | 135 | 135 | 134 | 133 | 132 | 131 | 130 | 130 | 125 | 130 | 131 | 129 | . 244 155 | 154 | 153 | 154 | 155 | 157 | 159 | 159 | 159 | 163 | 162 | 158 | 158 | 163 | 160 | 153 | 151 | 153 | 155 | 154 | 152 | 151 | 155 | 158 | 153 | 152 | 151 | 149 | 147 | 146 | 147 | 148 | 148 | 152 | 153 | 153 | 156 | 161 | 161 | 159 | 159 | 164 | 161 | 149 | 142 | 143 | 142 | 136 | 140 | 141 | 140 | 138 | 135 | 132 | 131 | 131 | 130 | 128 | 128 | 130 | 132 | 131 | 130 | 129 | 132 | 133 | 128 | 128 | 129 | 128 | 132 | 128 | 134 | 143 | 139 | 133 | 123 | 132 | 132 | 131 | 129 | 128 | 128 | 127 | 127 | 128 | 130 | 131 | 130 | 130 | 130 | 130 | 130 | 129 | 128 | 128 | 129 | 133 | 134 | 130 | . 245 154 | 153 | 153 | 153 | 154 | 155 | 155 | 155 | 158 | 162 | 164 | 162 | 160 | 161 | 161 | 160 | 154 | 154 | 153 | 152 | 152 | 153 | 155 | 157 | 157 | 154 | 150 | 150 | 151 | 152 | 150 | 148 | 146 | 143 | 143 | 146 | 149 | 150 | 154 | 159 | 152 | 157 | 160 | 157 | 152 | 149 | 146 | 142 | 141 | 143 | 144 | 143 | 141 | 139 | 136 | 134 | 133 | 130 | 128 | 127 | 127 | 127 | 127 | 126 | 126 | 132 | 131 | 131 | 131 | 131 | 137 | 136 | 135 | 139 | 137 | 136 | 130 | 130 | 130 | 131 | 133 | 133 | 133 | 131 | 129 | 127 | 126 | 125 | 127 | 128 | 128 | 128 | 128 | 128 | 128 | 128 | 131 | 131 | 130 | 130 | . 246 152 | 152 | 152 | 153 | 154 | 154 | 154 | 154 | 159 | 156 | 158 | 164 | 165 | 160 | 159 | 162 | 161 | 156 | 151 | 151 | 154 | 156 | 155 | 152 | 156 | 154 | 152 | 152 | 153 | 154 | 152 | 151 | 152 | 143 | 138 | 141 | 142 | 140 | 146 | 157 | 163 | 159 | 159 | 163 | 160 | 152 | 147 | 149 | 148 | 149 | 149 | 147 | 146 | 145 | 143 | 141 | 140 | 137 | 132 | 128 | 126 | 126 | 125 | 124 | 121 | 132 | 133 | 132 | 129 | 131 | 142 | 144 | 143 | 132 | 131 | 136 | 139 | 129 | 129 | 134 | 138 | 137 | 136 | 133 | 129 | 128 | 127 | 128 | 134 | 133 | 131 | 129 | 128 | 128 | 128 | 128 | 128 | 128 | 129 | 132 | . 247 150 | 150 | 150 | 152 | 153 | 155 | 155 | 155 | 154 | 156 | 156 | 156 | 162 | 168 | 163 | 152 | 159 | 159 | 158 | 155 | 151 | 150 | 152 | 154 | 152 | 155 | 157 | 155 | 151 | 149 | 152 | 155 | 152 | 156 | 153 | 144 | 142 | 149 | 151 | 147 | 145 | 151 | 154 | 156 | 160 | 164 | 159 | 150 | 149 | 149 | 147 | 145 | 144 | 145 | 144 | 142 | 142 | 139 | 135 | 131 | 129 | 129 | 128 | 128 | 127 | 131 | 127 | 127 | 131 | 137 | 145 | 141 | 133 | 131 | 135 | 129 | 133 | 128 | 136 | 139 | 136 | 135 | 132 | 130 | 129 | 131 | 136 | 140 | 141 | 138 | 134 | 131 | 128 | 127 | 127 | 128 | 127 | 130 | 134 | 135 | . 248 150 | 151 | 150 | 149 | 150 | 152 | 154 | 153 | 154 | 152 | 152 | 154 | 157 | 160 | 164 | 168 | 159 | 159 | 163 | 164 | 157 | 148 | 147 | 151 | 152 | 154 | 155 | 157 | 157 | 156 | 154 | 153 | 155 | 153 | 153 | 155 | 154 | 149 | 146 | 144 | 147 | 154 | 156 | 154 | 155 | 162 | 166 | 165 | 158 | 152 | 147 | 147 | 149 | 148 | 146 | 145 | 146 | 145 | 141 | 136 | 135 | 135 | 132 | 128 | 130 | 128 | 126 | 126 | 129 | 132 | 132 | 129 | 132 | 133 | 132 | 134 | 136 | 133 | 134 | 140 | 138 | 130 | 128 | 137 | 144 | 142 | 137 | 136 | 133 | 131 | 130 | 129 | 128 | 126 | 127 | 129 | 129 | 130 | 130 | 129 | . 249 149 | 150 | 150 | 149 | 149 | 151 | 153 | 152 | 154 | 152 | 152 | 153 | 154 | 155 | 158 | 161 | 162 | 161 | 162 | 164 | 166 | 164 | 157 | 150 | 153 | 153 | 153 | 153 | 153 | 153 | 153 | 152 | 155 | 154 | 154 | 154 | 152 | 149 | 151 | 154 | 152 | 144 | 142 | 148 | 151 | 151 | 157 | 165 | 165 | 161 | 157 | 153 | 151 | 150 | 147 | 145 | 146 | 145 | 143 | 141 | 140 | 139 | 136 | 131 | 133 | 132 | 129 | 127 | 129 | 132 | 133 | 132 | 134 | 133 | 131 | 131 | 132 | 130 | 130 | 137 | 138 | 134 | 131 | 133 | 137 | 141 | 144 | 146 | 146 | 137 | 131 | 133 | 135 | 132 | 129 | 129 | 129 | 128 | 128 | 128 | . 250 147 | 148 | 149 | 148 | 148 | 151 | 151 | 151 | 155 | 154 | 153 | 155 | 155 | 154 | 155 | 156 | 156 | 160 | 160 | 157 | 159 | 164 | 166 | 163 | 155 | 155 | 153 | 152 | 151 | 151 | 151 | 151 | 147 | 152 | 158 | 160 | 157 | 154 | 154 | 156 | 146 | 137 | 135 | 140 | 139 | 135 | 143 | 158 | 161 | 163 | 163 | 159 | 157 | 156 | 154 | 151 | 149 | 150 | 149 | 148 | 147 | 144 | 139 | 135 | 137 | 136 | 134 | 130 | 130 | 132 | 133 | 133 | 133 | 132 | 128 | 128 | 129 | 127 | 128 | 135 | 135 | 135 | 132 | 126 | 126 | 135 | 145 | 150 | 143 | 135 | 129 | 131 | 134 | 131 | 129 | 129 | 129 | 127 | 125 | 126 | . 251 144 | 146 | 147 | 146 | 148 | 150 | 150 | 150 | 153 | 152 | 153 | 155 | 155 | 154 | 154 | 156 | 153 | 157 | 157 | 153 | 152 | 158 | 164 | 166 | 157 | 158 | 158 | 156 | 152 | 150 | 151 | 152 | 151 | 152 | 153 | 154 | 154 | 155 | 158 | 161 | 154 | 149 | 143 | 141 | 146 | 151 | 150 | 145 | 150 | 158 | 162 | 160 | 159 | 160 | 159 | 155 | 153 | 153 | 154 | 154 | 153 | 150 | 146 | 142 | 139 | 140 | 139 | 136 | 133 | 133 | 133 | 133 | 131 | 130 | 126 | 127 | 129 | 127 | 128 | 135 | 133 | 134 | 132 | 126 | 125 | 131 | 140 | 146 | 138 | 138 | 135 | 133 | 130 | 129 | 129 | 129 | 130 | 128 | 126 | 125 | . 252 143 | 145 | 145 | 145 | 146 | 149 | 149 | 149 | 149 | 148 | 150 | 152 | 154 | 153 | 153 | 154 | 157 | 156 | 156 | 157 | 159 | 159 | 157 | 156 | 155 | 159 | 162 | 160 | 156 | 153 | 153 | 154 | 149 | 149 | 151 | 154 | 158 | 159 | 156 | 152 | 148 | 158 | 162 | 156 | 152 | 155 | 153 | 148 | 147 | 154 | 157 | 154 | 153 | 156 | 157 | 155 | 153 | 154 | 155 | 157 | 157 | 155 | 153 | 152 | 140 | 143 | 144 | 142 | 138 | 136 | 134 | 132 | 131 | 130 | 127 | 128 | 131 | 129 | 129 | 134 | 133 | 132 | 133 | 135 | 136 | 137 | 141 | 145 | 144 | 148 | 145 | 137 | 133 | 135 | 133 | 128 | 128 | 129 | 129 | 128 | . 253 143 | 145 | 145 | 144 | 145 | 147 | 148 | 147 | 149 | 148 | 149 | 151 | 152 | 152 | 152 | 154 | 155 | 155 | 156 | 157 | 157 | 155 | 157 | 160 | 153 | 156 | 160 | 160 | 159 | 157 | 156 | 157 | 150 | 150 | 150 | 153 | 156 | 157 | 153 | 147 | 142 | 152 | 161 | 160 | 153 | 148 | 149 | 151 | 148 | 150 | 150 | 147 | 148 | 153 | 156 | 156 | 157 | 156 | 156 | 157 | 156 | 154 | 153 | 153 | 143 | 146 | 148 | 146 | 143 | 140 | 136 | 133 | 133 | 132 | 129 | 131 | 133 | 130 | 127 | 132 | 130 | 128 | 131 | 139 | 145 | 145 | 143 | 143 | 140 | 141 | 137 | 131 | 133 | 139 | 134 | 125 | 126 | 129 | 132 | 132 | . 254 145 | 146 | 145 | 144 | 144 | 145 | 146 | 146 | 150 | 148 | 148 | 150 | 151 | 151 | 152 | 154 | 150 | 155 | 156 | 152 | 149 | 153 | 160 | 165 | 156 | 155 | 155 | 157 | 160 | 160 | 159 | 157 | 159 | 156 | 150 | 143 | 142 | 148 | 154 | 158 | 160 | 152 | 148 | 153 | 160 | 161 | 156 | 150 | 151 | 149 | 147 | 148 | 151 | 154 | 156 | 156 | 157 | 156 | 156 | 156 | 154 | 151 | 150 | 151 | 148 | 150 | 150 | 148 | 145 | 143 | 140 | 138 | 135 | 133 | 130 | 131 | 133 | 129 | 126 | 130 | 128 | 127 | 129 | 135 | 143 | 146 | 142 | 136 | 132 | 129 | 125 | 125 | 130 | 134 | 133 | 129 | 130 | 131 | 131 | 131 | . 255 147 | 147 | 146 | 143 | 143 | 144 | 145 | 144 | 147 | 146 | 145 | 147 | 148 | 148 | 150 | 153 | 153 | 156 | 154 | 150 | 153 | 161 | 159 | 151 | 162 | 157 | 153 | 154 | 160 | 163 | 160 | 156 | 147 | 154 | 159 | 156 | 150 | 148 | 148 | 149 | 158 | 160 | 159 | 153 | 150 | 154 | 160 | 163 | 155 | 151 | 150 | 154 | 157 | 155 | 152 | 150 | 151 | 151 | 152 | 154 | 154 | 152 | 151 | 153 | 152 | 152 | 151 | 148 | 146 | 145 | 144 | 142 | 135 | 133 | 129 | 130 | 132 | 129 | 126 | 130 | 129 | 131 | 130 | 130 | 137 | 143 | 139 | 129 | 133 | 129 | 127 | 131 | 131 | 130 | 133 | 140 | 137 | 133 | 128 | 126 | . 256 146 | 147 | 148 | 147 | 146 | 146 | 148 | 151 | 143 | 146 | 147 | 147 | 147 | 148 | 149 | 148 | 149 | 151 | 149 | 146 | 146 | 149 | 151 | 149 | 157 | 157 | 158 | 156 | 149 | 145 | 156 | 171 | 161 | 151 | 150 | 157 | 161 | 160 | 155 | 148 | 154 | 150 | 151 | 154 | 153 | 150 | 155 | 163 | 163 | 158 | 156 | 159 | 158 | 153 | 150 | 151 | 151 | 152 | 151 | 150 | 152 | 156 | 156 | 154 | 152 | 152 | 152 | 151 | 150 | 148 | 147 | 146 | 138 | 139 | 137 | 132 | 128 | 127 | 127 | 126 | 130 | 130 | 132 | 136 | 138 | 138 | 141 | 144 | 142 | 138 | 133 | 130 | 129 | 129 | 129 | 129 | 140 | 127 | 127 | 128 | . 257 144 | 145 | 146 | 146 | 145 | 145 | 146 | 148 | 149 | 148 | 146 | 142 | 141 | 143 | 146 | 146 | 146 | 147 | 146 | 145 | 146 | 148 | 150 | 150 | 148 | 153 | 157 | 156 | 151 | 150 | 153 | 156 | 166 | 163 | 159 | 150 | 145 | 152 | 159 | 159 | 143 | 142 | 145 | 152 | 158 | 159 | 154 | 150 | 157 | 161 | 163 | 160 | 160 | 163 | 162 | 158 | 150 | 152 | 153 | 152 | 153 | 153 | 151 | 147 | 154 | 153 | 152 | 150 | 149 | 148 | 148 | 148 | 145 | 143 | 138 | 133 | 130 | 130 | 129 | 128 | 131 | 129 | 129 | 131 | 134 | 136 | 141 | 146 | 144 | 141 | 137 | 133 | 131 | 130 | 129 | 128 | 131 | 124 | 129 | 131 | . 258 143 | 144 | 146 | 146 | 145 | 145 | 146 | 147 | 149 | 148 | 144 | 139 | 138 | 140 | 142 | 143 | 146 | 144 | 144 | 146 | 147 | 147 | 149 | 151 | 146 | 154 | 157 | 153 | 153 | 158 | 156 | 150 | 158 | 160 | 162 | 158 | 150 | 151 | 155 | 156 | 169 | 157 | 142 | 135 | 143 | 155 | 159 | 156 | 156 | 161 | 162 | 158 | 157 | 160 | 162 | 161 | 162 | 160 | 155 | 149 | 146 | 148 | 151 | 152 | 153 | 153 | 152 | 152 | 151 | 151 | 150 | 150 | 147 | 144 | 138 | 132 | 131 | 132 | 131 | 129 | 130 | 128 | 128 | 129 | 131 | 133 | 138 | 142 | 139 | 137 | 134 | 132 | 130 | 128 | 126 | 124 | 128 | 123 | 132 | 136 | . 259 143 | 145 | 146 | 146 | 145 | 145 | 145 | 144 | 145 | 146 | 145 | 143 | 142 | 143 | 144 | 143 | 147 | 145 | 145 | 148 | 149 | 147 | 149 | 152 | 151 | 155 | 153 | 148 | 151 | 159 | 161 | 156 | 151 | 146 | 153 | 166 | 165 | 156 | 150 | 149 | 149 | 161 | 170 | 165 | 154 | 148 | 148 | 151 | 154 | 153 | 155 | 160 | 159 | 154 | 153 | 156 | 157 | 159 | 161 | 160 | 158 | 155 | 154 | 153 | 150 | 151 | 153 | 154 | 154 | 153 | 151 | 150 | 144 | 143 | 139 | 135 | 133 | 133 | 132 | 130 | 128 | 128 | 129 | 130 | 130 | 130 | 131 | 133 | 130 | 129 | 128 | 127 | 126 | 125 | 124 | 123 | 128 | 124 | 131 | 139 | . 260 143 | 146 | 146 | 145 | 144 | 145 | 144 | 142 | 145 | 147 | 149 | 148 | 147 | 148 | 148 | 147 | 149 | 146 | 147 | 149 | 150 | 147 | 147 | 150 | 153 | 153 | 150 | 147 | 149 | 154 | 158 | 158 | 156 | 145 | 145 | 155 | 158 | 157 | 157 | 157 | 159 | 153 | 149 | 155 | 163 | 163 | 157 | 151 | 149 | 148 | 152 | 160 | 162 | 158 | 154 | 154 | 153 | 155 | 159 | 161 | 161 | 160 | 160 | 161 | 152 | 153 | 153 | 154 | 153 | 153 | 152 | 151 | 145 | 147 | 146 | 142 | 138 | 135 | 133 | 131 | 128 | 129 | 130 | 130 | 129 | 128 | 128 | 127 | 127 | 127 | 126 | 125 | 125 | 125 | 126 | 126 | 127 | 123 | 128 | 134 | . 261 147 | 149 | 148 | 145 | 145 | 147 | 147 | 145 | 146 | 148 | 148 | 146 | 146 | 147 | 148 | 148 | 147 | 147 | 147 | 148 | 148 | 147 | 147 | 147 | 149 | 150 | 152 | 153 | 153 | 152 | 153 | 155 | 159 | 155 | 150 | 144 | 144 | 155 | 163 | 162 | 155 | 154 | 156 | 158 | 156 | 153 | 156 | 161 | 154 | 156 | 153 | 150 | 152 | 158 | 160 | 156 | 161 | 158 | 154 | 153 | 153 | 155 | 160 | 164 | 158 | 157 | 155 | 153 | 151 | 151 | 152 | 153 | 151 | 154 | 155 | 151 | 145 | 141 | 137 | 134 | 134 | 134 | 133 | 130 | 128 | 129 | 130 | 130 | 128 | 128 | 127 | 125 | 124 | 124 | 126 | 127 | 127 | 128 | 129 | 127 | . 262 147 | 149 | 148 | 144 | 144 | 148 | 149 | 147 | 145 | 146 | 146 | 145 | 144 | 145 | 146 | 145 | 144 | 146 | 147 | 147 | 147 | 148 | 148 | 147 | 146 | 149 | 152 | 155 | 155 | 153 | 153 | 154 | 154 | 159 | 160 | 153 | 148 | 154 | 158 | 152 | 162 | 162 | 159 | 155 | 154 | 155 | 157 | 158 | 161 | 161 | 156 | 148 | 148 | 154 | 157 | 156 | 156 | 155 | 156 | 159 | 159 | 156 | 154 | 154 | 160 | 159 | 157 | 155 | 154 | 153 | 153 | 153 | 153 | 155 | 155 | 152 | 149 | 147 | 144 | 142 | 141 | 141 | 138 | 133 | 130 | 131 | 132 | 132 | 130 | 130 | 129 | 127 | 125 | 124 | 125 | 126 | 128 | 131 | 130 | 124 | . 263 144 | 145 | 143 | 140 | 141 | 146 | 147 | 145 | 143 | 146 | 148 | 148 | 147 | 147 | 147 | 145 | 142 | 146 | 147 | 146 | 147 | 150 | 150 | 147 | 144 | 148 | 150 | 150 | 151 | 154 | 156 | 156 | 150 | 154 | 162 | 165 | 160 | 154 | 149 | 141 | 148 | 160 | 166 | 162 | 157 | 158 | 159 | 156 | 155 | 155 | 158 | 163 | 160 | 153 | 151 | 153 | 156 | 154 | 153 | 156 | 159 | 159 | 160 | 161 | 157 | 158 | 159 | 159 | 159 | 157 | 154 | 152 | 150 | 150 | 149 | 149 | 150 | 152 | 151 | 149 | 147 | 147 | 144 | 138 | 134 | 134 | 133 | 132 | 132 | 133 | 132 | 131 | 128 | 127 | 127 | 127 | 125 | 128 | 128 | 125 | . 264 149 | 142 | 139 | 143 | 147 | 147 | 146 | 146 | 146 | 147 | 147 | 146 | 145 | 145 | 147 | 148 | 148 | 146 | 146 | 146 | 146 | 146 | 148 | 151 | 149 | 148 | 148 | 149 | 149 | 149 | 151 | 155 | 155 | 155 | 156 | 159 | 163 | 161 | 152 | 142 | 149 | 150 | 159 | 167 | 163 | 156 | 156 | 158 | 157 | 160 | 159 | 156 | 158 | 162 | 160 | 153 | 155 | 155 | 156 | 156 | 156 | 156 | 156 | 155 | 162 | 160 | 158 | 157 | 158 | 159 | 159 | 158 | 152 | 151 | 151 | 152 | 153 | 154 | 153 | 152 | 150 | 150 | 148 | 144 | 140 | 138 | 137 | 138 | 135 | 135 | 135 | 134 | 131 | 129 | 127 | 127 | 128 | 129 | 130 | 131 | . 265 145 | 145 | 146 | 146 | 144 | 142 | 144 | 146 | 143 | 144 | 146 | 147 | 146 | 145 | 145 | 145 | 149 | 147 | 146 | 146 | 145 | 144 | 145 | 148 | 148 | 148 | 149 | 151 | 151 | 150 | 151 | 154 | 153 | 153 | 155 | 158 | 163 | 165 | 161 | 155 | 152 | 143 | 144 | 154 | 163 | 165 | 162 | 156 | 156 | 157 | 158 | 158 | 158 | 159 | 159 | 158 | 155 | 155 | 154 | 154 | 154 | 155 | 155 | 155 | 158 | 158 | 158 | 157 | 157 | 157 | 158 | 158 | 162 | 160 | 157 | 154 | 152 | 153 | 155 | 157 | 151 | 152 | 152 | 150 | 146 | 143 | 141 | 141 | 138 | 137 | 137 | 137 | 137 | 134 | 130 | 127 | 129 | 132 | 133 | 131 | . 266 141 | 144 | 144 | 140 | 137 | 137 | 140 | 142 | 144 | 145 | 146 | 147 | 146 | 146 | 146 | 147 | 148 | 146 | 146 | 145 | 144 | 143 | 144 | 146 | 147 | 147 | 149 | 152 | 152 | 150 | 150 | 152 | 150 | 151 | 151 | 153 | 158 | 163 | 164 | 162 | 160 | 152 | 147 | 146 | 150 | 158 | 165 | 165 | 160 | 157 | 155 | 157 | 158 | 157 | 158 | 162 | 158 | 157 | 156 | 155 | 155 | 154 | 154 | 154 | 156 | 157 | 159 | 158 | 157 | 156 | 157 | 159 | 159 | 157 | 154 | 150 | 146 | 146 | 149 | 152 | 151 | 153 | 154 | 153 | 151 | 148 | 146 | 145 | 145 | 142 | 139 | 139 | 141 | 140 | 135 | 131 | 131 | 130 | 133 | 142 | . 267 151 | 151 | 147 | 142 | 142 | 146 | 147 | 145 | 146 | 146 | 144 | 143 | 144 | 145 | 147 | 149 | 145 | 144 | 144 | 145 | 145 | 144 | 145 | 148 | 146 | 147 | 149 | 150 | 151 | 150 | 150 | 150 | 150 | 151 | 150 | 149 | 152 | 156 | 159 | 160 | 166 | 166 | 163 | 153 | 144 | 148 | 159 | 163 | 166 | 160 | 155 | 155 | 157 | 158 | 159 | 160 | 161 | 160 | 159 | 158 | 156 | 154 | 152 | 151 | 154 | 156 | 157 | 158 | 158 | 157 | 158 | 159 | 155 | 156 | 156 | 154 | 152 | 150 | 150 | 150 | 150 | 151 | 152 | 152 | 152 | 150 | 149 | 149 | 151 | 147 | 142 | 140 | 141 | 141 | 139 | 137 | 131 | 132 | 132 | 134 | . 268 146 | 147 | 144 | 139 | 139 | 142 | 141 | 138 | 144 | 143 | 142 | 141 | 142 | 143 | 145 | 145 | 144 | 143 | 143 | 145 | 145 | 145 | 146 | 148 | 146 | 147 | 147 | 147 | 148 | 149 | 149 | 148 | 151 | 152 | 151 | 150 | 150 | 154 | 157 | 158 | 163 | 165 | 168 | 164 | 157 | 155 | 153 | 147 | 161 | 162 | 161 | 157 | 156 | 157 | 158 | 158 | 160 | 160 | 160 | 159 | 157 | 155 | 152 | 150 | 152 | 152 | 153 | 155 | 158 | 159 | 159 | 159 | 155 | 155 | 157 | 158 | 159 | 157 | 154 | 151 | 151 | 150 | 149 | 149 | 150 | 151 | 152 | 152 | 152 | 150 | 146 | 144 | 142 | 142 | 141 | 141 | 140 | 137 | 133 | 128 | . 269 145 | 149 | 152 | 150 | 146 | 143 | 142 | 141 | 141 | 142 | 143 | 145 | 146 | 145 | 143 | 141 | 144 | 143 | 143 | 145 | 145 | 144 | 145 | 147 | 146 | 147 | 146 | 145 | 146 | 148 | 148 | 147 | 147 | 149 | 149 | 149 | 150 | 153 | 156 | 156 | 156 | 159 | 166 | 168 | 165 | 164 | 160 | 152 | 151 | 160 | 165 | 162 | 157 | 156 | 156 | 157 | 159 | 160 | 161 | 161 | 161 | 159 | 157 | 156 | 151 | 150 | 150 | 152 | 156 | 158 | 159 | 158 | 155 | 155 | 154 | 156 | 157 | 157 | 154 | 152 | 154 | 152 | 150 | 149 | 150 | 152 | 153 | 154 | 149 | 150 | 151 | 150 | 147 | 144 | 143 | 142 | 146 | 143 | 140 | 139 | . 270 140 | 143 | 146 | 148 | 146 | 141 | 139 | 139 | 143 | 144 | 146 | 148 | 149 | 147 | 143 | 140 | 143 | 142 | 143 | 144 | 144 | 143 | 144 | 146 | 146 | 147 | 146 | 145 | 146 | 148 | 148 | 146 | 145 | 146 | 147 | 147 | 148 | 152 | 154 | 154 | 154 | 156 | 162 | 165 | 162 | 164 | 167 | 166 | 154 | 155 | 157 | 159 | 160 | 157 | 155 | 154 | 159 | 159 | 160 | 160 | 161 | 161 | 161 | 161 | 156 | 155 | 153 | 153 | 153 | 155 | 156 | 157 | 159 | 158 | 158 | 157 | 158 | 158 | 157 | 157 | 157 | 155 | 153 | 152 | 153 | 153 | 153 | 152 | 149 | 151 | 153 | 153 | 151 | 148 | 147 | 146 | 145 | 148 | 149 | 143 | . 271 147 | 142 | 141 | 146 | 150 | 149 | 145 | 144 | 144 | 144 | 145 | 146 | 147 | 146 | 143 | 140 | 141 | 141 | 142 | 143 | 143 | 143 | 143 | 145 | 146 | 147 | 146 | 145 | 146 | 149 | 148 | 145 | 146 | 147 | 147 | 147 | 148 | 151 | 152 | 151 | 154 | 151 | 155 | 161 | 162 | 164 | 165 | 162 | 166 | 152 | 144 | 152 | 162 | 161 | 155 | 151 | 157 | 157 | 156 | 156 | 156 | 157 | 158 | 159 | 162 | 161 | 159 | 155 | 152 | 151 | 153 | 155 | 154 | 156 | 157 | 156 | 155 | 155 | 156 | 157 | 158 | 157 | 156 | 155 | 155 | 153 | 151 | 149 | 151 | 152 | 152 | 153 | 152 | 151 | 151 | 151 | 151 | 149 | 148 | 148 | . 272 148 | 147 | 145 | 144 | 145 | 146 | 148 | 149 | 146 | 144 | 142 | 142 | 143 | 145 | 146 | 146 | 143 | 144 | 145 | 145 | 148 | 149 | 147 | 143 | 146 | 145 | 146 | 146 | 143 | 141 | 143 | 147 | 148 | 147 | 147 | 148 | 149 | 150 | 150 | 150 | 152 | 152 | 154 | 158 | 160 | 160 | 161 | 162 | 168 | 167 | 157 | 150 | 155 | 157 | 155 | 158 | 150 | 154 | 157 | 157 | 157 | 157 | 157 | 155 | 159 | 159 | 161 | 162 | 161 | 158 | 155 | 152 | 153 | 154 | 155 | 155 | 154 | 154 | 155 | 155 | 154 | 155 | 155 | 154 | 153 | 153 | 155 | 156 | 153 | 152 | 151 | 151 | 151 | 151 | 151 | 151 | 151 | 150 | 148 | 147 | . 273 147 | 147 | 146 | 145 | 145 | 146 | 147 | 148 | 144 | 143 | 143 | 144 | 145 | 146 | 145 | 145 | 143 | 144 | 144 | 144 | 145 | 146 | 144 | 141 | 144 | 142 | 141 | 142 | 142 | 141 | 141 | 143 | 144 | 144 | 145 | 147 | 149 | 151 | 152 | 152 | 152 | 151 | 152 | 156 | 159 | 159 | 159 | 159 | 157 | 166 | 170 | 164 | 157 | 152 | 153 | 158 | 151 | 153 | 155 | 156 | 156 | 155 | 156 | 157 | 156 | 156 | 157 | 158 | 159 | 158 | 157 | 156 | 156 | 156 | 156 | 155 | 154 | 154 | 156 | 157 | 155 | 155 | 156 | 156 | 155 | 154 | 155 | 156 | 154 | 153 | 151 | 150 | 149 | 148 | 147 | 145 | 151 | 150 | 149 | 149 | . 274 145 | 146 | 146 | 146 | 146 | 145 | 145 | 145 | 146 | 145 | 144 | 144 | 143 | 142 | 141 | 140 | 143 | 144 | 143 | 142 | 143 | 144 | 143 | 140 | 146 | 143 | 141 | 143 | 145 | 145 | 144 | 143 | 144 | 144 | 145 | 147 | 147 | 148 | 148 | 148 | 151 | 150 | 151 | 155 | 157 | 158 | 157 | 158 | 160 | 164 | 169 | 169 | 164 | 160 | 157 | 152 | 153 | 151 | 152 | 154 | 155 | 153 | 155 | 158 | 155 | 155 | 154 | 155 | 157 | 158 | 159 | 160 | 157 | 157 | 157 | 156 | 155 | 155 | 155 | 156 | 154 | 154 | 155 | 155 | 154 | 154 | 154 | 154 | 154 | 152 | 151 | 151 | 153 | 153 | 151 | 150 | 150 | 150 | 149 | 149 | . 275 143 | 144 | 145 | 145 | 145 | 144 | 143 | 143 | 148 | 147 | 145 | 143 | 142 | 142 | 142 | 142 | 143 | 144 | 143 | 142 | 142 | 144 | 143 | 141 | 147 | 145 | 144 | 146 | 148 | 148 | 147 | 146 | 145 | 146 | 147 | 148 | 147 | 147 | 146 | 146 | 150 | 150 | 151 | 154 | 156 | 156 | 157 | 159 | 164 | 157 | 159 | 163 | 166 | 171 | 168 | 157 | 160 | 153 | 150 | 154 | 155 | 153 | 154 | 157 | 157 | 156 | 155 | 156 | 157 | 159 | 160 | 160 | 156 | 158 | 159 | 159 | 158 | 156 | 154 | 154 | 154 | 154 | 154 | 154 | 154 | 154 | 155 | 155 | 152 | 151 | 150 | 152 | 155 | 156 | 154 | 152 | 151 | 151 | 151 | 150 | . 276 143 | 144 | 145 | 146 | 146 | 145 | 144 | 143 | 145 | 145 | 146 | 146 | 145 | 145 | 145 | 146 | 143 | 144 | 144 | 142 | 143 | 145 | 145 | 144 | 143 | 144 | 144 | 144 | 144 | 144 | 145 | 145 | 142 | 144 | 146 | 148 | 149 | 149 | 150 | 151 | 147 | 148 | 151 | 153 | 153 | 153 | 155 | 159 | 157 | 154 | 158 | 160 | 159 | 166 | 174 | 172 | 167 | 159 | 153 | 156 | 159 | 156 | 155 | 157 | 158 | 157 | 156 | 157 | 158 | 158 | 159 | 159 | 159 | 159 | 160 | 160 | 159 | 157 | 157 | 156 | 157 | 156 | 155 | 155 | 155 | 156 | 157 | 157 | 154 | 152 | 151 | 152 | 153 | 152 | 150 | 148 | 151 | 151 | 152 | 153 | . 277 144 | 145 | 146 | 147 | 147 | 146 | 146 | 145 | 143 | 145 | 147 | 148 | 146 | 144 | 141 | 140 | 142 | 144 | 144 | 143 | 144 | 146 | 147 | 146 | 140 | 143 | 144 | 143 | 140 | 141 | 142 | 144 | 140 | 142 | 144 | 146 | 146 | 146 | 147 | 149 | 145 | 146 | 149 | 151 | 150 | 150 | 152 | 156 | 156 | 158 | 160 | 159 | 156 | 159 | 166 | 168 | 170 | 164 | 160 | 161 | 162 | 160 | 158 | 158 | 157 | 156 | 156 | 157 | 158 | 158 | 158 | 157 | 162 | 162 | 161 | 159 | 159 | 159 | 160 | 162 | 158 | 156 | 155 | 155 | 155 | 155 | 155 | 155 | 157 | 156 | 155 | 155 | 155 | 154 | 153 | 152 | 153 | 152 | 151 | 151 | . 278 144 | 145 | 145 | 145 | 146 | 146 | 146 | 146 | 146 | 147 | 148 | 147 | 144 | 141 | 139 | 138 | 141 | 143 | 144 | 143 | 143 | 145 | 146 | 145 | 141 | 145 | 146 | 143 | 140 | 141 | 143 | 144 | 143 | 144 | 145 | 144 | 141 | 140 | 141 | 142 | 147 | 146 | 146 | 149 | 150 | 150 | 150 | 152 | 157 | 159 | 157 | 155 | 157 | 158 | 158 | 158 | 165 | 165 | 164 | 163 | 161 | 159 | 159 | 160 | 158 | 158 | 158 | 158 | 158 | 158 | 157 | 156 | 160 | 160 | 160 | 160 | 160 | 160 | 161 | 162 | 159 | 158 | 157 | 157 | 157 | 156 | 153 | 152 | 155 | 156 | 157 | 157 | 156 | 157 | 158 | 159 | 156 | 154 | 152 | 151 | . 279 143 | 143 | 143 | 143 | 144 | 145 | 146 | 146 | 149 | 149 | 148 | 146 | 144 | 144 | 146 | 148 | 140 | 142 | 143 | 143 | 143 | 144 | 145 | 144 | 143 | 146 | 146 | 143 | 141 | 143 | 144 | 144 | 146 | 146 | 147 | 145 | 142 | 140 | 141 | 142 | 151 | 147 | 145 | 148 | 151 | 151 | 150 | 149 | 148 | 155 | 154 | 152 | 157 | 158 | 157 | 163 | 158 | 163 | 166 | 163 | 159 | 157 | 159 | 160 | 162 | 161 | 160 | 159 | 159 | 158 | 157 | 156 | 154 | 157 | 160 | 162 | 162 | 160 | 159 | 158 | 164 | 163 | 163 | 162 | 162 | 159 | 155 | 152 | 152 | 153 | 154 | 153 | 151 | 151 | 153 | 155 | 159 | 158 | 157 | 156 | . 280 148 | 145 | 140 | 138 | 140 | 143 | 143 | 141 | 142 | 143 | 144 | 146 | 147 | 147 | 147 | 146 | 143 | 141 | 142 | 145 | 146 | 145 | 146 | 147 | 143 | 145 | 146 | 145 | 145 | 146 | 144 | 142 | 140 | 142 | 145 | 146 | 146 | 146 | 146 | 146 | 146 | 147 | 148 | 148 | 147 | 148 | 150 | 152 | 152 | 150 | 152 | 156 | 156 | 154 | 155 | 158 | 162 | 158 | 162 | 166 | 164 | 165 | 160 | 146 | 152 | 159 | 162 | 159 | 160 | 164 | 161 | 153 | 151 | 157 | 159 | 159 | 160 | 157 | 155 | 157 | 161 | 159 | 157 | 158 | 160 | 161 | 160 | 159 | 156 | 154 | 152 | 152 | 153 | 155 | 154 | 152 | 154 | 154 | 153 | 154 | . 281 144 | 144 | 142 | 139 | 138 | 141 | 143 | 144 | 141 | 143 | 144 | 145 | 146 | 146 | 147 | 148 | 147 | 145 | 145 | 146 | 147 | 145 | 146 | 147 | 143 | 144 | 145 | 144 | 144 | 146 | 145 | 144 | 140 | 141 | 142 | 142 | 144 | 145 | 147 | 148 | 144 | 146 | 149 | 149 | 148 | 147 | 147 | 148 | 145 | 146 | 148 | 150 | 152 | 152 | 154 | 156 | 159 | 158 | 162 | 163 | 160 | 165 | 171 | 168 | 145 | 147 | 151 | 155 | 158 | 158 | 158 | 158 | 160 | 158 | 153 | 152 | 158 | 161 | 161 | 162 | 158 | 158 | 158 | 159 | 161 | 161 | 161 | 161 | 161 | 159 | 156 | 154 | 153 | 153 | 154 | 154 | 155 | 153 | 152 | 152 | . 282 143 | 146 | 146 | 142 | 138 | 139 | 143 | 145 | 143 | 144 | 145 | 146 | 145 | 146 | 147 | 148 | 148 | 147 | 146 | 146 | 145 | 144 | 143 | 144 | 143 | 144 | 144 | 143 | 143 | 145 | 147 | 146 | 146 | 145 | 143 | 143 | 143 | 143 | 143 | 143 | 142 | 144 | 147 | 149 | 148 | 147 | 146 | 146 | 144 | 146 | 148 | 148 | 150 | 153 | 155 | 155 | 153 | 155 | 161 | 163 | 160 | 163 | 167 | 166 | 175 | 158 | 148 | 152 | 154 | 150 | 152 | 160 | 162 | 164 | 161 | 158 | 157 | 156 | 157 | 162 | 159 | 160 | 160 | 160 | 159 | 158 | 158 | 158 | 162 | 162 | 161 | 157 | 153 | 151 | 150 | 150 | 155 | 153 | 152 | 152 | . 283 148 | 150 | 150 | 146 | 142 | 141 | 142 | 142 | 143 | 145 | 147 | 147 | 145 | 145 | 145 | 147 | 146 | 146 | 147 | 146 | 145 | 144 | 143 | 143 | 144 | 144 | 143 | 142 | 142 | 145 | 147 | 147 | 149 | 148 | 147 | 147 | 146 | 144 | 141 | 139 | 141 | 143 | 145 | 147 | 147 | 147 | 147 | 148 | 147 | 151 | 151 | 149 | 149 | 153 | 154 | 153 | 151 | 153 | 157 | 161 | 162 | 161 | 158 | 154 | 167 | 171 | 159 | 137 | 132 | 147 | 154 | 148 | 154 | 159 | 162 | 163 | 162 | 158 | 156 | 160 | 159 | 160 | 161 | 159 | 157 | 156 | 156 | 157 | 158 | 159 | 160 | 160 | 158 | 155 | 152 | 151 | 152 | 152 | 153 | 153 | . 284 149 | 149 | 148 | 146 | 147 | 147 | 143 | 139 | 141 | 143 | 145 | 145 | 145 | 144 | 144 | 144 | 144 | 146 | 148 | 149 | 148 | 147 | 146 | 145 | 145 | 146 | 144 | 142 | 142 | 145 | 146 | 147 | 146 | 147 | 147 | 148 | 149 | 148 | 147 | 146 | 144 | 144 | 144 | 144 | 145 | 146 | 148 | 149 | 148 | 151 | 151 | 148 | 147 | 150 | 151 | 150 | 154 | 154 | 154 | 155 | 159 | 160 | 160 | 161 | 155 | 162 | 165 | 155 | 142 | 138 | 143 | 149 | 150 | 148 | 145 | 152 | 163 | 166 | 163 | 164 | 159 | 160 | 161 | 160 | 158 | 157 | 159 | 162 | 156 | 156 | 157 | 159 | 162 | 162 | 161 | 159 | 153 | 154 | 154 | 154 | . 285 147 | 146 | 144 | 145 | 148 | 149 | 146 | 141 | 139 | 139 | 141 | 142 | 143 | 144 | 143 | 143 | 140 | 144 | 147 | 148 | 147 | 147 | 146 | 145 | 146 | 147 | 145 | 143 | 143 | 145 | 146 | 146 | 146 | 147 | 146 | 146 | 146 | 148 | 150 | 152 | 148 | 146 | 145 | 143 | 143 | 145 | 147 | 148 | 147 | 148 | 149 | 148 | 148 | 149 | 150 | 150 | 150 | 155 | 156 | 156 | 157 | 156 | 158 | 166 | 164 | 156 | 161 | 173 | 168 | 151 | 148 | 161 | 159 | 152 | 144 | 143 | 151 | 155 | 159 | 166 | 163 | 164 | 164 | 163 | 160 | 159 | 160 | 161 | 163 | 160 | 157 | 157 | 159 | 160 | 160 | 158 | 158 | 159 | 158 | 156 | . 286 147 | 147 | 146 | 145 | 145 | 147 | 146 | 144 | 142 | 141 | 140 | 141 | 143 | 144 | 144 | 143 | 140 | 143 | 146 | 145 | 144 | 145 | 146 | 145 | 146 | 147 | 146 | 144 | 144 | 146 | 146 | 145 | 145 | 146 | 147 | 145 | 143 | 144 | 147 | 150 | 147 | 146 | 145 | 144 | 144 | 145 | 145 | 145 | 145 | 146 | 147 | 149 | 149 | 149 | 150 | 152 | 147 | 154 | 155 | 157 | 160 | 155 | 153 | 159 | 150 | 156 | 158 | 155 | 161 | 171 | 170 | 160 | 165 | 163 | 157 | 152 | 148 | 144 | 148 | 159 | 164 | 165 | 166 | 165 | 163 | 161 | 160 | 160 | 166 | 163 | 160 | 158 | 157 | 156 | 154 | 153 | 160 | 159 | 158 | 158 | . 287 150 | 152 | 152 | 147 | 142 | 142 | 144 | 146 | 149 | 145 | 142 | 141 | 143 | 145 | 145 | 143 | 142 | 146 | 147 | 145 | 144 | 145 | 147 | 147 | 146 | 147 | 147 | 145 | 145 | 147 | 147 | 145 | 140 | 143 | 146 | 146 | 143 | 143 | 145 | 148 | 144 | 144 | 145 | 145 | 146 | 145 | 144 | 144 | 144 | 142 | 144 | 148 | 149 | 147 | 147 | 151 | 150 | 152 | 149 | 152 | 160 | 158 | 153 | 157 | 152 | 153 | 159 | 162 | 158 | 152 | 155 | 163 | 161 | 162 | 161 | 162 | 161 | 152 | 147 | 150 | 157 | 159 | 162 | 164 | 165 | 164 | 163 | 163 | 161 | 162 | 164 | 163 | 161 | 158 | 156 | 155 | 156 | 154 | 154 | 157 | . 288 144 | 147 | 151 | 151 | 147 | 143 | 145 | 150 | 144 | 148 | 148 | 144 | 142 | 144 | 144 | 142 | 144 | 144 | 144 | 143 | 143 | 145 | 145 | 144 | 146 | 148 | 147 | 144 | 143 | 147 | 148 | 147 | 144 | 147 | 147 | 145 | 146 | 148 | 147 | 144 | 145 | 144 | 143 | 140 | 137 | 140 | 144 | 141 | 142 | 144 | 146 | 146 | 146 | 146 | 147 | 149 | 148 | 149 | 149 | 149 | 150 | 154 | 156 | 156 | 158 | 152 | 148 | 151 | 155 | 156 | 155 | 155 | 163 | 159 | 155 | 157 | 163 | 165 | 159 | 151 | 149 | 158 | 161 | 161 | 164 | 165 | 164 | 164 | 161 | 164 | 162 | 158 | 159 | 164 | 165 | 161 | 159 | 157 | 156 | 157 | . 289 148 | 141 | 136 | 140 | 147 | 150 | 148 | 146 | 146 | 150 | 151 | 145 | 140 | 141 | 144 | 144 | 143 | 145 | 144 | 142 | 141 | 143 | 144 | 143 | 141 | 143 | 145 | 144 | 144 | 145 | 145 | 144 | 146 | 146 | 144 | 142 | 143 | 145 | 146 | 145 | 144 | 144 | 146 | 145 | 141 | 142 | 143 | 140 | 143 | 144 | 145 | 145 | 145 | 146 | 148 | 150 | 148 | 149 | 148 | 147 | 148 | 151 | 152 | 152 | 155 | 160 | 156 | 143 | 138 | 147 | 156 | 156 | 154 | 157 | 159 | 158 | 157 | 160 | 163 | 165 | 169 | 159 | 149 | 153 | 162 | 162 | 160 | 163 | 165 | 163 | 165 | 169 | 166 | 158 | 159 | 166 | 165 | 162 | 159 | 158 | . 290 173 | 165 | 155 | 148 | 145 | 145 | 146 | 148 | 140 | 144 | 147 | 148 | 149 | 150 | 146 | 140 | 146 | 147 | 147 | 144 | 143 | 143 | 144 | 144 | 143 | 143 | 144 | 145 | 145 | 143 | 142 | 143 | 145 | 144 | 145 | 148 | 148 | 147 | 147 | 147 | 145 | 145 | 147 | 147 | 144 | 144 | 145 | 141 | 142 | 142 | 142 | 142 | 143 | 144 | 145 | 146 | 148 | 149 | 148 | 147 | 147 | 149 | 150 | 149 | 150 | 155 | 157 | 152 | 144 | 141 | 145 | 150 | 152 | 155 | 156 | 155 | 155 | 157 | 160 | 161 | 154 | 163 | 163 | 158 | 159 | 160 | 158 | 156 | 161 | 164 | 165 | 164 | 162 | 162 | 163 | 164 | 165 | 162 | 159 | 159 | . 291 174 | 174 | 171 | 161 | 149 | 142 | 143 | 147 | 151 | 150 | 148 | 145 | 145 | 146 | 146 | 143 | 146 | 148 | 149 | 146 | 144 | 143 | 144 | 143 | 147 | 144 | 143 | 145 | 146 | 145 | 145 | 148 | 143 | 142 | 143 | 146 | 146 | 142 | 142 | 144 | 146 | 145 | 147 | 147 | 144 | 145 | 148 | 146 | 142 | 141 | 141 | 142 | 142 | 142 | 142 | 141 | 148 | 149 | 150 | 149 | 149 | 150 | 149 | 148 | 146 | 147 | 152 | 159 | 158 | 149 | 141 | 139 | 148 | 150 | 152 | 153 | 154 | 156 | 155 | 154 | 160 | 151 | 150 | 164 | 171 | 159 | 152 | 159 | 159 | 158 | 154 | 151 | 156 | 165 | 166 | 162 | 164 | 160 | 158 | 160 | . 292 168 | 170 | 173 | 173 | 169 | 160 | 148 | 140 | 142 | 146 | 149 | 149 | 147 | 147 | 148 | 150 | 144 | 146 | 147 | 145 | 143 | 142 | 142 | 140 | 145 | 142 | 142 | 145 | 147 | 146 | 147 | 149 | 150 | 146 | 144 | 145 | 143 | 141 | 143 | 148 | 146 | 144 | 147 | 148 | 145 | 145 | 147 | 145 | 141 | 142 | 143 | 144 | 144 | 144 | 143 | 143 | 145 | 148 | 150 | 150 | 150 | 150 | 149 | 147 | 145 | 150 | 151 | 149 | 154 | 159 | 153 | 141 | 139 | 146 | 151 | 151 | 149 | 151 | 155 | 157 | 158 | 161 | 155 | 147 | 151 | 161 | 164 | 163 | 165 | 153 | 147 | 153 | 158 | 157 | 158 | 163 | 167 | 164 | 161 | 162 | . 293 168 | 170 | 173 | 176 | 178 | 176 | 169 | 161 | 147 | 144 | 142 | 144 | 149 | 152 | 150 | 146 | 145 | 146 | 146 | 144 | 144 | 144 | 143 | 141 | 146 | 144 | 144 | 146 | 146 | 144 | 140 | 139 | 142 | 143 | 146 | 148 | 148 | 147 | 147 | 149 | 145 | 144 | 148 | 151 | 147 | 145 | 144 | 142 | 139 | 141 | 144 | 144 | 144 | 143 | 144 | 144 | 143 | 145 | 147 | 148 | 149 | 150 | 149 | 147 | 147 | 148 | 148 | 148 | 151 | 156 | 156 | 153 | 144 | 144 | 143 | 142 | 144 | 149 | 151 | 152 | 154 | 154 | 155 | 157 | 154 | 147 | 153 | 169 | 163 | 159 | 158 | 159 | 158 | 154 | 154 | 158 | 166 | 163 | 162 | 164 | . 294 156 | 160 | 162 | 163 | 167 | 174 | 180 | 183 | 181 | 167 | 151 | 143 | 144 | 146 | 146 | 143 | 148 | 147 | 145 | 143 | 144 | 147 | 147 | 145 | 148 | 148 | 147 | 146 | 145 | 144 | 140 | 135 | 132 | 137 | 141 | 143 | 143 | 143 | 144 | 143 | 145 | 143 | 147 | 151 | 148 | 145 | 145 | 143 | 139 | 142 | 144 | 143 | 141 | 140 | 142 | 145 | 143 | 145 | 145 | 145 | 146 | 148 | 149 | 148 | 148 | 145 | 146 | 152 | 153 | 150 | 152 | 157 | 154 | 148 | 141 | 139 | 144 | 149 | 147 | 142 | 143 | 151 | 152 | 149 | 156 | 163 | 156 | 146 | 157 | 162 | 163 | 160 | 158 | 158 | 157 | 154 | 160 | 159 | 159 | 161 | . 295 158 | 159 | 159 | 158 | 160 | 165 | 169 | 170 | 173 | 177 | 179 | 173 | 161 | 150 | 147 | 148 | 149 | 147 | 142 | 140 | 142 | 147 | 148 | 146 | 146 | 147 | 146 | 144 | 146 | 149 | 148 | 144 | 148 | 149 | 145 | 138 | 136 | 140 | 145 | 146 | 145 | 142 | 145 | 148 | 146 | 145 | 148 | 148 | 143 | 146 | 147 | 144 | 140 | 138 | 142 | 145 | 145 | 145 | 145 | 144 | 145 | 148 | 150 | 149 | 147 | 150 | 149 | 145 | 146 | 152 | 154 | 150 | 154 | 154 | 152 | 148 | 147 | 147 | 148 | 147 | 142 | 147 | 146 | 143 | 148 | 153 | 156 | 159 | 158 | 151 | 152 | 161 | 164 | 159 | 157 | 161 | 157 | 156 | 157 | 158 | . 296 154 | 156 | 156 | 156 | 155 | 156 | 158 | 161 | 164 | 166 | 169 | 174 | 179 | 179 | 171 | 162 | 147 | 148 | 150 | 149 | 144 | 140 | 143 | 148 | 146 | 145 | 145 | 147 | 147 | 146 | 143 | 141 | 147 | 146 | 145 | 145 | 143 | 140 | 134 | 129 | 140 | 143 | 146 | 146 | 144 | 144 | 147 | 150 | 143 | 144 | 143 | 141 | 139 | 139 | 137 | 135 | 140 | 145 | 147 | 142 | 139 | 142 | 147 | 149 | 144 | 147 | 150 | 150 | 149 | 148 | 149 | 151 | 149 | 153 | 154 | 152 | 149 | 148 | 147 | 146 | 144 | 144 | 146 | 148 | 148 | 146 | 147 | 150 | 169 | 159 | 149 | 148 | 154 | 161 | 161 | 159 | 161 | 159 | 160 | 163 | . 297 155 | 157 | 158 | 157 | 156 | 157 | 159 | 161 | 164 | 164 | 163 | 164 | 169 | 175 | 178 | 178 | 164 | 152 | 142 | 142 | 148 | 151 | 147 | 143 | 146 | 148 | 146 | 141 | 141 | 145 | 147 | 146 | 146 | 145 | 145 | 146 | 147 | 146 | 145 | 143 | 135 | 138 | 140 | 141 | 142 | 145 | 149 | 153 | 146 | 145 | 142 | 138 | 137 | 139 | 141 | 141 | 144 | 141 | 140 | 141 | 144 | 145 | 145 | 144 | 144 | 145 | 147 | 147 | 147 | 146 | 146 | 147 | 150 | 150 | 149 | 149 | 152 | 154 | 152 | 147 | 146 | 145 | 145 | 147 | 146 | 145 | 147 | 150 | 146 | 152 | 156 | 155 | 151 | 150 | 154 | 158 | 157 | 162 | 163 | 160 | . 298 161 | 162 | 162 | 162 | 161 | 161 | 163 | 164 | 162 | 163 | 163 | 161 | 160 | 163 | 166 | 167 | 180 | 177 | 171 | 160 | 148 | 141 | 144 | 150 | 142 | 143 | 143 | 142 | 140 | 140 | 143 | 146 | 148 | 148 | 147 | 147 | 147 | 147 | 147 | 148 | 141 | 141 | 141 | 141 | 141 | 143 | 146 | 148 | 147 | 146 | 142 | 138 | 137 | 139 | 142 | 142 | 147 | 140 | 138 | 143 | 147 | 145 | 142 | 141 | 145 | 145 | 146 | 146 | 146 | 146 | 146 | 146 | 148 | 148 | 147 | 148 | 152 | 155 | 154 | 151 | 148 | 147 | 147 | 147 | 147 | 147 | 150 | 154 | 145 | 149 | 155 | 157 | 156 | 155 | 155 | 156 | 154 | 158 | 159 | 156 | . 299 157 | 158 | 158 | 158 | 157 | 156 | 157 | 158 | 157 | 161 | 163 | 163 | 162 | 164 | 165 | 165 | 157 | 162 | 168 | 171 | 167 | 158 | 150 | 145 | 137 | 139 | 145 | 149 | 142 | 131 | 133 | 142 | 145 | 146 | 146 | 145 | 144 | 144 | 144 | 144 | 149 | 147 | 145 | 144 | 143 | 143 | 144 | 144 | 147 | 148 | 147 | 144 | 143 | 143 | 142 | 140 | 143 | 143 | 144 | 146 | 144 | 141 | 140 | 141 | 144 | 144 | 144 | 145 | 146 | 147 | 147 | 147 | 145 | 148 | 150 | 149 | 147 | 148 | 151 | 154 | 151 | 151 | 150 | 149 | 148 | 148 | 150 | 152 | 156 | 152 | 150 | 153 | 159 | 163 | 161 | 158 | 155 | 151 | 150 | 155 | . - 결국 이 이미지는 683 $ times$ 1024 개의 숫자의 모임 . - 이 이미지를 벡터로 만든다음 히스토그램을 그려보자. . img.flatten().shape . (699392,) . fig1=plt.hist(img.flatten(),256,[0,256]) . - 히스토그램을 그려보니 120~200 사이에 너무 값들이 모여있음 . - 원래 0~255까지의 색을 표현할 수 있는데 컴퓨터가 표현가능한 색상보다 적은 조합만을 사용하고 있음. . - 아이디어: 좀 더 많은 색상을 표현할 수 없을까? $ to$ 위의 히스토그램은 좀 평평하게 만들면 되지 않을까? . img2=cv.equalizeHist(img) . fig2_1=plt.hist(img2.flatten(),256,[0,256]) . fig2_2=plt.hist(img2.flatten(),10,[0,256]) . plt.imshow(img2,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x7f9bd9321580&gt; . - 변환전과 변환후를 나란히 보게 되면? . import numpy as np . _img=np.hstack((img,img2)) . plt.imshow(_img,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f9bd92efa60&gt; . &#49689;&#51228; . - 아래 이미지를 HE(histogram equalization)로 보정하고 스샷제출 . ref: https://ukdevguy.com/histogram-equalization-in-python/ | . hw_img=cv.imread(&#39;hw_img.png&#39;,0) plt.imshow(hw_img,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x7f9bd9249e20&gt; . - 이미지는 https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/hw_img.png 에서 다운받을 수 있다. .",
            "url": "https://minji219.github.io/zw/2021/09/08/(2%EC%A3%BC%EC%B0%A8)-9%EC%9B%948%EC%9D%BC.html",
            "relUrl": "/2021/09/08/(2%EC%A3%BC%EC%B0%A8)-9%EC%9B%948%EC%9D%BC.html",
            "date": " • Sep 8, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "(1주차) 9월6일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/6): 박스플랏: 전북고예제 (평균은 좋은 측정값인가?) . - (2/6): 박스플랏 기본개념 . - (3/6): plotly . - (4/6): 히스토그램 . - (5/6): 히스토그램 2개 겹쳐서 비교하기 . - (6/6): 과제안내 . import . import matplotlib.pyplot as plt import numpy as np . boxplot . &#51204;&#48513;&#44256;&#50696;&#51228;: &#54217;&#44512;&#51008; &#44316;&#52270;&#51008; &#52769;&#51221;&#44050;&#51064;&#44032;? . - 전북고등학교에서 통계학을 수업하는 두 선생님이 있다. 편의상 A선생님과 B선생님이라고 하자. A선생님이 강의한 반의 통계학 점수는 79.1점이고, B선생님이 강의한 반의 통계학 점수는 78.3점 이라고 하자. . - 의사결정: A선생님에게 배운 학생들의 실력이 평균적으로 좋을 것이다. . y1=[75,75,76,76,77,77,79,79,79,98] # A선생님에게 통계학을 배운 학생의 점수들 y2=[76,76,77,77,78,78,80,80,80,81] # B선생님에게 통계학을 배운 학생의 점수들 . np.mean(y1), np.mean(y2) . (79.1, 78.3) . - 평균은 A반(=A선생님에게 통계학을 배운 반)이 더 높다. 그런데 98점을 받은 학생때문에 전체평균이 올라간 것이고, 나머지 학생들은 전체적으로 B반 학생들이 점수가 더 높다고 해석할 수 있다. . - 단순한 평균비교보다 분포를 비교해보는 것이 중요하다. 분포를 살펴보는 방법 중 유용한 방법이 박스플랏이다. . plt.boxplot(y1) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc9291b5040&gt;, &lt;matplotlib.lines.Line2D at 0x7fc9291b53d0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc9291b5760&gt;, &lt;matplotlib.lines.Line2D at 0x7fc9291b5af0&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc92b216c70&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc9291b5eb0&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc9291bf280&gt;], &#39;means&#39;: []} . A반의 boxplot | 뚝 떨어진 하나의 점은 98점 | 붉은 선은 중앙값 (평균이 아니라 중앙값) | 나머지 점들은 7~80점에 분포되어있다. | . plt.boxplot(y2) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc92911b550&gt;, &lt;matplotlib.lines.Line2D at 0x7fc92911b8e0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc92911bca0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc929127070&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc92911b1c0&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc929127400&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc929127790&gt;], &#39;means&#39;: []} . B반의 boxplot | . - 아래와 같이 하면 박스플랏을 나란히 그릴 수 있다. . plt.boxplot([y1,y2]) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc929089550&gt;, &lt;matplotlib.lines.Line2D at 0x7fc9290898e0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc929095e80&gt;, &lt;matplotlib.lines.Line2D at 0x7fc92909e250&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc929089c70&gt;, &lt;matplotlib.lines.Line2D at 0x7fc929095040&gt;, &lt;matplotlib.lines.Line2D at 0x7fc92909e5e0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc92909e970&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc9290891c0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc929095af0&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc9290953d0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc92909ed00&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc929095760&gt;, &lt;matplotlib.lines.Line2D at 0x7fc9290ac0d0&gt;], &#39;means&#39;: []} . - 미적인 그래프는 아니지만 이정도는 괜찮은것 같다. . boxplot&#51060;&#46976;? . - ref: https://github.com/mGalarnyk/Python_Tutorials/blob/master/Statistics/boxplot/box_plot.ipynb . np.random.seed(916170) # connection path is here: https://stackoverflow.com/questions/6146290/plotting-a-line-over-several-graphs mu, sigma = 0, 1 # mean and standard deviation s = np.random.normal(mu, sigma, 1000) fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(10, 5)) # rectangular box plot bplot = axes.boxplot(s, vert=False, patch_artist=True, showfliers=True, # This would show outliers (the remaining .7% of the data) positions = [0], boxprops = dict(linestyle=&#39;--&#39;, linewidth=2, color=&#39;Black&#39;, facecolor = &#39;red&#39;, alpha = .4), medianprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Yellow&#39;), whiskerprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Blue&#39;, alpha = .4), capprops = dict(linestyle=&#39;-&#39;, linewidth=2, color=&#39;Black&#39;), flierprops = dict(marker=&#39;o&#39;, markerfacecolor=&#39;green&#39;, markersize=10, linestyle=&#39;none&#39;, alpha = .4), widths = .3, zorder = 1) axes.set_xlim(-4, 4) plt.xticks(fontsize = 14) axes.set_yticks([]) axes.annotate(r&#39;&#39;, xy=(-.73, .205), xycoords=&#39;data&#39;, xytext=(.66, .205), textcoords=&#39;data&#39;, arrowprops=dict(arrowstyle=&quot;|-|&quot;, connectionstyle=&quot;arc3&quot;) ); axes.text(0, .25, &quot;Interquartile Range n(IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=18) axes.text(0, -.21, r&quot;Median&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(2.65, -.15, &quot; &quot;Maximum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.15, &quot; &quot;Minimum &quot;&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-.68, -.24, r&quot;Q1&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(-2.65, -.21, r&quot;(Q1 - 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.text(.6745, -.24, r&quot;Q3&quot;, horizontalalignment=&#39;center&#39;, fontsize=18); axes.text(.6745, -.30, r&quot;(75th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(-.68, -.30, r&quot;(25th Percentile)&quot;, horizontalalignment=&#39;center&#39;, fontsize=12); axes.text(2.65, -.21, r&quot;(Q3 + 1.5*IQR)&quot;, horizontalalignment=&#39;center&#39;, fontsize=16); axes.annotate(&#39;Outliers&#39;, xy=(2.93,0.015), xytext=(2.52,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); axes.annotate(&#39;Outliers&#39;, xy=(-3.01,0.015), xytext=(-3.41,0.20), fontsize = 18, arrowprops={&#39;arrowstyle&#39;: &#39;-&gt;&#39;, &#39;color&#39;: &#39;black&#39;, &#39;lw&#39;: 2}, va=&#39;center&#39;); fig.tight_layout() . . plotly . !pip install plotly !pip install ipywidgets !pip install jupyter-dash !pip install dash !pip install pandas . import plotly.express as px import pandas as pd from IPython.display import HTML . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) . df=pd.concat([A,B],ignore_index=True) . df . score class . 0 75 | A | . 1 75 | A | . 2 76 | A | . 3 76 | A | . 4 77 | A | . 5 77 | A | . 6 79 | A | . 7 79 | A | . 8 79 | A | . 9 98 | A | . 10 76 | B | . 11 76 | B | . 12 77 | B | . 13 77 | B | . 14 78 | B | . 15 78 | B | . 16 80 | B | . 17 80 | B | . 18 80 | B | . 19 81 | B | . fig=px.box(data_frame=df, x=&#39;class&#39;,y=&#39;score&#39;) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . histogram . &#55176;&#49828;&#53664;&#44536;&#47016;&#51060;&#46976;? . - X축이 변수의 구간, Y축은 그 구간에 포함된 빈도를 의미하는 그림 . - 예를들면 아래와 같음 . plt.hist(np.random.normal(loc=0, scale=1, size=1000000)) . (array([2.40000e+01, 1.21000e+03, 2.13380e+04, 1.39948e+05, 3.51614e+05, 3.39662e+05, 1.27147e+05, 1.80510e+04, 9.87000e+02, 1.90000e+01]), array([-5.05590169, -4.03792348, -3.01994528, -2.00196708, -0.98398887, 0.03398933, 1.05196753, 2.06994573, 3.08792394, 4.10590214, 5.12388034]), &lt;BarContainer object of 10 artists&gt;) . &#51204;&#48513;&#44256;&#50696;&#51228; . - 중심경향값, 집중경향치 (Measure of central tendency): 분포의 중심성을 나타내기 위한 값, 예시로는 평균, 중앙값. . https://en.wikipedia.org/wiki/Central_tendency | . - &#39;평균이 항상 좋은 중심경향값은 아니다.&#39;라는 사실은 이해했음. . - 하지만 특수한 상황을 가정하면 평균이 좋은 중심경향값임 . np.random.seed(43052) y1=np.random.normal(loc=0,scale=1,size=10000) #전북고 A반의 통계학 성적이라 생각하자. y2=np.random.normal(loc=0.5,scale=1,size=10000) #전북고 B반의 통계학 성적이라 생각하자. . np.mean(y1), np.mean(y2) . (-0.011790879905079434, 0.4979147460611458) . (np.mean(y2)-np.mean(y1)).round(3) . 0.51 . plt.boxplot([y1,y2]) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc92668e9d0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc92668ed90&gt;, &lt;matplotlib.lines.Line2D at 0x7fc926627370&gt;, &lt;matplotlib.lines.Line2D at 0x7fc926627700&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc92661c160&gt;, &lt;matplotlib.lines.Line2D at 0x7fc92661c4f0&gt;, &lt;matplotlib.lines.Line2D at 0x7fc926627a90&gt;, &lt;matplotlib.lines.Line2D at 0x7fc926627e20&gt;], &#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc92668e640&gt;, &lt;matplotlib.lines.Line2D at 0x7fc92661cfa0&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc92661c880&gt;, &lt;matplotlib.lines.Line2D at 0x7fc9266351f0&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fc92661cc10&gt;, &lt;matplotlib.lines.Line2D at 0x7fc926635580&gt;], &#39;means&#39;: []} . 분포의 모양이 거의 비슷하고, 왼쪽그림을 거의 컨트롤+C,V 오른쪽에 붙인다음 위치조정을 한 느낌 | 이런상황에서는 $B반의 성적 approx A반의 성적 + 0.51$ 라고 주장해도 큰 무리가 없음. | . - 정규분포인것은 어떻게 아는가? $ to$ 히스토그램을 그려보아서 종 모양이 나오는지 살펴보자. . plt.hist(y1,bins=50) . (array([ 1., 1., 3., 0., 1., 4., 5., 12., 14., 26., 32., 52., 67., 89., 144., 171., 238., 282., 325., 378., 489., 492., 561., 635., 652., 636., 626., 606., 573., 539., 475., 444., 350., 250., 232., 172., 137., 80., 58., 47., 30., 23., 17., 12., 9., 4., 4., 0., 1., 1.]), array([-4.12186916, -3.96068404, -3.79949892, -3.6383138 , -3.47712868, -3.31594356, -3.15475844, -2.99357332, -2.8323882 , -2.67120308, -2.51001796, -2.34883284, -2.18764772, -2.0264626 , -1.86527748, -1.70409236, -1.54290724, -1.38172212, -1.220537 , -1.05935188, -0.89816676, -0.73698164, -0.57579652, -0.4146114 , -0.25342628, -0.09224116, 0.06894396, 0.23012908, 0.3913142 , 0.55249932, 0.71368444, 0.87486956, 1.03605468, 1.1972398 , 1.35842492, 1.51961004, 1.68079516, 1.84198028, 2.0031654 , 2.16435052, 2.32553564, 2.48672076, 2.64790588, 2.809091 , 2.97027612, 3.13146124, 3.29264636, 3.45383148, 3.6150166 , 3.77620172, 3.93738684]), &lt;BarContainer object of 50 artists&gt;) . plt.hist(y2,bins=50) . (array([ 1., 0., 3., 2., 4., 5., 5., 10., 16., 25., 33., 56., 74., 116., 119., 152., 244., 272., 351., 362., 438., 509., 531., 621., 624., 690., 636., 571., 564., 514., 462., 402., 356., 297., 233., 184., 144., 113., 80., 55., 38., 34., 21., 18., 4., 3., 2., 4., 1., 1.]), array([-3.5752867 , -3.4164866 , -3.2576865 , -3.0988864 , -2.9400863 , -2.7812862 , -2.6224861 , -2.463686 , -2.3048859 , -2.1460858 , -1.9872857 , -1.8284856 , -1.6696855 , -1.5108854 , -1.3520853 , -1.1932852 , -1.0344851 , -0.875685 , -0.7168849 , -0.5580848 , -0.3992847 , -0.2404846 , -0.0816845 , 0.0771156 , 0.2359157 , 0.3947158 , 0.5535159 , 0.712316 , 0.87111611, 1.02991621, 1.18871631, 1.34751641, 1.50631651, 1.66511661, 1.82391671, 1.98271681, 2.14151691, 2.30031701, 2.45911711, 2.61791721, 2.77671731, 2.93551741, 3.09431751, 3.25311761, 3.41191771, 3.57071781, 3.72951791, 3.88831801, 4.04711811, 4.20591821, 4.36471831]), &lt;BarContainer object of 50 artists&gt;) . plt.hist([y1,y2],bins=200) . (array([[ 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 2., 1., 0., 1., 1., 3., 4., 4., 2., 2., 6., 4., 1., 4., 7., 8., 9., 11., 5., 9., 9., 14., 12., 16., 11., 9., 18., 25., 30., 22., 18., 28., 29., 39., 40., 41., 37., 42., 48., 56., 58., 49., 80., 62., 62., 91., 78., 75., 82., 89., 81., 106., 85., 89., 126., 125., 106., 142., 141., 121., 121., 135., 154., 166., 146., 125., 169., 160., 170., 172., 162., 161., 161., 193., 146., 186., 170., 166., 197., 152., 149., 167., 173., 158., 155., 156., 153., 152., 137., 151., 147., 126., 141., 125., 139., 117., 116., 135., 118., 93., 115., 99., 78., 91., 77., 63., 81., 52., 83., 53., 61., 49., 46., 46., 47., 45., 26., 48., 31., 27., 27., 20., 17., 22., 15., 15., 14., 14., 15., 10., 8., 13., 7., 5., 8., 6., 6., 6., 2., 4., 9., 3., 3., 6., 2., 1., 4., 2., 2., 2., 2., 0., 1., 1., 2., 2., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 3., 1., 2., 1., 1., 1., 2., 1., 2., 2., 1., 6., 1., 6., 3., 7., 7., 5., 6., 10., 5., 7., 16., 9., 11., 13., 28., 21., 16., 20., 27., 25., 32., 33., 28., 31., 31., 39., 42., 34., 43., 44., 64., 56., 80., 64., 74., 77., 69., 82., 92., 101., 99., 81., 90., 115., 110., 106., 108., 127., 127., 138., 145., 138., 121., 159., 135., 145., 156., 186., 158., 164., 172., 182., 147., 194., 178., 176., 195., 162., 182., 164., 164., 163., 145., 150., 143., 155., 144., 142., 161., 141., 146., 129., 115., 132., 120., 118., 128., 103., 88., 111., 104., 97., 82., 77., 83., 83., 80., 77., 67., 58., 48., 47., 54., 50., 43., 36., 43., 33., 33., 42., 29., 24., 28., 19., 22., 16., 18., 14., 14., 11., 10., 9., 7., 12., 10., 8., 8., 9., 4., 7., 4., 6., 3., 8., 1., 1., 1., 0., 1., 0., 2., 1., 0., 2., 0., 0., 2., 2., 0., 0., 0., 0., 1., 0., 0., 0., 1.]]), array([-4.12186916, -4.07943623, -4.03700329, -3.99457035, -3.95213741, -3.90970448, -3.86727154, -3.8248386 , -3.78240567, -3.73997273, -3.69753979, -3.65510685, -3.61267392, -3.57024098, -3.52780804, -3.4853751 , -3.44294217, -3.40050923, -3.35807629, -3.31564335, -3.27321042, -3.23077748, -3.18834454, -3.1459116 , -3.10347867, -3.06104573, -3.01861279, -2.97617986, -2.93374692, -2.89131398, -2.84888104, -2.80644811, -2.76401517, -2.72158223, -2.67914929, -2.63671636, -2.59428342, -2.55185048, -2.50941754, -2.46698461, -2.42455167, -2.38211873, -2.33968579, -2.29725286, -2.25481992, -2.21238698, -2.16995405, -2.12752111, -2.08508817, -2.04265523, -2.0002223 , -1.95778936, -1.91535642, -1.87292348, -1.83049055, -1.78805761, -1.74562467, -1.70319173, -1.6607588 , -1.61832586, -1.57589292, -1.53345998, -1.49102705, -1.44859411, -1.40616117, -1.36372824, -1.3212953 , -1.27886236, -1.23642942, -1.19399649, -1.15156355, -1.10913061, -1.06669767, -1.02426474, -0.9818318 , -0.93939886, -0.89696592, -0.85453299, -0.81210005, -0.76966711, -0.72723417, -0.68480124, -0.6423683 , -0.59993536, -0.55750243, -0.51506949, -0.47263655, -0.43020361, -0.38777068, -0.34533774, -0.3029048 , -0.26047186, -0.21803893, -0.17560599, -0.13317305, -0.09074011, -0.04830718, -0.00587424, 0.0365587 , 0.07899164, 0.12142457, 0.16385751, 0.20629045, 0.24872338, 0.29115632, 0.33358926, 0.3760222 , 0.41845513, 0.46088807, 0.50332101, 0.54575395, 0.58818688, 0.63061982, 0.67305276, 0.7154857 , 0.75791863, 0.80035157, 0.84278451, 0.88521744, 0.92765038, 0.97008332, 1.01251626, 1.05494919, 1.09738213, 1.13981507, 1.18224801, 1.22468094, 1.26711388, 1.30954682, 1.35197976, 1.39441269, 1.43684563, 1.47927857, 1.52171151, 1.56414444, 1.60657738, 1.64901032, 1.69144325, 1.73387619, 1.77630913, 1.81874207, 1.861175 , 1.90360794, 1.94604088, 1.98847382, 2.03090675, 2.07333969, 2.11577263, 2.15820557, 2.2006385 , 2.24307144, 2.28550438, 2.32793732, 2.37037025, 2.41280319, 2.45523613, 2.49766906, 2.540102 , 2.58253494, 2.62496788, 2.66740081, 2.70983375, 2.75226669, 2.79469963, 2.83713256, 2.8795655 , 2.92199844, 2.96443138, 3.00686431, 3.04929725, 3.09173019, 3.13416313, 3.17659606, 3.219029 , 3.26146194, 3.30389487, 3.34632781, 3.38876075, 3.43119369, 3.47362662, 3.51605956, 3.5584925 , 3.60092544, 3.64335837, 3.68579131, 3.72822425, 3.77065719, 3.81309012, 3.85552306, 3.897956 , 3.94038894, 3.98282187, 4.02525481, 4.06768775, 4.11012068, 4.15255362, 4.19498656, 4.2374195 , 4.27985243, 4.32228537, 4.36471831]), &lt;a list of 2 BarContainer objects&gt;) . seaborn . import seaborn as sns . A=pd.DataFrame({&#39;score&#39;:y1,&#39;class&#39;:[&#39;A&#39;]*len(y1)}) B=pd.DataFrame({&#39;score&#39;:y2,&#39;class&#39;:[&#39;B&#39;]*len(y2)}) df=pd.concat([A,B],ignore_index=True) . sns.histplot(df,x=&#39;score&#39;,hue=&#39;class&#39;) . &lt;AxesSubplot:xlabel=&#39;score&#39;, ylabel=&#39;Count&#39;&gt; . plotnine . from plotnine import * . ggplot(df)+geom_histogram(aes(x=&#39;score&#39;,fill=&#39;class&#39;),position=&#39;identity&#39;,alpha=0.5) . /home/cgb3/anaconda3/envs/dv2021/lib/python3.8/site-packages/plotnine/stats/stat_bin.py:95: PlotnineWarning: &#39;stat_bin()&#39; using &#39;bins = 84&#39;. Pick better value with &#39;binwidth&#39;. . &lt;ggplot: (8781336505688)&gt; . plotly . - 인터랙티브 그래프를 위해서 plotly 홈페이지를 방문하여 적당한 코드를 가져온다. . import plotly.figure_factory as ff import numpy as np . hist_data=[y1,y2] group_labels=[&#39;A&#39;,&#39;B&#39;] fig = ff.create_distplot(hist_data, group_labels, bin_size=.2, show_rug=False) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False)) . . . &#49689;&#51228; . (1) 자기학번으로 np.random.seed(202043052)를 만들고 . (2) y1, y2 // 10만개의 정규분포를 생성해서 저장 . y1: 평균 0, 표준편차=1 | y2: 평균 1, 표준편차=1 | . (3) plotly 를 활용하여 히스토그램을 겹쳐서 그려보는것. .",
            "url": "https://minji219.github.io/zw/2021/09/06/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%946%EC%9D%BC.html",
            "relUrl": "/2021/09/06/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%946%EC%9D%BC.html",
            "date": " • Sep 6, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "(1주차) 9월1일",
            "content": "&#44053;&#51032;&#50689;&#49345; . . - (1/4): 데이터 시각화 과목에 대한 소개 . - (2/4): 강의안내 (강의계획서, 출석인정 방법, 과제안내, 질문하는 방법 등) . - (3/4): 윈도우에서 주피터랩 설치하는 방법 &lt;- 파이썬입문(2021) 수강하셨던 학생은 안들으셔도 될것 같아요. . - (4/4): 주피터랩 최초접속시 토큰설정하는 방법, 과제안내 &lt;- 파이썬입문(2021) 수강하셨던 학생은 안들으셔도 될것 같아요. (과제안내만 들으시면 될것같습니다) . &#47112;&#54252;&#53944; . - 카카오톡 스샷제출 .",
            "url": "https://minji219.github.io/zw/2021/09/01/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%941%EC%9D%BC.html",
            "relUrl": "/2021/09/01/(1%EC%A3%BC%EC%B0%A8)-9%EC%9B%941%EC%9D%BC.html",
            "date": " • Sep 1, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "(A1) 깃허브와 fastpages를 이용하여 블로그 개설하기",
            "content": "About this doc . - 본 포스트는 2021년 1학기 Python 입문 강의내용중 일부를 업로드 하였음. . - Github, fastpages를 사용하여 블로그를 개설하고 관리하는 방법에 대한 설명임. . .",
            "url": "https://minji219.github.io/zw/2021/08/17/(A1)-%EA%B9%83%ED%97%88%EB%B8%8C%EC%99%80-fastpages%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B0%9C%EC%84%A4%ED%95%98%EA%B8%B0.html",
            "relUrl": "/2021/08/17/(A1)-%EA%B9%83%ED%97%88%EB%B8%8C%EC%99%80-fastpages%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EA%B0%9C%EC%84%A4%ED%95%98%EA%B8%B0.html",
            "date": " • Aug 17, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://minji219.github.io/zw/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://minji219.github.io/zw/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}